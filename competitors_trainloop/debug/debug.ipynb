{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import os\n",
    "\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from datetime import date, timedelta\n",
    "import numpy as np\n",
    "\n",
    "import ruclip\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from typing import List, Tuple\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "import optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programming\\jupyterD\\WORK\\venv_second\\Lib\\site-packages\\huggingface_hub\\file_download.py:655: FutureWarning: 'cached_download' is the legacy way to download files from the HF hub, please consider upgrading to 'hf_hub_download'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MPSTATS_TOKEN = '65ddd17d7a2011.184733406ca693eaa900f8cf86e212b476abc2cd'\n",
    "cash = {'data':dict(), 'description':dict()}\n",
    "sbert = SentenceTransformer('all-distilroberta-v1')\n",
    "clip, processor = ruclip.load('ruclip-vit-base-patch32-384')\n",
    "device = 'cpu'\n",
    "is_debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tg_report(text) -> None:\n",
    "    token = '6498069099:AAFtdDZFR-A1h1F-8FvOpt6xIzqjCbdLdsc'\n",
    "    method = 'sendMessage'\n",
    "    chat_id = 324956476\n",
    "    _ = requests.post(\n",
    "            url='https://api.telegram.org/bot{0}/{1}'.format(token, method),\n",
    "            data={'chat_id': chat_id, 'text': text}\n",
    "        ).json()\n",
    "    \n",
    "def get_shard_name(e):\n",
    "    if 0 <= e <= 143:\n",
    "        num = '01'\n",
    "    elif 144 <= e <= 287:\n",
    "        num = '02'\n",
    "    elif 288 <= e <= 431:\n",
    "        num = '03'\n",
    "    elif 432 <= e <= 719:\n",
    "        num = '04'\n",
    "    elif 720 <= e <= 1007:\n",
    "        num = '05'\n",
    "    elif 1008 <= e <= 1061:\n",
    "        num = '06'\n",
    "    elif 1062 <= e <= 1115:\n",
    "        num = '07'\n",
    "    elif 1116 <= e <= 1169:\n",
    "        num = '08'\n",
    "    elif 1170 <= e <= 1313:\n",
    "        num = '09'\n",
    "    elif 1314 <= e <= 1601:\n",
    "        num = '10'\n",
    "    elif 1602 <= e <= 1655:\n",
    "        num = '11'\n",
    "    elif 1656 <= e <= 1919:\n",
    "        num = '12'\n",
    "    else:\n",
    "        num = '13'\n",
    "    return f'//basket-{num}.wb.ru/'\n",
    "\n",
    "def make_url_base(sku):\n",
    "    vol_num = math.floor(sku / 100000)\n",
    "    part_num = math.floor(sku / 1000)\n",
    "    shard_name = get_shard_name(vol_num)\n",
    "    result = f'https:{shard_name}vol{vol_num}/part{part_num}/{sku}'\n",
    "    return result\n",
    "\n",
    "def make_desc_url(sku):\n",
    "    return f'{make_url_base(sku)}/info/ru/card.json'\n",
    "\n",
    "def make_img_url(sku):\n",
    "    return f'{make_url_base(sku)}/images/c246x328/1.jpg'\n",
    "\n",
    "def get_sku_description(sku):\n",
    "    url = make_desc_url(sku)\n",
    "    response = requests.get(url, timeout=(3, 30))\n",
    "    # Check if request was successful (status code 200)\n",
    "    if response.ok:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_sku_image(sku):\n",
    "    url = make_img_url(sku)\n",
    "    img_data = requests.get(url).content\n",
    "    try:\n",
    "        img_data = Image.open(BytesIO(img_data))\n",
    "        # images_urls.append(url)\n",
    "    except: \n",
    "        img_data = None\n",
    "    return img_data\n",
    "\n",
    "def get_images_names(df) -> Tuple[List[Image.Image], List[object]]:\n",
    "    images, names, problems = list(), list(), list()\n",
    "    for row in df.iterrows():\n",
    "        row_num = row[0]\n",
    "        row = row[1]\n",
    "        img1 = get_sku_image(int(row.sku_first))\n",
    "        img2 = get_sku_image(int(row.sku_second))\n",
    "        name1, name2 = row.name_first, row.name_second\n",
    "        if img1 is not None and img2 is not None:\n",
    "            images.append(img1)\n",
    "            images.append(img2)\n",
    "            names.append(name1)\n",
    "            names.append(name2)\n",
    "        else:\n",
    "            problems.append(row_num)\n",
    "    images = images\n",
    "    # im_problems = problems\n",
    "    return images, names, problems\n",
    "\n",
    "def get_data(sku, date_from=None, date_to=None):\n",
    "    \"\"\"\n",
    "    gets features of the product like balance, sales, rating, price, n_comments, discount, position\n",
    "    Returns:\n",
    "        dict or list of dicts (if timedelta calculated for more than one day)\n",
    "    \"\"\"\n",
    "    # данные ЗА предыдущий день появляются в 03:00 AM, за текущий день никогда нет до завтра.\n",
    "    # если будем просматривать промежуток в 00:00 - 03:00 AM, то будет уже и \"завтра\", но данных нет\n",
    "    # будем всегда смотреть на позавчера\n",
    "    if date_from is None:\n",
    "        date_from = date.today() - timedelta(days=1)\n",
    "    if date_to is None:\n",
    "        date_to = date.today() - timedelta(days=1)\n",
    "    payload = {}\n",
    "    headers = {\n",
    "            'x-Mpstats-TOKEN': MPSTATS_TOKEN,\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "    url = f\"https://mpstats.io/api/wb/get/item/{sku}/sales?d1={date_from}&d2={date_to}&SKU={sku}\"\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    resp = response.json() # zero because returned list with one object\n",
    "    return resp\n",
    "\n",
    "def concat_options(options: List[dict]) -> str:\n",
    "    s = ''\n",
    "    if options is not None:\n",
    "        for d in options:\n",
    "            l = list(d.values())\n",
    "            s += l[0] + ': ' + l[1] + '. '\n",
    "    return s\n",
    "\n",
    "def get_df_row(sku:int) -> Tuple[dict, list, list]:\n",
    "    # сначала посмотрим есть ли данные в кэше:\n",
    "    if sku not in cash['data'].keys():\n",
    "        try:\n",
    "            data = get_data(sku)[0] # 0 because we take data for 1 day and get list with one object in result\n",
    "        except:\n",
    "            print(f'sku not found:{sku}')\n",
    "            return None, None, None\n",
    "        # print(sku)\n",
    "        cash['data'][sku] = data\n",
    "        sku_data = get_sku_description(sku)\n",
    "        cash['description'][sku] = sku_data\n",
    "    else:\n",
    "        data = cash['data'][sku] # not using .get()\n",
    "        sku_data = cash['description'][sku] \n",
    "    options = concat_options(sku_data.get('options'))\n",
    "    data['description'] = sku_data.get('description', '')\n",
    "    data['name'] = sku_data.get('imt_name', '')\n",
    "    data['options'] = options\n",
    "    data['sku'] = sku\n",
    "    data['has_video'] = sku_data.get('media').get('has_video', 0)\n",
    "    data['photo_count'] = sku_data.get('media').get('photo_count', 0)\n",
    "    check_if_eq = [sku_data.get('vendor_code', ''), sku_data.get('nm_colors_names'), \n",
    "                sku_data.get('selling', {}).get('brand_name', ''), \n",
    "                sku_data.get('selling', {}).get('supplier_id', '')]\n",
    "    return data, sku_data.get('colors'), check_if_eq # TODO: add colors default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 429,\n",
       " 'message': 'Превышен лимит запросов за 19.03.2024. Повторите попытку позже или выберите более подходящий тарифный план.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data(161053301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'sku_labeled_original_elena.csv'\n",
    "sku = pd.read_csv(data_path)#[:20]   # TODO: test\n",
    "remap = {0:0, 0.1:0, 0.5:0, 0.7:1, 0.9:1, 1:1} \n",
    "sku.replace({'y':remap}, inplace=True)\n",
    "sku.y = sku.y.apply(int)\n",
    "y = sku.y.copy()\n",
    "num_class = sku.y.unique().shape[0]\n",
    "sku.columns = ['sku_first', 'sku_second', 'y']\n",
    "sku_pairs = sku[['sku_first', 'sku_second']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sku not found:161053301\n",
      "161053301\n",
      "sku not found:163552180\n",
      "163552180\n",
      "sku not found:151996747\n",
      "151996747\n",
      "sku not found:127837598\n",
      "127837598\n",
      "sku not found:93307429\n",
      "93307429\n",
      "sku not found:59489486\n",
      "59489486\n",
      "sku not found:160625752\n",
      "160625752\n",
      "sku not found:132739317\n",
      "132739317\n",
      "sku not found:18459707\n",
      "18459707\n",
      "sku not found:66515255\n",
      "66515255\n",
      "sku not found:11386440\n",
      "11386440\n",
      "sku not found:161334901\n",
      "161334901\n",
      "sku not found:136947239\n",
      "136947239\n",
      "sku not found:74692279\n",
      "74692279\n",
      "sku not found:81984205\n",
      "81984205\n",
      "sku not found:90556060\n",
      "90556060\n",
      "sku not found:139357771\n",
      "139357771\n",
      "sku not found:73290325\n",
      "73290325\n",
      "sku not found:144600904\n",
      "144600904\n",
      "sku not found:88390913\n",
      "88390913\n",
      "sku not found:160236284\n",
      "160236284\n",
      "sku not found:90611831\n",
      "90611831\n",
      "sku not found:29233463\n",
      "29233463\n",
      "sku not found:104588539\n",
      "104588539\n",
      "sku not found:68908817\n",
      "68908817\n",
      "sku not found:5980964\n",
      "5980964\n",
      "sku not found:66097681\n",
      "66097681\n",
      "sku not found:159424463\n",
      "159424463\n",
      "sku not found:151287601\n",
      "151287601\n",
      "sku not found:10178895\n",
      "10178895\n",
      "sku not found:115126913\n",
      "115126913\n",
      "sku not found:160798342\n",
      "160798342\n",
      "sku not found:58453532\n",
      "58453532\n",
      "sku not found:126892772\n",
      "126892772\n",
      "sku not found:164912243\n",
      "164912243\n",
      "sku not found:161053301\n",
      "sku not found:165606782\n",
      "161053301 165606782\n",
      "sku not found:161053301\n",
      "sku not found:37985057\n",
      "161053301 37985057\n",
      "sku not found:161053301\n",
      "sku not found:47811809\n",
      "161053301 47811809\n",
      "sku not found:161053301\n",
      "sku not found:157443143\n",
      "161053301 157443143\n",
      "sku not found:161053301\n",
      "sku not found:164287344\n",
      "161053301 164287344\n",
      "sku not found:161053301\n",
      "sku not found:34701883\n",
      "161053301 34701883\n",
      "sku not found:161053301\n",
      "sku not found:111799730\n",
      "161053301 111799730\n",
      "sku not found:161053301\n",
      "sku not found:163343469\n",
      "161053301 163343469\n",
      "sku not found:161053301\n",
      "sku not found:123098828\n",
      "161053301 123098828\n",
      "sku not found:161053301\n",
      "sku not found:87001265\n",
      "161053301 87001265\n",
      "sku not found:161053301\n",
      "sku not found:154063145\n",
      "161053301 154063145\n",
      "sku not found:161053301\n",
      "sku not found:91480025\n",
      "161053301 91480025\n",
      "sku not found:161053301\n",
      "sku not found:28620031\n",
      "161053301 28620031\n",
      "sku not found:161053301\n",
      "sku not found:34344752\n",
      "161053301 34344752\n",
      "sku not found:161053301\n",
      "sku not found:76574810\n",
      "161053301 76574810\n",
      "sku not found:161053301\n",
      "sku not found:79085292\n",
      "161053301 79085292\n",
      "sku not found:161053301\n",
      "sku not found:113307897\n",
      "161053301 113307897\n",
      "sku not found:161053301\n",
      "sku not found:111588016\n",
      "161053301 111588016\n",
      "sku not found:161053301\n",
      "sku not found:113360227\n",
      "161053301 113360227\n",
      "sku not found:161053301\n",
      "sku not found:77948394\n",
      "161053301 77948394\n",
      "sku not found:161053301\n",
      "sku not found:165151088\n",
      "161053301 165151088\n",
      "sku not found:161053301\n",
      "sku not found:161694637\n",
      "161053301 161694637\n",
      "sku not found:161053301\n",
      "sku not found:111588528\n",
      "161053301 111588528\n",
      "sku not found:161053301\n",
      "sku not found:165383213\n",
      "161053301 165383213\n",
      "sku not found:161053301\n",
      "sku not found:30598840\n",
      "161053301 30598840\n",
      "sku not found:161053301\n",
      "sku not found:111655648\n",
      "161053301 111655648\n",
      "sku not found:161053301\n",
      "sku not found:159514712\n",
      "161053301 159514712\n",
      "sku not found:161053301\n",
      "sku not found:156072821\n",
      "161053301 156072821\n",
      "sku not found:161053301\n",
      "sku not found:154592697\n",
      "161053301 154592697\n",
      "sku not found:161053301\n",
      "sku not found:147037928\n",
      "161053301 147037928\n",
      "sku not found:161053301\n",
      "sku not found:13326811\n",
      "161053301 13326811\n",
      "sku not found:161053301\n",
      "sku not found:164003296\n",
      "161053301 164003296\n",
      "sku not found:161053301\n",
      "sku not found:161403913\n",
      "161053301 161403913\n",
      "sku not found:161053301\n",
      "sku not found:161345936\n",
      "161053301 161345936\n",
      "sku not found:161053301\n",
      "sku not found:151572260\n",
      "161053301 151572260\n"
     ]
    }
   ],
   "source": [
    "first, second = [], []\n",
    "paired = []\n",
    "problems = []\n",
    "names = ['iseq_vendor', 'iseq_color', 'iseq_brand', 'iseq_supp']  \n",
    "for sku_first in sku_pairs.sku_first.unique():    # approx 2 min\n",
    "    temp = sku_pairs[sku_pairs.sku_first == sku_first]\n",
    "    data_first, relatives, eq1 = get_df_row(sku_first)\n",
    "    if data_first is None:\n",
    "        if is_debug:\n",
    "            print(sku_first)\n",
    "        for row in temp.iterrows():\n",
    "            row = row[1]\n",
    "            problems.append([row.sku_first, row.sku_second])\n",
    "        continue\n",
    "    for sku_second in temp.sku_second:\n",
    "        data_second, _, eq2 = get_df_row(sku_second)\n",
    "        if data_second is None:\n",
    "            if is_debug:\n",
    "                print(sku_first, sku_second)\n",
    "            problems.append([sku_first, sku_second])\n",
    "            continue\n",
    "        d = {names[i]:(1 if el1 == el2 else 0) for i, (el1, el2) in enumerate(zip(eq1, eq2))}\n",
    "        if relatives is not None and sku_second in relatives:\n",
    "            d['are_related'] = 1\n",
    "        else:\n",
    "            d['are_related'] = 0\n",
    "        paired.append(d)\n",
    "        second.append(data_second)\n",
    "        first.append(data_first)\n",
    "if is_debug:    \n",
    "    make_tg_report('Конец загрузки данных')\n",
    "# handling problems (~ timeouts by mpstats server)\n",
    "# Just iterating again\n",
    "for sku_first, sku_second in problems:\n",
    "    data_first, relatives, eq1 = get_df_row(sku_first)\n",
    "    data_second, _, eq2 = get_df_row(sku_second)\n",
    "    if data_first is None or data_second is None:\n",
    "        if is_debug:\n",
    "            print(sku_first, sku_second)\n",
    "        continue\n",
    "    d = {names[i]:(1 if el1 == el2 else 0) for i, (el1, el2) in enumerate(zip(eq1, eq2))}\n",
    "    if relatives is not None and sku_second in relatives:\n",
    "        d['are_related'] = 1\n",
    "    else:\n",
    "        d['are_related'] = 0\n",
    "    paired.append(d)\n",
    "    second.append(data_second)\n",
    "    first.append(data_first)\n",
    "data_first = pd.DataFrame(first)\n",
    "data_second = pd.DataFrame(second)\n",
    "data_paired = pd.DataFrame(paired)\n",
    "cols_to_stay = ['balance', 'sales', 'rating', 'final_price', 'comments', \\\n",
    "                'description', 'name', 'options', 'sku', 'has_video', 'photo_count'] \n",
    "data_first = data_first[cols_to_stay]\n",
    "data_second = data_second[cols_to_stay]\n",
    "df = data_first.join(data_second, lsuffix=\"_first\", rsuffix=(\"_second\"))\n",
    "# additional position feature\n",
    "df = pd.concat([df, data_paired], axis=1)\n",
    "# handling NaNs\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids of images that did not open: [13, 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:18,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "desc_first, opt_first = df.description_first, df.options_first\n",
    "desc_second, opt_second = df.description_second, df.options_second \n",
    "emb_first = sbert.encode(desc_first, convert_to_tensor=True, show_progress_bar = False)\n",
    "emb_second = sbert.encode(desc_second, convert_to_tensor=True, show_progress_bar = False)\n",
    "desc_sim = np.diag(util.cos_sim(emb_first, emb_second).cpu().numpy())\n",
    "emb_first = sbert.encode(opt_first, convert_to_tensor=True, show_progress_bar = False)\n",
    "emb_second = sbert.encode(opt_second, convert_to_tensor=True, show_progress_bar = False)\n",
    "opt_sim = np.diag(util.cos_sim(emb_first, emb_second).cpu().numpy())\n",
    "images, names, problems_ids = get_images_names(df)\n",
    "id_to_del = ~df.index.isin(problems_ids)\n",
    "df = df[id_to_del]\n",
    "# print(df.shape)\n",
    "y = y[id_to_del]\n",
    "# print(y.shape)q\n",
    "if is_debug:\n",
    "    print(f'ids of images that did not open: {problems_ids}')\n",
    "desc_sim = np.delete(desc_sim, problems_ids)\n",
    "opt_sim = np.delete(opt_sim, problems_ids)\n",
    "# print(desc_sim.shape)\n",
    "# print(opt_sim.shape)\n",
    "classes = list(names)\n",
    "# print(len(classes))\n",
    "templates = ['{}', 'это {}', 'на картинке {}', 'товар {}']\n",
    "# predict\n",
    "predictor = ruclip.Predictor(clip, processor, device, bs=8, templates=templates)\n",
    "with torch.no_grad():\n",
    "    text_latents = predictor.get_text_latents(classes)\n",
    "    images_latents = predictor.get_image_latents(images)\n",
    "name_sim = []\n",
    "img_sim = []\n",
    "# print(text_latents.shape)\n",
    "for ind in range(0, text_latents.shape[0], 2):\n",
    "    first = text_latents[ind]\n",
    "    second = text_latents[ind + 1]\n",
    "    name_sim.append(util.cos_sim(first, second).cpu().numpy().squeeze())\n",
    "    first = images_latents[ind]\n",
    "    second = images_latents[ind + 1]\n",
    "    img_sim.append(util.cos_sim(first, second).cpu().numpy().squeeze())\n",
    "# print(len(name_sim))\n",
    "# print(len(img_sim))\n",
    "scores = np.c_[desc_sim, opt_sim, name_sim, img_sim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 27)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(scores, columns=['desc_sim', 'opt_sim', 'name_sim', 'img_sim'])\n",
    "new_df = pd.concat([df.reset_index(drop=True), scores_df], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_second",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
