{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcaee945",
   "metadata": {},
   "source": [
    "# Installs & tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d9b411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    import mlflow\n",
    "except ImportError:\n",
    "    !pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c65f9c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    import dotenv\n",
    "except ImportError:\n",
    "    !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e77b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Log into huggingface via Kaggle Secrets\n",
    "\n",
    "# import os\n",
    "# import huggingface_hub\n",
    "# from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# user_secrets = UserSecretsClient()\n",
    "# HF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "\n",
    "# huggingface_hub.login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0c3f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Log into huggingface via .env\n",
    "\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# import huggingface_hub\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "# huggingface_hub.login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a0467",
   "metadata": {},
   "source": [
    "# Choose notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be91836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "## CHOOSE MODEL PARAMETERS #################################################\n",
    "\n",
    "DATA_PATH = 'data/'\n",
    "DEVICE='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "NAME_MODEL_NAME = 'cointegrated/rubert-tiny' # 'DeepPavlov/distilrubert-tiny-cased-conversational-v1'\n",
    "DESCRIPTION_MODEL_NAME = 'cointegrated/rubert-tiny'\n",
    "\n",
    "# BATCH_SIZE=90\n",
    "# NUM_WORKERS=8\n",
    "# NUM_DEBUG_SAMPLES=None\n",
    "# EPOCHS=20\n",
    "\n",
    "BATCH_SIZE=1\n",
    "NUM_WORKERS=0\n",
    "NUM_DEBUG_SAMPLES=2\n",
    "EPOCHS=2\n",
    "\n",
    "EMB_SIZE=768\n",
    "VALIDATION_SPLIT=.25\n",
    "SHUFFLE_DATASET=True\n",
    "RANDOM_SEED=42\n",
    "LR=9e-5\n",
    "MOMENTUM=0.9\n",
    "WEIGHT_DECAY=1e-2\n",
    "CONTRASTIVE_MARGIN=1.5\n",
    "CONTRASTIVE_THRESHOLD=0.3\n",
    "SHEDULER_PATIENCE=3 # in epochs\n",
    "\n",
    "MODEL_NAME_POSTFIX='splitting-by-query'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d9e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHOOSE DATA #########################################################\n",
    "\n",
    "# # These table files need 'image_name_first', 'image_name_second' constructed from sku to be usable in current pipeline\n",
    "# TABLE_DATASET_FILE = 'tables_labeled/processed/labeled_1.3k_with-options.csv'\n",
    "# TABLE_DATASET_FILE = 'tables_labeled/processed/labeled_56k_with-options.csv'\n",
    "# IMG_DATASET_NAME = 'images_7k'\n",
    "# STRATIFY_COLS = None\n",
    "\n",
    "# TABLE_DATASET_FILE = 'tables_labeled/processed/labeled_5k_with-options.csv'\n",
    "# IMG_DATASET_NAME = 'images_7k' \n",
    "# STRATIFY_COLS = None\n",
    "\n",
    "# TABLE_DATASET_FILE = 'tables_WB_OZ_100/WB_OZ_100.csv'\n",
    "# TABLE_DATASET_FILE = 'tables_WB_OZ_100/WB_OZ_100_conjugated.csv'\n",
    "# TABLE_DATASET_FILE = 'tables_WB_OZ_100/WB_OZ_100_conjugated_shuffled_seed=42_fraction=1.csv'\n",
    "# TABLE_DATASET_FILE = 'tables_WB_OZ_100/WB_OZ_100_conjugated_shuffled_seed=42_fraction=0.5.csv'\n",
    "# IMG_DATASET_NAME = 'images_WB_OZ_100'\n",
    "# STRATIFY_COLS = None\n",
    "\n",
    "TABLE_DATASET_FILE = 'tables_OZ_geo_5500/processed/regex-pairwise-dataset_num-queries=20_num-pairs=6226_patterns-dict-hash=6dbf9b3ef9568e60cd959f87be7e3b26.csv'\n",
    "IMG_DATASET_NAME = 'images_OZ_geo_5500'\n",
    "STRATIFY_COLS = ['sku_first', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14b5eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOGGING PARAMS ######################################################################\n",
    "\n",
    "# MLFLOW_URI = \"http://176.56.185.96:5000\"\n",
    "# MLFLOW_URI = \"http://localhost:5000\"\n",
    "MLFLOW_URI = None\n",
    "\n",
    "MLFLOW_EXPERIMENT = \"siamese/1fold\"\n",
    "\n",
    "TELEGRAM_TOKEN = None\n",
    "# TELEGRAM_TOKEN = '' # set token to get notifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b40bc83",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00017085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from timm import create_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "# import transformers\n",
    "# from transformers import DistilBertModel, DistilBertConfig, DistilBertTokenizer,\\\n",
    "#         get_linear_schedule_with_warmup\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# import json\n",
    "# from itertools import product\n",
    "\n",
    "# import datasets\n",
    "# from datasets import Dataset, concatenate_datasets\n",
    "# import argparse\n",
    "import requests\n",
    "\n",
    "# from io import BytesIO\n",
    "# from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "# import more_itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3494173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tg_report(text, token=None) -> None:\n",
    "    method = 'sendMessage'\n",
    "    chat_id = 324956476\n",
    "    _ = requests.post(\n",
    "            url='https://api.telegram.org/bot{0}/{1}'.format(token, method),\n",
    "            data={'chat_id': chat_id, 'text': text} \n",
    "        ).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84518fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuCLIPtiny(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.visual = create_model('convnext_tiny',\n",
    "                                   pretrained=False, # TODO: берём претрейн\n",
    "                                   num_classes=0,\n",
    "                                   in_chans=3)  # out 768\n",
    "\n",
    "        self.transformer = AutoModel.from_pretrained(NAME_MODEL_NAME)\n",
    "        name_model_output_shape = self.transformer.config.hidden_size  # dynamically get hidden size\n",
    "        self.final_ln = torch.nn.Linear(name_model_output_shape, 768)  # now uses the transformer hidden size\n",
    "        self.logit_scale = torch.nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        return self.visual.stem[0].weight.dtype\n",
    "\n",
    "    def encode_image(self, image):\n",
    "        return self.visual(image.type(self.dtype))\n",
    "\n",
    "    def encode_text(self, input_ids, attention_mask):\n",
    "        x = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = x.last_hidden_state[:, 0, :]\n",
    "        x = self.final_ln(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, image, input_ids, attention_mask):\n",
    "        image_features = self.encode_image(image)\n",
    "        text_features = self.encode_text(input_ids, attention_mask)\n",
    "\n",
    "        # normalized features\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # cosine similarity as logits\n",
    "        logit_scale = self.logit_scale.exp()\n",
    "        logits_per_image = logit_scale * image_features @ text_features.t()\n",
    "        logits_per_text = logits_per_image.t()\n",
    "\n",
    "        return logits_per_image, logits_per_text\n",
    "    \n",
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        _convert_image_to_rgb,\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]), ])\n",
    "\n",
    "def _convert_image_to_rgb(image):\n",
    "    return image.convert(\"RGB\")\n",
    "\n",
    "class Tokenizers:\n",
    "    def __init__(self):\n",
    "        self.name_tokenizer = AutoTokenizer.from_pretrained(NAME_MODEL_NAME)\n",
    "        self.desc_tokenizer = AutoTokenizer.from_pretrained(DESCRIPTION_MODEL_NAME)\n",
    "\n",
    "    def tokenize_name(self, texts, max_len=77):\n",
    "        tokenized = self.name_tokenizer.batch_encode_plus(texts,\n",
    "                                                     truncation=True,\n",
    "                                                     add_special_tokens=True,\n",
    "                                                     max_length=max_len,\n",
    "                                                     padding='max_length',\n",
    "                                                     return_attention_mask=True,\n",
    "                                                     return_tensors='pt')\n",
    "        return torch.stack([tokenized[\"input_ids\"], tokenized[\"attention_mask\"]])\n",
    "    \n",
    "    def tokenize_description(self, texts, max_len=77):\n",
    "        tokenized = self.desc_tokenizer(texts,\n",
    "                                        truncation=True,\n",
    "                                        add_special_tokens=True,\n",
    "                                        max_length=max_len,\n",
    "                                        padding='max_length',\n",
    "                                        return_attention_mask=True,\n",
    "                                        return_tensors='pt')\n",
    "        return torch.stack([tokenized[\"input_ids\"], tokenized[\"attention_mask\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2d263be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "class SiameseRuCLIP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 device: str,\n",
    "                 name_model_name: str,\n",
    "                 description_model_name: str,\n",
    "                 models_dir: str = None,\n",
    "                 preload_ruclip: bool = False,\n",
    "                 preload_model_name: str = None):\n",
    "        \"\"\"\n",
    "        Initializes the SiameseRuCLIP model.\n",
    "        Required parameters:\n",
    "          - models_dir: directory containing saved checkpoints.\n",
    "          - name_model_name: model name for text (name) branch.\n",
    "          - description_model_name: model name for description branch.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        device = torch.device(device)\n",
    "\n",
    "        # Initialize RuCLIPtiny\n",
    "        self.ruclip = RuCLIPtiny(name_model_name)\n",
    "        if preload_ruclip:\n",
    "            std = torch.load(\n",
    "                os.path.join(models_dir, preload_model_name),\n",
    "                weights_only=True,\n",
    "                map_location=device\n",
    "            )\n",
    "            self.ruclip.load_state_dict(std)\n",
    "            self.ruclip.eval()\n",
    "        self.ruclip = self.ruclip.to(device)\n",
    "\n",
    "        # Initialize the description transformer\n",
    "        self.description_transformer = AutoModel.from_pretrained(description_model_name)\n",
    "        self.description_transformer = self.description_transformer.to(device)\n",
    "\n",
    "        # Determine dimensionality\n",
    "        vision_dim = self.ruclip.visual.num_features\n",
    "        name_dim = self.ruclip.final_ln.out_features\n",
    "        desc_dim = self.description_transformer.config.hidden_size\n",
    "        self.hidden_dim = vision_dim + name_dim + desc_dim\n",
    "\n",
    "        # Define MLP head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim // 2, self.hidden_dim // 4),\n",
    "        ).to(device)\n",
    "\n",
    "    def encode_image(self, image):\n",
    "        return self.ruclip.encode_image(image)\n",
    "\n",
    "    def encode_name(self, name):\n",
    "        return self.ruclip.encode_text(name[:, 0, :], name[:, 1, :])\n",
    "\n",
    "    def encode_description(self, desc):\n",
    "        last_hidden_states = self.description_transformer(desc[:, 0, :], desc[:, 1, :]).last_hidden_state\n",
    "        attention_mask = desc[:, 1, :]\n",
    "        return average_pool(last_hidden_states, attention_mask)\n",
    "\n",
    "    def get_final_embedding(self, im, name, desc):\n",
    "        image_emb = self.encode_image(im)\n",
    "        name_emb = self.encode_name(name)\n",
    "        # desc_emb = self.encode_description(desc)\n",
    "\n",
    "        # for models using ruclip instead of another BERT for descriptions\n",
    "        desc_emb  = self.ruclip.encode_text(desc[:,0,:], desc[:,1,:]) \n",
    "\n",
    "\n",
    "        # Concatenate the embeddings and forward through the head\n",
    "        combined_emb = torch.cat([image_emb, name_emb, desc_emb], dim=1)\n",
    "        final_embedding = self.head(combined_emb)\n",
    "        return final_embedding\n",
    "\n",
    "    def forward(self, im1, name1, desc1, im2, name2, desc2):\n",
    "        out1 = self.get_final_embedding(im1, name1, desc1)\n",
    "        out2 = self.get_final_embedding(im2, name2, desc2)\n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "987d1ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def __name__(self,):\n",
    "        return 'ContrastiveLoss'\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        pos = (1-label) * torch.pow(euclidean_distance, 2)\n",
    "        neg = label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        loss_contrastive = torch.mean( pos + neg )\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9c6281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pair(output1, output2, target, threshold):\n",
    "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "    # меньше границы, там где будет True — конкуренты\n",
    "    cond = euclidean_distance < threshold\n",
    "    pos_sum = 0\n",
    "    neg_sum = 0\n",
    "    pos_acc = 0\n",
    "    neg_acc = 0\n",
    "\n",
    "    for i in range(len(cond)):\n",
    "        # 1 значит не конкуренты\n",
    "        if target[i]:\n",
    "            neg_sum+=1\n",
    "            # 0 в cond значит дальше друг от друга чем threshold\n",
    "            if not cond[i]:\n",
    "                neg_acc+=1\n",
    "        elif not target[i]:\n",
    "            pos_sum+=1\n",
    "            if cond[i]:\n",
    "                pos_acc+=1\n",
    "\n",
    "    return pos_acc, pos_sum, neg_acc, neg_sum\n",
    "\n",
    "def predict(out1, out2, threshold=CONTRASTIVE_THRESHOLD):\n",
    "    # вернёт 1 если похожи\n",
    "    return F.pairwise_distance(out1, out2) < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6664f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, valid_loader, epoch, device='cpu', split_name='validation') -> float:\n",
    "    assert split_name in ['train', 'validation', 'test']\n",
    "\n",
    "    valid_loss = 0\n",
    "    val_pos_accuracy = 0\n",
    "    val_neg_accuracy = 0\n",
    "    num_pos = 0\n",
    "    num_neg = 0\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for data in tqdm(valid_loader, desc=split_name):\n",
    "            im1, name1, desc1, im2, name2, desc2, label = data \n",
    "            im1, name1, desc1, im2, name2, desc2, label = (\n",
    "                im1.to(device), name1.to(device), desc1.to(device),\n",
    "                im2.to(device), name2.to(device), desc2.to(device), label.to(device)\n",
    "            )\n",
    "            out1, out2 = model(im1, name1, desc1, im2, name2, desc2) \n",
    "            loss = criterion(out1, out2, label)\n",
    "            pos_acc, pos_sum, neg_acc, neg_sum = evaluate_pair(out1, out2, label, CONTRASTIVE_THRESHOLD)\n",
    "            val_pos_accuracy += pos_acc\n",
    "            val_neg_accuracy += neg_acc\n",
    "            num_pos += pos_sum\n",
    "            num_neg += neg_sum\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "    val_pos_accuracy = val_pos_accuracy / num_pos if num_pos > 0 else 0.0\n",
    "    val_neg_accuracy = val_neg_accuracy / num_neg if num_neg > 0 else 0.0\n",
    "    valid_loss = valid_loss / len(valid_loader) if len(valid_loader) > 0 else 0.0\n",
    "\n",
    "    report = (\n",
    "        f\"[{split_name}] Epoch: {epoch}, loss: {valid_loss:.3f}, \"\n",
    "        f\"P Acc: {val_pos_accuracy:.3f}, N Acc: {val_neg_accuracy:.3f} \" + MODEL_NAME_POSTFIX + '\\n'\n",
    "    )\n",
    "    print(report)\n",
    "    make_tg_report(report, TELEGRAM_TOKEN)\n",
    "    \n",
    "    return val_pos_accuracy, val_neg_accuracy, (val_pos_accuracy + val_neg_accuracy) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e34b5c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def plot_epoch(loss_history, filename=\"data/runs_artifacts/epoch_loss.png\") -> None:\n",
    "    Path(filename).parent.mkdir(parents=True, exist_ok=True)\n",
    "    display.clear_output(wait=True)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.title(\"Training loss\")\n",
    "    plt.xlabel(\"Iteration number\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(loss_history, 'b')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)  # Save the plot to a file\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4952b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def train(model, optimizer, criterion, \n",
    "          epochs_num, train_loader, valid_loader=None, \n",
    "          device='cpu', print_epoch=False,\n",
    "          models_dir=DATA_PATH + 'train_results/') -> tuple[int, float, dict]:\n",
    "    \"\"\"\n",
    "    Trains the model, saving a checkpoint at each epoch and keeping track\n",
    "    of the one with the highest validation score.\n",
    "    Returns:\n",
    "      best_epoch: int\n",
    "      best_valid_score: float\n",
    "      best_weights: state_dict of the best model\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    \n",
    "    best_valid_score = float('-inf')\n",
    "    best_epoch = -1\n",
    "    best_weights = None\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, mode=\"max\",\n",
    "        factor=0.1, patience=SHEDULER_PATIENCE,\n",
    "        threshold=0.0001, threshold_mode='rel',\n",
    "        cooldown=0, min_lr=0, eps=1e-08\n",
    "    )\n",
    "\n",
    "    # ensure checkpoint directory exists\n",
    "    Path(models_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for epoch in range(epochs_num):\n",
    "        print(f\"Epoch {epoch+1}/{epochs_num}\")\n",
    "        for i, data in enumerate(tqdm(train_loader, desc='train')):\n",
    "            im1, name1, desc1, im2, name2, desc2, label = (\n",
    "                t.to(device) for t in data\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            out1, out2 = model(im1, name1, desc1, im2, name2, desc2)\n",
    "            loss = criterion(out1, out2, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if print_epoch and valid_loader is not None:\n",
    "            val_pos_acc, val_neg_acc, val_acc = validation(\n",
    "                model, criterion, valid_loader, epoch, device, split_name='validation'\n",
    "            )\n",
    "\n",
    "            # step scheduler based on combined accuracy\n",
    "            scheduler.step(val_acc)\n",
    "\n",
    "            # save this epoch's checkpoint\n",
    "            ckpt_path = Path(models_dir) / f\"checkpoint_epoch_{epoch+1}.pt\"\n",
    "            torch.save(model.state_dict(), ckpt_path)\n",
    "\n",
    "            # update best if improved\n",
    "            if val_acc > best_valid_score:\n",
    "                best_valid_score = val_acc\n",
    "                best_epoch = epoch + 1\n",
    "                best_weights = model.state_dict()\n",
    "                \n",
    "    print(f\"Best validation accuracy {best_valid_score:.3f} at epoch {best_epoch}\")\n",
    "    return best_epoch, best_valid_score, best_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481940bc",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e226754b",
   "metadata": {},
   "source": [
    "## Download data from HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b8cde88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e79c07194b49e78d208fd619332408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download models' weights & text/image datasets\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_ID = \"INDEEPA/clip-siamese\"\n",
    "LOCAL_DIR = Path(\"data/train_results\")\n",
    "LOCAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=REPO_ID,\n",
    "    repo_type='dataset',\n",
    "    local_dir='data',\n",
    "    allow_patterns=[\n",
    "        \"train_results/cc12m*.pt\",\n",
    "        TABLE_DATASET_FILE,\n",
    "        f\"{IMG_DATASET_NAME}.zip\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "!unzip -n -q data/{IMG_DATASET_NAME}.zip -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d35d53",
   "metadata": {},
   "source": [
    "## Split data by query sku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "387fca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique query sku: 20\n"
     ]
    }
   ],
   "source": [
    "TABLE_DATASET_PATH = DATA_PATH + TABLE_DATASET_FILE\n",
    "\n",
    "labeled = pd.read_csv(TABLE_DATASET_PATH)\n",
    "print(f\"Unique query sku: {labeled.sku_query.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c414d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/val/test\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "def split_pairwise(\n",
    "    df: pd.DataFrame,\n",
    "    test_size: float = 0.20,\n",
    "    random_state: int | None = None,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Leakage-free DEV / TEST split for a pair-wise SKU dataset.\n",
    "    Input `df` must have columns ['sku_query','sku_candidate','label'].\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    test_rows, dev_rows   = [], []\n",
    "    test_entities: set[str] = set()\n",
    "\n",
    "    # ---- iterate over each original query SKU ------------------------------\n",
    "    for q_sku, grp in df.groupby(\"sku_query\"):\n",
    "        pos_idx = grp.index[grp.label == 1].tolist()\n",
    "        neg_idx = grp.index[grp.label == 0].tolist()\n",
    "\n",
    "        # --- (1) sample TEST rows -------------------------------------------\n",
    "        n_pos = int(np.ceil(test_size * len(pos_idx))) if pos_idx else 0\n",
    "        n_neg = int(np.ceil(test_size * len(neg_idx))) if neg_idx else 0\n",
    "\n",
    "        pos_test = rng.choice(pos_idx, size=n_pos, replace=False) if n_pos else []\n",
    "        neg_test = rng.choice(neg_idx, size=n_neg, replace=False) if n_neg else []\n",
    "\n",
    "        test_rows.extend(pos_test)\n",
    "        test_rows.extend(neg_test)\n",
    "\n",
    "        # register every entity that just entered TEST\n",
    "        test_entities.add(q_sku)\n",
    "        test_entities.update(df.loc[pos_test, \"sku_candidate\"])\n",
    "        test_entities.update(df.loc[neg_test, \"sku_candidate\"])\n",
    "\n",
    "        # --- (2) build DEV from remaining rows ------------------------------\n",
    "        remain_pos = list(set(pos_idx) - set(pos_test))\n",
    "        remain_neg = list(set(neg_idx) - set(neg_test))\n",
    "\n",
    "        if remain_pos:\n",
    "            # choose substitute query (one of the remaining positives)\n",
    "            sub_idx  = int(rng.choice(remain_pos))\n",
    "            sub_sku  = df.loc[sub_idx, \"sku_candidate\"]\n",
    "\n",
    "            for idx in remain_pos:\n",
    "                if idx == sub_idx:            # skip (sub,sub) self-pair\n",
    "                    continue\n",
    "                row = df.loc[idx].copy()\n",
    "                row[\"sku_query\"] = sub_sku\n",
    "                dev_rows.append(row)\n",
    "\n",
    "            for idx in remain_neg:\n",
    "                row = df.loc[idx].copy()\n",
    "                row[\"sku_query\"] = sub_sku\n",
    "                dev_rows.append(row)\n",
    "\n",
    "    # ---- materialise the splits -------------------------------------------\n",
    "    test_df = df.loc[test_rows].reset_index(drop=True)\n",
    "    dev_df  = pd.DataFrame(dev_rows).reset_index(drop=True)\n",
    "\n",
    "    # ---- (3) final purge: remove any row touching a TEST entity ------------\n",
    "    mask = ~(dev_df[\"sku_query\"].isin(test_entities) |\n",
    "             dev_df[\"sku_candidate\"].isin(test_entities))\n",
    "    dev_df = dev_df[mask].reset_index(drop=True)\n",
    "\n",
    "    return dev_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e00ad1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2548, 95), (409, 95), (332, 95))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into train/val/test\n",
    "\n",
    "dev_df,  test_df  = split_pairwise(labeled,  test_size=0.05, random_state=42)\n",
    "train_df, val_df  = split_pairwise(dev_df,   test_size=0.1, random_state=42)\n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efc1fa9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       hard_negative  positive  total\n",
      "split                                \n",
      "train           2210       338   2548\n",
      "val              348        61    409\n",
      "test             280        52    332\n"
     ]
    }
   ],
   "source": [
    "# Print positive/hard_negative pairs count per each split \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# collect your splits in a dict\n",
    "splits = {\n",
    "    'train': train_df,\n",
    "    'val':   val_df,\n",
    "    'test':  test_df,\n",
    "}\n",
    "\n",
    "# build the summary_df records\n",
    "records = []\n",
    "for name, df in splits.items():\n",
    "    vc = df['label'].value_counts()\n",
    "    records.append({\n",
    "        'split':    name,\n",
    "        'hard_negative': vc.get(0, 0),\n",
    "        'positive': vc.get(1, 0),\n",
    "        'total':    len(df),\n",
    "    })\n",
    "\n",
    "# create a DataFrame and set the split name as index\n",
    "summary_df = (\n",
    "    pd.DataFrame(records)\n",
    "      .set_index('split')\n",
    "      .astype(int)\n",
    ")\n",
    "\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bed0574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All sanity checks passed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def sanity_checks(train: pd.DataFrame, val: pd.DataFrame, test: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Verify that:\n",
    "      1) Each query SKU appears in exactly one split\n",
    "      2) No SKU (query or candidate) overlaps across splits\n",
    "      3) No duplicate pairs across splits\n",
    "      4) Each split has at least one positive and one hard_negative\n",
    "    \"\"\"\n",
    "    # 1) Query-level disjointness\n",
    "    q_train = set(train[\"sku_query\"])\n",
    "    q_val   = set(val  [\"sku_query\"])\n",
    "    q_test  = set(test [\"sku_query\"])\n",
    "    assert not (q_train & q_val),   f\"Query SKU overlap train↔val: {q_train & q_val}\"\n",
    "    assert not (q_train & q_test),  f\"Query SKU overlap train↔test: {q_train & q_test}\"\n",
    "    assert not (q_val   & q_test),  f\"Query SKU overlap val↔test:   {q_val   & q_test}\"\n",
    "    \n",
    "    # 2) Global SKU disjointness (query OR candidate)\n",
    "    def all_skus(df):\n",
    "        return set(df[\"sku_query\"]) | set(df[\"sku_candidate\"])\n",
    "    s_train, s_val, s_test = all_skus(train), all_skus(val), all_skus(test)\n",
    "    assert not (s_train & s_val),   f\"SKU overlap train↔val: {s_train & s_val}\"\n",
    "    assert not (s_train & s_test),  f\"SKU overlap train↔test: {s_train & s_test}\"\n",
    "    assert not (s_val   & s_test),  f\"SKU overlap val↔test:   {s_val   & s_test}\"\n",
    "    \n",
    "    # 3) Unique pairs\n",
    "    all_pairs = pd.concat([train, val, test], ignore_index=True)\n",
    "    dupes = all_pairs.duplicated(subset=[\"sku_query\",\"sku_candidate\",\"label\"])\n",
    "    assert not dupes.any(), f\"Found {dupes.sum()} duplicate pairs across splits\"\n",
    "    \n",
    "    # 4) Label coverage in each split\n",
    "    for name, df in [(\"train\", train), (\"val\", val), (\"test\", test)]:\n",
    "        labels = df[\"label\"].unique()\n",
    "        assert set(labels) == {0,1}, f\"{name} split has labels {labels}, expected {{0,1}}\"\n",
    "    \n",
    "    print(\"✅ All sanity checks passed!\")\n",
    "\n",
    "sanity_checks(train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4aa24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_split(df: pd.DataFrame, num_samples: int | None, random_state: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    If num_samples is set, take up to that many random rows;\n",
    "    otherwise just shuffle the entire DataFrame.\n",
    "    Always resets the index.\n",
    "    \"\"\"\n",
    "    if num_samples is not None:\n",
    "        n = min(num_samples, len(df))\n",
    "        out = df.sample(n=n, random_state=random_state)\n",
    "    else:\n",
    "        out = df.sample(frac=1, random_state=random_state)\n",
    "    return out.reset_index(drop=True)\n",
    "\n",
    "# apply to each split\n",
    "train_df = sample_split(train_df, NUM_DEBUG_SAMPLES, RANDOM_SEED)\n",
    "val_df   = sample_split(val_df,   NUM_DEBUG_SAMPLES, RANDOM_SEED)\n",
    "test_df  = sample_split(test_df,  NUM_DEBUG_SAMPLES, RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef17b84c",
   "metadata": {},
   "source": [
    "# Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afb31be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def _run():\n",
    "    images_dir = os.path.join(DATA_PATH, IMG_DATASET_NAME)\n",
    "\n",
    "    # 1) Prepare splits and rename columns\n",
    "    splits = {\n",
    "        'train':      train_df,\n",
    "        'validation': val_df,\n",
    "        'test':       test_df,\n",
    "    }\n",
    "    loaders = {}\n",
    "\n",
    "    for split_name, df in splits.items():\n",
    "        # rename for dataset compatibility\n",
    "        df = df.rename(columns={\n",
    "            col: col.replace(\"_query\", \"_first\").replace(\"_candidate\", \"_second\")\n",
    "            for col in df.columns\n",
    "            if \"_query\" in col or \"_candidate\" in col\n",
    "        })\n",
    "\n",
    "        # build dataset + loader\n",
    "        labels = df[\"label\"].values\n",
    "        ds     = SiameseRuCLIPDataset(df.drop(columns=\"label\"), labels, images_dir=images_dir)\n",
    "\n",
    "        shuffle = (split_name == 'train')\n",
    "        loaders[split_name] = DataLoader(\n",
    "            ds,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=NUM_WORKERS\n",
    "        )\n",
    "\n",
    "    train_loader = loaders['train']\n",
    "    valid_loader = loaders['validation']\n",
    "    test_loader  = loaders['test']\n",
    "\n",
    "    # 2) Model, loss, optimizer\n",
    "    print('Loading model...')\n",
    "    model     = SiameseRuCLIP(device=DEVICE).to(DEVICE)\n",
    "    criterion = ContrastiveLoss(margin=CONTRASTIVE_MARGIN).to(DEVICE)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    print('Done loading model.')\n",
    "\n",
    "    # 3) (Optional) MLflow setup\n",
    "    if MLFLOW_URI:\n",
    "        mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "        mlflow.set_experiment(MLFLOW_EXPERIMENT)\n",
    "        mlflow.enable_system_metrics_logging()\n",
    "        mlflow.start_run()\n",
    "        mlflow.log_params({\n",
    "            \"epochs\":       EPOCHS,\n",
    "            \"lr\":           LR,\n",
    "            \"batch_size\":   BATCH_SIZE,\n",
    "            \"weight_decay\": WEIGHT_DECAY,\n",
    "            \"num_workers\":  NUM_WORKERS,\n",
    "        })\n",
    "\n",
    "    # 4) Training + validation, now returns best_epoch & best_score\n",
    "    best_epoch, best_score, best_weights = train(\n",
    "        model, optimizer, criterion,\n",
    "        EPOCHS, train_loader, valid_loader,\n",
    "        print_epoch=True,\n",
    "        device=DEVICE,\n",
    "        models_dir=DATA_PATH + 'train_results/'\n",
    "    )\n",
    "\n",
    "    # 5) Reload best weights before testing\n",
    "    print(f\"Reloading best model from epoch {best_epoch} (val_acc={best_score:.3f})\")\n",
    "    model.load_state_dict(best_weights)\n",
    "    model.eval()\n",
    "\n",
    "    # 6) FINAL TESTING on the best checkpoint\n",
    "    with torch.no_grad():\n",
    "        test_pos_acc, test_neg_acc, test_acc = validation(\n",
    "            model,\n",
    "            criterion,\n",
    "            test_loader,\n",
    "            epoch=best_epoch,\n",
    "            device=DEVICE,\n",
    "            split_name='test'\n",
    "        )\n",
    "    print(f\"Test accuracy on best model: {test_acc:.3f}\")\n",
    "\n",
    "    # 7) Log model signature (no example) if using MLflow\n",
    "    if MLFLOW_URI:\n",
    "        # infer signature from a small batch\n",
    "        batch = next(iter(valid_loader))\n",
    "        # move to CPU/NumPy and back to torch to compute output shapes\n",
    "        inputs = [t.to(DEVICE).cpu().numpy() for t in batch[:-1]]\n",
    "        tensors = [torch.from_numpy(arr).to(DEVICE) for arr in inputs]\n",
    "        outputs = model(*tensors)\n",
    "        outputs = [o.cpu().detach().numpy() for o in outputs]\n",
    "\n",
    "        signature = infer_signature(\n",
    "            {k: v for k, v in zip(\n",
    "                [\"im1\",\"name1\",\"desc1\",\"im2\",\"name2\",\"desc2\"], inputs\n",
    "            )},\n",
    "            {\"out1\": outputs[0], \"out2\": outputs[1]}\n",
    "        )\n",
    "\n",
    "        mlflow.pytorch.log_model(\n",
    "            model,\n",
    "            artifact_path=\"model\",\n",
    "            signature=signature\n",
    "        )\n",
    "\n",
    "    print('Done saving model.')\n",
    "\n",
    "    if MLFLOW_URI:\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6511a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Done loading model.\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd872fdb6cd476f8be3bb4c32b32064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f4524289f340968393e7a3ae96892f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[validation] Epoch: 0, loss: 5.132, P Acc: 0.000, N Acc: 1.000 splitting-by-query\n",
      "\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef1816a3ba84dd1bfe89900374bdbca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2bf5a0a97145a59b6416c1c9abd429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[validation] Epoch: 1, loss: 2.602, P Acc: 0.000, N Acc: 1.000 splitting-by-query\n",
      "\n",
      "Best validation accuracy 0.500 at epoch 1\n",
      "Reloading best model from epoch 1 (val_acc=0.500)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b3838142034f4facebe2c07ebc99ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 1, loss: 5.634, P Acc: 0.000, N Acc: 0.000 splitting-by-query\n",
      "\n",
      "Test accuracy on best model: 0.000\n",
      "Done saving model.\n"
     ]
    }
   ],
   "source": [
    "_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
