{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcaee945",
   "metadata": {},
   "source": [
    "# Installs & tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d9b411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    import mlflow\n",
    "except ImportError:\n",
    "    !pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c65f9c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    import dotenv\n",
    "except ImportError:\n",
    "    !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0c3f67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Kaggle environment. Skipping Kaggle secrets.\n",
      "Trying to load HF_TOKEN from .env.\n",
      "Success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "# Log into huggingface via Kaggle Secrets or .env\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import huggingface_hub\n",
    "\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "    user_secrets = UserSecretsClient()\n",
    "    HF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Not Kaggle environment. Skipping Kaggle secrets.\")\n",
    "    print(\"Trying to load HF_TOKEN from .env.\")\n",
    "    load_dotenv()\n",
    "    HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "    print(\"Success!\")\n",
    "\n",
    "huggingface_hub.login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a0467",
   "metadata": {},
   "source": [
    "# Choose notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be91836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "## CHOOSE MODEL PARAMETERS #################################################\n",
    "\n",
    "MODEL_NAME_POSTFIX='splitting-by-query'\n",
    "\n",
    "NAME_MODEL_NAME = 'cointegrated/rubert-tiny' # 'DeepPavlov/distilrubert-tiny-cased-conversational-v1'\n",
    "DESCRIPTION_MODEL_NAME = 'cointegrated/rubert-tiny'\n",
    "\n",
    "DATA_PATH = 'data/'\n",
    "RESULTS_DIR = 'train_results/'\n",
    "\n",
    "# BATCH_SIZE=60 # uses 14.5GiB of 1 GPU\n",
    "# NUM_WORKERS=2 # TODO: use multiple GPU, tune number of workers\n",
    "# NUM_DEBUG_SAMPLES=None\n",
    "# EPOCHS=10 # epochs > 8 => overfit; NOTE: can train for longer since we take best validation checkpoint anyway\n",
    "\n",
    "BATCH_SIZE=1\n",
    "NUM_WORKERS=0\n",
    "NUM_DEBUG_SAMPLES=2\n",
    "EPOCHS=2\n",
    "\n",
    "PRELOAD_MODEL_NAME = 'cc12m_rubert_tiny_ep_1.pt' # preload ruclip\n",
    "# PRELOAD_MODEL_NAME = None\n",
    "\n",
    "POS_WEIGHT = 4.0 # TODO: infer from data\n",
    "\n",
    "# USE_ALL_TRAIN_PAIRS = False\n",
    "# MAX_SAMPLES_PER_EPOCH = None\n",
    "\n",
    "USE_ALL_TRAIN_PAIRS = True\n",
    "MAX_SAMPLES_PER_EPOCH = 2_500\n",
    "# MAX_SAMPLES_PER_EPOCH = 2_500 * 12\n",
    "\n",
    "DROPOUT = 0.5\n",
    "# DROPOUT = None\n",
    "\n",
    "# BEST_CKPT_METRIC = 'f1'\n",
    "BEST_CKPT_METRIC = 'pos_acc'\n",
    "\n",
    "VALIDATION_SPLIT=.05\n",
    "TEST_SPLIT=.1\n",
    "RANDOM_SEED=42\n",
    "LR=9e-5\n",
    "MOMENTUM=0.9\n",
    "WEIGHT_DECAY=1e-2\n",
    "CONTRASTIVE_MARGIN=1.5\n",
    "CONTRASTIVE_THRESHOLD=0.3\n",
    "SHEDULER_PATIENCE=3 # in epochs\n",
    "\n",
    "DEVICE='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "880a333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHOOSE DATA #########################################################\n",
    "\n",
    "DATA_PATH=  'data/'\n",
    "SOURCE_TABLE_NAME = 'tables_OZ_geo_5500/processed/OZ_geo_5500.csv'\n",
    "\n",
    "# --- Load source_df and pairwise_mapping_df from Parquet ---\n",
    "SOURCE_TABLE_NAME = 'tables_OZ_geo_5500/processed/OZ_geo_5500.csv'\n",
    "PAIRWISE_TABLE_NAME = 'tables_OZ_geo_5500/processed/regex-pairwise-groups/regex-pairwise-groups_num-queries=20_patterns-dict-hash=6dbf9b3ef9568e60cd959f87be7e3b26.parquet'\n",
    "IMG_DATASET_NAME = 'images_OZ_geo_5500'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14b5eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOGGING PARAMS ######################################################################\n",
    "\n",
    "# MLFLOW_URI = \"http://176.56.185.96:5000\"\n",
    "# MLFLOW_URI = \"http://localhost:5000\"\n",
    "MLFLOW_URI = None\n",
    "\n",
    "MLFLOW_EXPERIMENT = \"siamese/1fold\"\n",
    "\n",
    "TELEGRAM_TOKEN = None\n",
    "# TELEGRAM_TOKEN = '' # set token to get notifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b40bc83",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00017085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from timm import create_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "# import transformers\n",
    "# from transformers import DistilBertModel, DistilBertConfig, DistilBertTokenizer,\\\n",
    "#         get_linear_schedule_with_warmup\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# import json\n",
    "# from itertools import product\n",
    "\n",
    "# import datasets\n",
    "# from datasets import Dataset, concatenate_datasets\n",
    "# import argparse\n",
    "import requests\n",
    "\n",
    "# from io import BytesIO\n",
    "# from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "# import more_itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import mlflow\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3494173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tg_report(text, token=None) -> None:\n",
    "    method = 'sendMessage'\n",
    "    chat_id = 324956476\n",
    "    _ = requests.post(\n",
    "            url='https://api.telegram.org/bot{0}/{1}'.format(token, method),\n",
    "            data={'chat_id': chat_id, 'text': text} \n",
    "        ).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34706f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuCLIPtiny(nn.Module):\n",
    "    def __init__(self, name_model_name):\n",
    "        super().__init__()\n",
    "        self.visual = create_model('convnext_tiny',\n",
    "                                   pretrained=False, # TODO: берём претрейн\n",
    "                                   num_classes=0,\n",
    "                                   in_chans=3)  # out 768\n",
    "\n",
    "        self.transformer = AutoModel.from_pretrained(name_model_name)\n",
    "        name_model_output_shape = self.transformer.config.hidden_size  # dynamically get hidden size\n",
    "        self.final_ln = torch.nn.Linear(name_model_output_shape, 768)  # now uses the transformer hidden size\n",
    "        self.logit_scale = torch.nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        return self.visual.stem[0].weight.dtype\n",
    "\n",
    "    def encode_image(self, image):\n",
    "        return self.visual(image.type(self.dtype))\n",
    "\n",
    "    def encode_text(self, input_ids, attention_mask):\n",
    "        x = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = x.last_hidden_state[:, 0, :]\n",
    "        x = self.final_ln(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, image, input_ids, attention_mask):\n",
    "        image_features = self.encode_image(image)\n",
    "        text_features = self.encode_text(input_ids, attention_mask)\n",
    "\n",
    "        # normalized features\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # cosine similarity as logits\n",
    "        logit_scale = self.logit_scale.exp()\n",
    "        logits_per_image = logit_scale * image_features @ text_features.t()\n",
    "        logits_per_text = logits_per_image.t()\n",
    "\n",
    "        return logits_per_image, logits_per_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84518fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        _convert_image_to_rgb,\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]), ])\n",
    "\n",
    "def _convert_image_to_rgb(image):\n",
    "    return image.convert(\"RGB\")\n",
    "\n",
    "class Tokenizers:\n",
    "    def __init__(self):\n",
    "        self.name_tokenizer = AutoTokenizer.from_pretrained(NAME_MODEL_NAME)\n",
    "        self.desc_tokenizer = AutoTokenizer.from_pretrained(DESCRIPTION_MODEL_NAME)\n",
    "\n",
    "    def tokenize_name(self, texts, max_len=77):\n",
    "        tokenized = self.name_tokenizer.batch_encode_plus(texts,\n",
    "                                                     truncation=True,\n",
    "                                                     add_special_tokens=True,\n",
    "                                                     max_length=max_len,\n",
    "                                                     padding='max_length',\n",
    "                                                     return_attention_mask=True,\n",
    "                                                     return_tensors='pt')\n",
    "        return torch.stack([tokenized[\"input_ids\"], tokenized[\"attention_mask\"]])\n",
    "    \n",
    "    def tokenize_description(self, texts, max_len=77):\n",
    "        tokenized = self.desc_tokenizer(texts,\n",
    "                                        truncation=True,\n",
    "                                        add_special_tokens=True,\n",
    "                                        max_length=max_len,\n",
    "                                        padding='max_length',\n",
    "                                        return_attention_mask=True,\n",
    "                                        return_tensors='pt')\n",
    "        return torch.stack([tokenized[\"input_ids\"], tokenized[\"attention_mask\"]])\n",
    "\n",
    "class SiameseRuCLIPDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df=None, labels=None, df_path=None, images_dir=DATA_PATH+'images/'):\n",
    "        # loads data either from path using `df_path` or directly from `df` argument\n",
    "        self.df = pd.read_csv(df_path) if df_path is not None else df\n",
    "        self.labels = labels\n",
    "        self.images_dir = images_dir\n",
    "        self.tokenizers = Tokenizers()\n",
    "        self.transform = get_transform()\n",
    "        # \n",
    "        self.max_len = 77\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        name_tokens = self.tokenizers.tokenize_name([str(row.name_first), \n",
    "                                               str(row.name_second)], max_len=self.max_len)\n",
    "        name_first = name_tokens[:, 0, :] # [input_ids, attention_mask]\n",
    "        name_second = name_tokens[:, 1, :]\n",
    "        desc_tokens = self.tokenizers.tokenize_description([str(row.description_first), \n",
    "                                               str(row.description_second)])\n",
    "        desc_first = desc_tokens[:, 0, :] # [input_ids, attention_mask]\n",
    "        desc_second = desc_tokens[:, 1, :]\n",
    "        im_first = cv2.imread(os.path.join(self.images_dir, row.image_name_first))\n",
    "        im_first = cv2.cvtColor(im_first, cv2.COLOR_BGR2RGB)\n",
    "        im_first = Image.fromarray(im_first)\n",
    "        im_first = self.transform(im_first)\n",
    "        im_second = cv2.imread(os.path.join(self.images_dir, row.image_name_second))\n",
    "        im_second = cv2.cvtColor(im_second, cv2.COLOR_BGR2RGB)\n",
    "        im_second = Image.fromarray(im_second)\n",
    "        im_second = self.transform(im_second)\n",
    "        label = self.labels[idx]\n",
    "        return im_first, name_first, desc_first, im_second, name_second, desc_second, label\n",
    "\n",
    "    def __len__(self,):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2d263be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "class SiameseRuCLIP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 device: str,\n",
    "                 name_model_name: str,\n",
    "                 description_model_name: str,\n",
    "                 preload_model_name: str = None,\n",
    "                 models_dir: str = None,\n",
    "                 dropout: float = None):\n",
    "        \"\"\"\n",
    "        Initializes the SiameseRuCLIP model.\n",
    "        Required parameters:\n",
    "          - models_dir: directory containing saved checkpoints.\n",
    "          - name_model_name: model name for text (name) branch.\n",
    "          - description_model_name: model name for description branch.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        device = torch.device(device)\n",
    "\n",
    "        # Initialize RuCLIPtiny\n",
    "        self.ruclip = RuCLIPtiny(name_model_name)\n",
    "        if preload_model_name is not None:\n",
    "            std = torch.load(\n",
    "                os.path.join(models_dir, preload_model_name),\n",
    "                weights_only=True,\n",
    "                map_location=device\n",
    "            )\n",
    "            self.ruclip.load_state_dict(std)\n",
    "            self.ruclip.eval()\n",
    "        self.ruclip = self.ruclip.to(device)\n",
    "\n",
    "        # Initialize the description transformer\n",
    "        self.description_transformer = AutoModel.from_pretrained(description_model_name)\n",
    "        self.description_transformer = self.description_transformer.to(device)\n",
    "\n",
    "        # Determine dimensionality\n",
    "        vision_dim = self.ruclip.visual.num_features\n",
    "        name_dim = self.ruclip.final_ln.out_features\n",
    "        desc_dim = self.description_transformer.config.hidden_size\n",
    "        self.hidden_dim = vision_dim + name_dim + desc_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define MLP head with optional dropout\n",
    "        layers = [\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            *( [nn.Dropout(self.dropout)] if self.dropout is not None else [] ),\n",
    "            nn.Linear(self.hidden_dim // 2, self.hidden_dim // 4),\n",
    "        ]\n",
    "        self.head = nn.Sequential(*layers).to(device)\n",
    "\n",
    "\n",
    "    def encode_image(self, image):\n",
    "        return self.ruclip.encode_image(image)\n",
    "\n",
    "    def encode_name(self, name):\n",
    "        return self.ruclip.encode_text(name[:, 0, :], name[:, 1, :])\n",
    "\n",
    "    def encode_description(self, desc):\n",
    "        last_hidden_states = self.description_transformer(desc[:, 0, :], desc[:, 1, :]).last_hidden_state\n",
    "        attention_mask = desc[:, 1, :]\n",
    "        return average_pool(last_hidden_states, attention_mask)\n",
    "\n",
    "    def get_final_embedding(self, im, name, desc):\n",
    "        image_emb = self.encode_image(im)\n",
    "        name_emb = self.encode_name(name)\n",
    "        desc_emb = self.encode_description(desc)\n",
    "\n",
    "        # Concatenate the embeddings and forward through the head\n",
    "        combined_emb = torch.cat([image_emb, name_emb, desc_emb], dim=1)\n",
    "        final_embedding = self.head(combined_emb)\n",
    "        return final_embedding\n",
    "\n",
    "    def forward(self, im1, name1, desc1, im2, name2, desc2):\n",
    "        out1 = self.get_final_embedding(im1, name1, desc1)\n",
    "        out2 = self.get_final_embedding(im2, name2, desc2)\n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "987d1ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # old\n",
    "# class ContrastiveLoss(torch.nn.Module):\n",
    "#     def __init__(self, margin=2.0):\n",
    "#         super(ContrastiveLoss, self).__init__()\n",
    "#         self.margin = margin\n",
    "        \n",
    "#     def __name__(self,):\n",
    "#         return 'ContrastiveLoss'\n",
    "\n",
    "#     def forward(self, output1, output2, label):\n",
    "#         euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "#         pos = (1-label) * torch.pow(euclidean_distance, 2)\n",
    "#         neg = label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "#         loss_contrastive = torch.mean( pos + neg )\n",
    "#         return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36cc0798",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin: float = 1.5, pos_weight: float = 4.0):\n",
    "        super().__init__()\n",
    "        self.margin      = margin\n",
    "        self.pos_weight  = pos_weight\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        d   = F.pairwise_distance(output1, output2)\n",
    "        pos = (1 - label) * d.pow(2)                            # duplicates (label==0)\n",
    "        neg = label * F.relu(self.margin - d).pow(2)            # different (label==1)\n",
    "        return (self.pos_weight * pos + neg).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfe81dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot epoch after each train epoch in `train()`\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def plot_epoch(loss_history, filename=\"data/runs_artifacts/epoch_loss.png\") -> None:\n",
    "    Path(filename).parent.mkdir(parents=True, exist_ok=True)\n",
    "    display.clear_output(wait=True)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.title(\"Training loss\")\n",
    "    plt.xlabel(\"Iteration number\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(loss_history, 'b')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)  # Save the plot to a file\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9c6281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pair(output1, output2, target, threshold):\n",
    "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "    # меньше границы, там где будет True — конкуренты\n",
    "    cond = euclidean_distance < threshold\n",
    "    pos_sum = 0\n",
    "    neg_sum = 0\n",
    "    pos_acc = 0\n",
    "    neg_acc = 0\n",
    "\n",
    "    for i in range(len(cond)):\n",
    "        # 1 значит не конкуренты\n",
    "        if target[i]:\n",
    "            neg_sum+=1\n",
    "            # 0 в cond значит дальше друг от друга чем threshold\n",
    "            if not cond[i]:\n",
    "                neg_acc+=1\n",
    "        elif not target[i]:\n",
    "            pos_sum+=1\n",
    "            if cond[i]:\n",
    "                pos_acc+=1\n",
    "\n",
    "    return pos_acc, pos_sum, neg_acc, neg_sum\n",
    "\n",
    "def predict(out1, out2, threshold=CONTRASTIVE_THRESHOLD):\n",
    "    # вернёт 1 если похожи\n",
    "    return F.pairwise_distance(out1, out2) < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "319a25ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "import mlflow\n",
    "from copy import deepcopy\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from pathlib import Path\n",
    "\n",
    "def validation(model,\n",
    "               criterion,\n",
    "               data_loader,\n",
    "               epoch,\n",
    "               device='cpu',\n",
    "               split_name='validation',\n",
    "               threshold=None,\n",
    "               margin=1.5,\n",
    "               steps=200,\n",
    "               metric='f1'):\n",
    "    \"\"\"\n",
    "    Runs one pass over `data_loader`, returning:\n",
    "      pos_acc, neg_acc, avg_acc, f1, avg_loss, best_thr\n",
    "\n",
    "    threshold sweep: if threshold is None, tests `steps` values in [0, margin]\n",
    "    and picks the one that maximises either:\n",
    "      - F1              if metric=='f1'\n",
    "      - positive accuracy if metric=='pos_acc'\n",
    "    \"\"\"\n",
    "    assert metric in ('f1', 'pos_acc'), \"metric must be 'f1' or 'pos_acc'\"\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_d, all_lbl = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            im1, n1, d1, im2, n2, d2, lbl = [t.to(device) for t in batch]\n",
    "            out1, out2 = model(im1, n1, d1, im2, n2, d2)\n",
    "            total_loss += criterion(out1, out2, lbl).item()\n",
    "            all_d.append(F.pairwise_distance(out1, out2).cpu())\n",
    "            all_lbl.append(lbl.cpu())\n",
    "\n",
    "    distances = torch.cat(all_d)\n",
    "    labels    = torch.cat(all_lbl)               # 0 = duplicate (positive), 1 = different (negative)\n",
    "    avg_loss  = total_loss / len(data_loader)\n",
    "\n",
    "    # === threshold sweep ===\n",
    "    if threshold is None:\n",
    "        grid = np.linspace(0.0, margin, steps)\n",
    "        best_val, best_thr = -1.0, 0.0\n",
    "        y_true = (labels.numpy() == 0).astype(int)   # 1 = positive\n",
    "        for t in grid:\n",
    "            y_pred = (distances.numpy() < t).astype(int)\n",
    "            if metric == 'f1':\n",
    "                val = f1_score(y_true, y_pred, zero_division=0)\n",
    "            else:  # metric == 'pos_acc'\n",
    "                # positive accuracy = TP / P\n",
    "                pos_mask = (y_true == 1)\n",
    "                val = (y_pred[pos_mask] == 1).mean() if pos_mask.sum() > 0 else 0.0\n",
    "            if val > best_val:\n",
    "                best_val, best_thr = val, t\n",
    "        threshold = best_thr\n",
    "    else:\n",
    "        best_thr = threshold\n",
    "\n",
    "    # === final metrics at chosen threshold ===\n",
    "    preds    = (distances < threshold).long()\n",
    "    pos_mask = (labels == 0)\n",
    "    neg_mask = (labels == 1)\n",
    "\n",
    "    pos_acc = (preds[pos_mask] == 1).float().mean().item() if pos_mask.any() else 0.0\n",
    "    neg_acc = (preds[neg_mask] == 0).float().mean().item() if neg_mask.any() else 0.0\n",
    "    avg_acc = (pos_acc + neg_acc) / 2.0\n",
    "    f1      = f1_score((labels.numpy() == 0).astype(int),\n",
    "                       preds.numpy(), zero_division=0)\n",
    "\n",
    "    # log to Telegram / console\n",
    "    report = (f\"[{split_name}] Epoch {epoch} – \"\n",
    "              f\"loss: {avg_loss:.4f}, \"\n",
    "              f\"P Acc: {pos_acc:.3f}, \"\n",
    "              f\"N Acc: {neg_acc:.3f}, \"\n",
    "              f\"Avg Acc: {avg_acc:.3f}, \"\n",
    "              f\"F1: {f1:.3f}, \"\n",
    "              f\"thr*: {threshold:.3f} \"\n",
    "              f\"(optimised: {metric})\")\n",
    "    print(report)\n",
    "    make_tg_report(report, TELEGRAM_TOKEN)\n",
    "\n",
    "    # log to MLflow under the chosen metric\n",
    "    if MLFLOW_URI and split_name == 'validation':\n",
    "        if metric == 'f1':\n",
    "            mlflow.log_metric(\"valid_f1_score\", f1, step=epoch)\n",
    "        else:\n",
    "            mlflow.log_metric(\"valid_pos_accuracy\", pos_acc, step=epoch)\n",
    "\n",
    "    return pos_acc, neg_acc, avg_acc, f1, avg_loss, threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff968d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from datetime import timedelta\n",
    "\n",
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion,\n",
    "          epochs_num,\n",
    "          train_loader,\n",
    "          valid_loader=None,\n",
    "          device='cpu',\n",
    "          print_epoch=False,\n",
    "          models_dir=None,\n",
    "          metric='f1'):\n",
    "    \"\"\"\n",
    "    Trains for `epochs_num` epochs, using `validation(..., metric=metric)` each epoch.\n",
    "    Uses the same `metric` to step the LR scheduler and to pick the best checkpoint.\n",
    "\n",
    "    Returns:\n",
    "      train_losses, val_losses, best_valid_metric, best_weights, thr_history\n",
    "    \"\"\"\n",
    "    assert metric in ('f1', 'pos_acc'), \"metric must be 'f1' or 'pos_acc'\"\n",
    "\n",
    "    model.to(device)\n",
    "    train_losses, val_losses, thr_history = [], [], []\n",
    "    best_valid_metric, best_threshold = float('-inf'), None\n",
    "    best_weights = None\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode=\"max\",\n",
    "        factor=0.1,\n",
    "        patience=SHEDULER_PATIENCE,\n",
    "        threshold=1e-4,\n",
    "        threshold_mode='rel'\n",
    "    )\n",
    "\n",
    "    if models_dir:\n",
    "        Path(models_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for epoch in range(1, epochs_num + 1):\n",
    "        # ---- training ----\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            im1, n1, d1, im2, n2, d2, lbl = [t.to(device) for t in batch]\n",
    "            optimizer.zero_grad()\n",
    "            out1, out2 = model(im1, n1, d1, im2, n2, d2)\n",
    "            loss = criterion(out1, out2, lbl)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "        train_losses.append(total_train_loss / len(train_loader))\n",
    "\n",
    "        # ---- validation & checkpointing ----\n",
    "        if print_epoch and valid_loader is not None:\n",
    "            pos_acc, neg_acc, avg_acc, f1_val, val_loss, val_thr = validation(\n",
    "                model,\n",
    "                criterion,\n",
    "                valid_loader,\n",
    "                epoch,\n",
    "                device=device,\n",
    "                split_name='validation',\n",
    "                threshold=None,\n",
    "                margin=CONTRASTIVE_MARGIN,\n",
    "                steps=200,\n",
    "                metric=metric\n",
    "            )\n",
    "            val_losses.append(val_loss)\n",
    "            thr_history.append(val_thr)\n",
    "\n",
    "            # pick the metric value to step & compare\n",
    "            cur_metric = pos_acc if metric == 'pos_acc' else f1_val\n",
    "            scheduler.step(cur_metric)\n",
    "\n",
    "            # save checkpoint every epoch if requested\n",
    "            if models_dir:\n",
    "                torch.save(model.state_dict(),\n",
    "                           Path(models_dir) / f\"checkpoint_epoch_{epoch}.pt\")\n",
    "\n",
    "            # update best if improved\n",
    "            if cur_metric > best_valid_metric:\n",
    "                best_valid_metric = cur_metric\n",
    "                best_threshold     = val_thr\n",
    "                best_weights       = deepcopy(model.state_dict())\n",
    "\n",
    "        print(f'Epoch {epoch} done.')\n",
    "\n",
    "    print(f\"Best validation {metric}: {best_valid_metric:.3f}  (thr={best_threshold:.3f})\")\n",
    "    return train_losses, val_losses, best_valid_metric, best_weights, thr_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481940bc",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e226754b",
   "metadata": {},
   "source": [
    "## Download data from HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b8cde88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e60d31b80047729598a8e1a0003c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/anton/marketplace/clip-siamese/data'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download models' weights & text/image datasets\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_ID = \"INDEEPA/clip-siamese\"\n",
    "LOCAL_DIR = Path(\"data/train_results\")\n",
    "LOCAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=REPO_ID,\n",
    "    repo_type='dataset',\n",
    "    local_dir='data',\n",
    "    allow_patterns=[\n",
    "        \"train_results/cc12m*.pt\",\n",
    "        SOURCE_TABLE_NAME, PAIRWISE_TABLE_NAME,\n",
    "        f\"{IMG_DATASET_NAME}.zip\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "# The following shell command was removed for script compatibility:\n",
    "# !unzip -n -q data/{IMG_DATASET_NAME}.zip -d data/\n",
    "\n",
    "# If you need to unzip in Python, use:\n",
    "# import zipfile\n",
    "# with zipfile.ZipFile(f\"data/{IMG_DATASET_NAME}.zip\", 'r') as zip_ref:\n",
    "#     zip_ref.extractall(\"data/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be5962fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sku',\n",
       " 'description',\n",
       " 'image_url',\n",
       " 'name',\n",
       " 'category',\n",
       " 'схема',\n",
       " 'brand',\n",
       " 'niche',\n",
       " 'seller',\n",
       " 'balance_fbo',\n",
       " 'balance_fbs',\n",
       " 'warehouses_count',\n",
       " 'comments',\n",
       " 'final_price',\n",
       " 'max_price',\n",
       " 'min_price',\n",
       " 'average_price',\n",
       " 'median_price',\n",
       " 'membership_card_price',\n",
       " 'sales',\n",
       " 'revenue',\n",
       " 'revenue_potential',\n",
       " 'revenue_average',\n",
       " 'lost_profit',\n",
       " 'lost_profit_percent',\n",
       " 'url',\n",
       " 'thumb',\n",
       " 'pics_count',\n",
       " 'has_video',\n",
       " 'first_date',\n",
       " 'days_in_website',\n",
       " 'days_in_stock',\n",
       " 'days_with_sales',\n",
       " 'average_if_in_stock',\n",
       " 'rating',\n",
       " 'fbs',\n",
       " 'base_price',\n",
       " 'category_position',\n",
       " 'categories_last_count',\n",
       " 'sales_per_day_average',\n",
       " 'sales.1',\n",
       " 'frozen_stocks',\n",
       " 'frozen_stocks_cost',\n",
       " 'frozen_stocks_percent',\n",
       " 'balance',\n",
       " 'image_name']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_df = pd.read_csv(DATA_PATH + SOURCE_TABLE_NAME)\n",
    "source_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c50327e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sku_query', 'sku_pos', 'sku_hard_neg', 'sku_soft_neg']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_mapping_df = pd.read_parquet(DATA_PATH + PAIRWISE_TABLE_NAME)\n",
    "pairwise_mapping_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70179151",
   "metadata": {},
   "source": [
    "# Cluster soft negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32453eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'embeddings/OZ_geo_5500/OZ_geo_5500_name-and-description_embeddings_num-rows=2.parquet'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'embeddings/OZ_geo_5500/OZ_geo_5500_name-and-description_embeddings_num-rows=5562.parquet'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List embeddings files in repo\n",
    "FILTER_STRING = 'name-and-description_embeddings'\n",
    "\n",
    "from huggingface_hub import list_repo_files\n",
    "\n",
    "emb_files = [name for name in list_repo_files(\"INDEEPA/clip-siamese\", repo_type=\"dataset\") if FILTER_STRING in name and \"OZ_geo_5500\" in name]\n",
    "for file in emb_files:\n",
    "    display(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c67ed0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suggest the correct path to the embedding file based on the context and previous file saving logic\n",
    "CHOSEN_EMBEDDING_FILE = 'OZ_geo_5500_name-and-description_embeddings_num-rows=5562.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3586cf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded embedding file to:\n",
      "data/embeddings/OZ_geo_5500/OZ_geo_5500_name-and-description_embeddings_num-rows=5562.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>name_desc_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1871769771</td>\n",
       "      <td>[-0.020089346915483475, -0.05487045273184776, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1679550303</td>\n",
       "      <td>[-0.00418242160230875, -0.04088427498936653, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1200553001</td>\n",
       "      <td>[-0.023978281766176224, -0.05447990819811821, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>922231521</td>\n",
       "      <td>[-0.024106157943606377, -0.053567297756671906,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>922230517</td>\n",
       "      <td>[-0.02229023538529873, -0.05309479311108589, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sku                                      name_desc_emb\n",
       "0  1871769771  [-0.020089346915483475, -0.05487045273184776, ...\n",
       "1  1679550303  [-0.00418242160230875, -0.04088427498936653, 0...\n",
       "2  1200553001  [-0.023978281766176224, -0.05447990819811821, ...\n",
       "3   922231521  [-0.024106157943606377, -0.053567297756671906,...\n",
       "4   922230517  [-0.02229023538529873, -0.05309479311108589, -..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import pandas as pd\n",
    "\n",
    "# Download the chosen embedding file from HuggingFace Hub to DATA_PATH\n",
    "from pathlib import Path\n",
    "\n",
    "downloaded_emb_file = hf_hub_download(\n",
    "    repo_id=\"INDEEPA/clip-siamese\",\n",
    "    repo_type=\"dataset\",\n",
    "    filename=f'embeddings/OZ_geo_5500/{CHOSEN_EMBEDDING_FILE}',\n",
    "    local_dir=DATA_PATH,\n",
    ")\n",
    "\n",
    "print(f\"Downloaded embedding file to:\\n{downloaded_emb_file}\")\n",
    "emb_table = pd.read_parquet(downloaded_emb_file)\n",
    "emb_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2de7bc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster label counts:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cluster_id</th>\n",
       "      <th>-1</th>\n",
       "      <th>396</th>\n",
       "      <th>1</th>\n",
       "      <th>98</th>\n",
       "      <th>216</th>\n",
       "      <th>389</th>\n",
       "      <th>383</th>\n",
       "      <th>159</th>\n",
       "      <th>495</th>\n",
       "      <th>269</th>\n",
       "      <th>...</th>\n",
       "      <th>429</th>\n",
       "      <th>418</th>\n",
       "      <th>12</th>\n",
       "      <th>303</th>\n",
       "      <th>138</th>\n",
       "      <th>424</th>\n",
       "      <th>373</th>\n",
       "      <th>490</th>\n",
       "      <th>428</th>\n",
       "      <th>459</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1244</td>\n",
       "      <td>64</td>\n",
       "      <td>47</td>\n",
       "      <td>42</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 498 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "cluster_id  -1     396   1     98    216   389   383   159   495   269  ...  \\\n",
       "count       1244    64    47    42    38    30    29    27    26    25  ...   \n",
       "\n",
       "cluster_id   429   418   12    303   138   424   373   490   428   459  \n",
       "count          5     5     5     5     5     5     5     5     5     5  \n",
       "\n",
       "[1 rows x 498 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import HDBSCAN\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the embeddings as a numpy array\n",
    "embeddings = np.stack(emb_table['name_desc_emb'].values)\n",
    "\n",
    "# Run HDBSCAN clustering using sklearn's implementation\n",
    "# Use coarser clustering: increase min_cluster_size and set min_samples for more robust, larger clusters\n",
    "clusterer = HDBSCAN(\n",
    "    min_samples=2,\n",
    "    metric='cosine',\n",
    ")\n",
    "\n",
    "cluster_labels = clusterer.fit_predict(embeddings)\n",
    "\n",
    "# Add cluster labels to the emb_table and assign to cluster_emb_table\n",
    "cluster_emb_table = emb_table.copy()\n",
    "cluster_emb_table['cluster_id'] = cluster_labels\n",
    "\n",
    "# Print cluster label counts\n",
    "print(\"Cluster label counts:\")\n",
    "display(cluster_emb_table['cluster_id'].value_counts().to_frame().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a02aeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster IDs with size > 20:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cluster_id</th>\n",
       "      <th>-1</th>\n",
       "      <th>396</th>\n",
       "      <th>1</th>\n",
       "      <th>98</th>\n",
       "      <th>216</th>\n",
       "      <th>389</th>\n",
       "      <th>383</th>\n",
       "      <th>159</th>\n",
       "      <th>495</th>\n",
       "      <th>269</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>492</th>\n",
       "      <th>102</th>\n",
       "      <th>198</th>\n",
       "      <th>427</th>\n",
       "      <th>163</th>\n",
       "      <th>181</th>\n",
       "      <th>384</th>\n",
       "      <th>239</th>\n",
       "      <th>116</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1244</td>\n",
       "      <td>64</td>\n",
       "      <td>47</td>\n",
       "      <td>42</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "cluster_id  -1     396   1     98    216   389   383   159   495   269  ...  \\\n",
       "count       1244    64    47    42    38    30    29    27    26    25  ...   \n",
       "\n",
       "cluster_id   19    492   102   198   427   163   181   384   239   116  \n",
       "count         24    23    23    22    22    21    21    21    21    21  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print cluster ids with size > N\n",
    "N = 20  # You can change N to any desired threshold\n",
    "cluster_counts = cluster_emb_table['cluster_id'].value_counts()\n",
    "large_clusters = cluster_counts[cluster_counts > N].to_frame()\n",
    "print(f\"Cluster IDs with size > {N}:\")\n",
    "display(large_clusters.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "74754845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKUs in cluster 396:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1867702733,\n",
       " 1855727917,\n",
       " 1849927012,\n",
       " 1849926941,\n",
       " 1757684675,\n",
       " 1747398740,\n",
       " 1726148392,\n",
       " 1726148384,\n",
       " 1596943291,\n",
       " 1596943084]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print SKUs for a given CLUSTER_ID\n",
    "CLUSTER_ID = 396  # Change this to the desired cluster id\n",
    "\n",
    "skus_in_cluster = cluster_emb_table.loc[cluster_emb_table['cluster_id'] == CLUSTER_ID, 'sku']\n",
    "print(f\"SKUs in cluster {CLUSTER_ID}:\")\n",
    "display(skus_in_cluster.tolist()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5dda22",
   "metadata": {},
   "source": [
    "# Make pairwise dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "51377883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_query_groups_adaptive(\n",
    "    mapping_df: pd.DataFrame,\n",
    "    test_size: float = 0.2,\n",
    "    val_size: float = 0.05,\n",
    "    random_state: int = 42,\n",
    "    min_positives_for_3way: int = 6  # minimum positives (including query) for 3-way split\n",
    "):\n",
    "    \"\"\"\n",
    "    Adaptive splitting based on number of positives:\n",
    "    - ≥6 positives: train/val/test split\n",
    "    - 3-5 positives: train/test split (no validation)\n",
    "    - <3 positives: all in test split only\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    split_rows = []\n",
    "\n",
    "    for _, row in mapping_df.iterrows():\n",
    "        q = row['sku_query']\n",
    "        total_positives = len(row['sku_pos'])  # includes query SKU\n",
    "        \n",
    "        pos_without_query = set(row['sku_pos']) - {q}\n",
    "        hard_neg = set(row['sku_hard_neg']) - {q}\n",
    "        soft_neg = set(row['sku_soft_neg']) - {q}\n",
    "\n",
    "        def split_list(lst, test_frac, val_frac=None):\n",
    "            lst = np.array(list(lst))\n",
    "            n = len(lst)\n",
    "            if val_frac is None:  # 2-way split\n",
    "                n_test = int(np.ceil(test_frac * n))\n",
    "                idx = rng.permutation(n)\n",
    "                test_idx = idx[:n_test]\n",
    "                train_idx = idx[n_test:]\n",
    "                return lst[train_idx].tolist(), [], lst[test_idx].tolist()\n",
    "            else:  # 3-way split\n",
    "                n_test = int(np.ceil(test_frac * n))\n",
    "                n_val = int(np.ceil(val_frac * n))\n",
    "                idx = rng.permutation(n)\n",
    "                test_idx = idx[:n_test]\n",
    "                val_idx = idx[n_test:n_test+n_val]\n",
    "                train_idx = idx[n_test+n_val:]\n",
    "                return lst[train_idx].tolist(), lst[val_idx].tolist(), lst[test_idx].tolist()\n",
    "\n",
    "        if total_positives >= min_positives_for_3way:\n",
    "            # 3-way split: train/val/test\n",
    "            pos_train, pos_val, pos_test = split_list(pos_without_query, test_size, val_size)\n",
    "            hard_train, hard_val, hard_test = split_list(hard_neg, test_size, val_size)\n",
    "            soft_train, soft_val, soft_test = split_list(soft_neg, test_size, val_size)\n",
    "            pos_test.append(q)\n",
    "            \n",
    "            splits_to_create = ['train', 'val', 'test']\n",
    "            pos_lists = [pos_train, pos_val, pos_test]\n",
    "            hard_lists = [hard_train, hard_val, hard_test]\n",
    "            soft_lists = [soft_train, soft_val, soft_test]\n",
    "            \n",
    "        elif total_positives >= 3:\n",
    "            # 2-way split: train/test only (no validation)\n",
    "            pos_train, _, pos_test = split_list(pos_without_query, test_size)\n",
    "            hard_train, _, hard_test = split_list(hard_neg, test_size)\n",
    "            soft_train, _, soft_test = split_list(soft_neg, test_size)\n",
    "            pos_test.append(q)\n",
    "            \n",
    "            splits_to_create = ['train', 'test']\n",
    "            pos_lists = [pos_train, pos_test]\n",
    "            hard_lists = [hard_train, hard_test]\n",
    "            soft_lists = [soft_train, soft_test]\n",
    "            \n",
    "        else:\n",
    "            # Too few positives: put everything in test split only\n",
    "            splits_to_create = ['test']\n",
    "            pos_lists = [list(pos_without_query) + [q]]\n",
    "            hard_lists = [list(hard_neg)]\n",
    "            soft_lists = [list(soft_neg)]\n",
    "\n",
    "        # Create the split rows\n",
    "        for split_name, pos_list, hard_list, soft_list in zip(\n",
    "            splits_to_create, pos_lists, hard_lists, soft_lists\n",
    "        ):\n",
    "            split_rows.append({\n",
    "                'sku_query': q,\n",
    "                'split': split_name,\n",
    "                'sku_pos': pos_list,\n",
    "                'sku_hard_neg': hard_list,\n",
    "                'sku_soft_neg': soft_list\n",
    "            })\n",
    "\n",
    "    split_df = pd.DataFrame(split_rows)\n",
    "    split_dict = {\n",
    "        split: split_df[split_df['split'] == split].reset_index(drop=True)\n",
    "        for split in ['train', 'val', 'test'] if split in split_df['split'].values\n",
    "    }\n",
    "    return split_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "763373ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_query</th>\n",
       "      <th>split</th>\n",
       "      <th>sku_pos</th>\n",
       "      <th>sku_hard_neg</th>\n",
       "      <th>sku_soft_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1871769771</td>\n",
       "      <td>test</td>\n",
       "      <td>[467420540, 1871769771]</td>\n",
       "      <td>[1418084594, 1573142945, 1536520050, 1573135817]</td>\n",
       "      <td>[1899881468, 1290396077, 1597431764, 165269677...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200553001</td>\n",
       "      <td>test</td>\n",
       "      <td>[945075396, 1436509994, 1436449707, 1438364324...</td>\n",
       "      <td>[1499532091, 963112482, 1422204647, 1122827873...</td>\n",
       "      <td>[1878150702, 1901123430, 1595672507, 679265327...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>922231521</td>\n",
       "      <td>test</td>\n",
       "      <td>[1436509994, 1158222448, 1081199697, 490461399...</td>\n",
       "      <td>[1001260979, 1802254834, 1252814277, 805782980...</td>\n",
       "      <td>[1032263980, 879403681, 1816716304, 1630407222...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>922230517</td>\n",
       "      <td>test</td>\n",
       "      <td>[600803111, 1125093440, 1726148392, 974286048,...</td>\n",
       "      <td>[564434635, 1449544071, 1333611366, 1294181877...</td>\n",
       "      <td>[1807617650, 1113350792, 1245721824, 620961901...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>922230183</td>\n",
       "      <td>test</td>\n",
       "      <td>[1819952117, 1679157969, 914654189, 922230183]</td>\n",
       "      <td>[959054273, 601557360, 1705669581, 950215375, ...</td>\n",
       "      <td>[1634447035, 1706808534, 1438798026, 181995203...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sku_query split                                            sku_pos  \\\n",
       "0  1871769771  test                            [467420540, 1871769771]   \n",
       "1  1200553001  test  [945075396, 1436509994, 1436449707, 1438364324...   \n",
       "2   922231521  test  [1436509994, 1158222448, 1081199697, 490461399...   \n",
       "3   922230517  test  [600803111, 1125093440, 1726148392, 974286048,...   \n",
       "4   922230183  test     [1819952117, 1679157969, 914654189, 922230183]   \n",
       "\n",
       "                                        sku_hard_neg  \\\n",
       "0   [1418084594, 1573142945, 1536520050, 1573135817]   \n",
       "1  [1499532091, 963112482, 1422204647, 1122827873...   \n",
       "2  [1001260979, 1802254834, 1252814277, 805782980...   \n",
       "3  [564434635, 1449544071, 1333611366, 1294181877...   \n",
       "4  [959054273, 601557360, 1705669581, 950215375, ...   \n",
       "\n",
       "                                        sku_soft_neg  \n",
       "0  [1899881468, 1290396077, 1597431764, 165269677...  \n",
       "1  [1878150702, 1901123430, 1595672507, 679265327...  \n",
       "2  [1032263980, 879403681, 1816716304, 1630407222...  \n",
       "3  [1807617650, 1113350792, 1245721824, 620961901...  \n",
       "4  [1634447035, 1706808534, 1438798026, 181995203...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits_dataset = split_query_groups_adaptive(\n",
    "    pairwise_mapping_df,\n",
    "    test_size=0.1,\n",
    "    val_size=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pd.reset_option('display.max_colwidth')\n",
    "splits_dataset['test'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a90de9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>#queries</th>\n",
       "      <th>#pos</th>\n",
       "      <th>#hard_neg</th>\n",
       "      <th>#soft_neg</th>\n",
       "      <th>#total_sku</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>18</td>\n",
       "      <td>934</td>\n",
       "      <td>3860</td>\n",
       "      <td>76902</td>\n",
       "      <td>5562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val</td>\n",
       "      <td>15</td>\n",
       "      <td>125</td>\n",
       "      <td>485</td>\n",
       "      <td>7754</td>\n",
       "      <td>4403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>20</td>\n",
       "      <td>152</td>\n",
       "      <td>690</td>\n",
       "      <td>20338</td>\n",
       "      <td>5562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split  #queries  #pos  #hard_neg  #soft_neg  #total_sku\n",
       "0  train        18   934       3860      76902        5562\n",
       "1    val        15   125        485       7754        4403\n",
       "2   test        20   152        690      20338        5562"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare a summary table for each split\n",
    "import pandas as pd\n",
    "\n",
    "summary_rows = []\n",
    "per_query_stats = {}\n",
    "\n",
    "for split_name, df in splits_dataset.items():\n",
    "    num_rows = len(df)\n",
    "    num_pos = df['sku_pos'].apply(lambda x: len(x) if isinstance(x, list) else 0).sum()\n",
    "    num_hard = df['sku_hard_neg'].apply(lambda x: len(x) if isinstance(x, list) else 0).sum()\n",
    "    num_soft = df['sku_soft_neg'].apply(lambda x: len(x) if isinstance(x, list) else 0).sum()\n",
    "    unique_skus = set(df['sku_query'])\n",
    "    for col in ['sku_pos', 'sku_hard_neg', 'sku_soft_neg']:\n",
    "        unique_skus.update([sku for sublist in df[col] for sku in (sublist if isinstance(sublist, list) else [])])\n",
    "    summary_rows.append({\n",
    "        'split': split_name,\n",
    "        '#queries': num_rows,\n",
    "        '#pos': num_pos,\n",
    "        '#hard_neg': num_hard,\n",
    "        '#soft_neg': num_soft,\n",
    "        '#total_sku': len(unique_skus)\n",
    "    })\n",
    "\n",
    "    # Per-query stats for each type\n",
    "    per_query = pd.DataFrame({\n",
    "        'pos': df['sku_pos'].apply(lambda x: len(x) if isinstance(x, list) else 0),\n",
    "        'hard_neg': df['sku_hard_neg'].apply(lambda x: len(x) if isinstance(x, list) else 0),\n",
    "        'soft_neg': df['sku_soft_neg'].apply(lambda x: len(x) if isinstance(x, list) else 0),\n",
    "    })\n",
    "    agg = per_query.agg(['mean', 'std', 'min', 'max']).T\n",
    "    agg.index.name = 'type'\n",
    "    agg.columns.name = 'agg'\n",
    "    per_query_stats[split_name] = agg\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "89bf141d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th colspan=\"4\" halign=\"left\">pos</th>\n",
       "      <th colspan=\"4\" halign=\"left\">hard_neg</th>\n",
       "      <th colspan=\"4\" halign=\"left\">soft_neg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agg</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>51</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>216</td>\n",
       "      <td>214</td>\n",
       "      <td>258</td>\n",
       "      <td>4</td>\n",
       "      <td>755</td>\n",
       "      <td>4272</td>\n",
       "      <td>440</td>\n",
       "      <td>3583</td>\n",
       "      <td>4989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>516</td>\n",
       "      <td>40</td>\n",
       "      <td>449</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>195</td>\n",
       "      <td>1016</td>\n",
       "      <td>1520</td>\n",
       "      <td>449</td>\n",
       "      <td>5558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type   pos              hard_neg               soft_neg                  \n",
       "agg   mean std min  max     mean  std min  max     mean   std   min   max\n",
       "split                                                                    \n",
       "train   51  65   2  216      214  258   4  755     4272   440  3583  4989\n",
       "val      8   8   1   28       32   33   1   95      516    40   449   555\n",
       "test     7   8   2   29       34   48   1  195     1016  1520   449  5558"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display per-query stats for each split\n",
    "multiindex_tuples = []\n",
    "values = []\n",
    "for split_name, agg in per_query_stats.items():\n",
    "    for t in agg.index:\n",
    "        for a in agg.columns:\n",
    "            multiindex_tuples.append((split_name, t, a))\n",
    "            values.append(agg.loc[t, a])\n",
    "multiindex = pd.MultiIndex.from_tuples(multiindex_tuples, names=['split', 'type', 'agg'])\n",
    "per_query_multi_df = pd.Series(values, index=multiindex).unstack(['type', 'agg']).swaplevel(axis=1)\n",
    "# The above gives columns as (agg, type), swap to (type, agg)\n",
    "per_query_multi_df.columns = per_query_multi_df.columns.swaplevel(0,1)\n",
    "per_query_multi_df = per_query_multi_df.sort_index(axis=1, level=0)\n",
    "\n",
    "# Cast all columns which are numerical to int (if possible)\n",
    "for col in per_query_multi_df.columns:\n",
    "    # Only cast if dtype is numeric and all values are close to integer (to avoid ValueError)\n",
    "    if pd.api.types.is_numeric_dtype(per_query_multi_df[col]):\n",
    "        if np.allclose(per_query_multi_df[col].dropna() % 1, 0):\n",
    "            per_query_multi_df[col] = per_query_multi_df[col].astype(int)\n",
    "\n",
    "# Reorder columns so that for each type (pos, hard_neg, soft_neg), columns are in order: mean, std, min, max\n",
    "ordered_types = ['pos', 'hard_neg', 'soft_neg']\n",
    "ordered_aggs = ['mean', 'std', 'min', 'max']\n",
    "per_query_multi_df = per_query_multi_df.loc[:, [(t, a) for t in ordered_types for a in ordered_aggs]]\n",
    "# Sort per_query_multi_df by split: train, val, test\n",
    "split_order = ['train', 'val', 'test']\n",
    "per_query_multi_df = per_query_multi_df.reindex(split_order)\n",
    "\n",
    "display(per_query_multi_df.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef17b84c",
   "metadata": {},
   "source": [
    "# Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "96a54d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score                 # ← new\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def best_threshold(distances: torch.Tensor,\n",
    "                   labels:    torch.Tensor,\n",
    "                   steps:     int = 200,\n",
    "                   margin:    float = 1.5):\n",
    "    \"\"\"\n",
    "    Sweep `steps` evenly-spaced thresholds between 0 and `margin`\n",
    "    and return the one that maximises duplicate-class F1.\n",
    "    Labels: 0 = duplicate (positive), 1 = different (negative).\n",
    "    \"\"\"\n",
    "    d   = distances.detach().cpu().numpy()\n",
    "    y   = labels.detach().cpu().numpy()\n",
    "    thr = np.linspace(0.0, margin, steps)\n",
    "\n",
    "    best_f1, best_thr = -1.0, 0.0\n",
    "    for t in thr:\n",
    "        y_pred = (d < t).astype(int)          # 1 = duplicate prediction\n",
    "        f1     = f1_score(1 - y, y_pred)      # make 1 = positive for sklearn\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_thr = f1, t\n",
    "    return best_thr, best_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6cb34367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3777/1435658876.py:20: RuntimeWarning: divide by zero encountered in divide\n",
      "  cls_weights    = 1.0 / cls_cnt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and optimizer…\n",
      "Done.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[175]\u001b[39m\u001b[32m, line 142\u001b[39m\n\u001b[32m    139\u001b[39m         mlflow.log_metric(\u001b[33m\"\u001b[39m\u001b[33mtest_f1_score\u001b[39m\u001b[33m\"\u001b[39m,     test_f1)\n\u001b[32m    140\u001b[39m         mlflow.end_run()\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m \u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[175]\u001b[39m\u001b[32m, line 72\u001b[39m, in \u001b[36m_run\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# ---------- 3) training ----------\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tempfile.TemporaryDirectory() \u001b[38;5;28;01mas\u001b[39;00m tmp_ckpt_dir:\n\u001b[32m     71\u001b[39m     (train_losses, val_losses,\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m      best_metric_val, best_weights, thr_history) = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprint_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodels_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtmp_ckpt_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBEST_CKPT_METRIC\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m→ Best validation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBEST_CKPT_METRIC\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_metric_val\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# ---------- 4) loss curves ----------\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[160]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, optimizer, criterion, epochs_num, train_loader, valid_loader, device, print_epoch, models_dir, metric)\u001b[39m\n\u001b[32m     47\u001b[39m out1, out2 = model(im1, n1, d1, im2, n2, d2)\n\u001b[32m     48\u001b[39m loss = criterion(out1, out2, lbl)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m optimizer.step()\n\u001b[32m     51\u001b[39m total_train_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/clip-siamese/lib/python3.13/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/clip-siamese/lib/python3.13/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/clip-siamese/lib/python3.13/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "def _run():\n",
    "    images_dir = os.path.join(DATA_PATH, IMG_DATASET_NAME)\n",
    "\n",
    "    # ---------- 1) build DataLoaders ----------\n",
    "    splits  = {'train': actual_train_df,\n",
    "               'validation': actual_val_df,\n",
    "               'test': actual_test_df}\n",
    "    loaders = {}\n",
    "\n",
    "    for split_name, df in splits.items():\n",
    "        labels = df[\"label\"].values\n",
    "        ds     = SiameseRuCLIPDataset(df.drop(columns=\"label\"),\n",
    "                                      labels,\n",
    "                                      images_dir=images_dir)\n",
    "\n",
    "        if split_name == \"train\":\n",
    "            cls_cnt        = np.bincount(labels, minlength=2)\n",
    "            cls_weights    = 1.0 / cls_cnt\n",
    "            sample_weights = cls_weights[labels]\n",
    "            total = len(sample_weights)\n",
    "            max_n = MAX_SAMPLES_PER_EPOCH or total\n",
    "            n_samples = min(total, max_n)\n",
    "\n",
    "            sampler = WeightedRandomSampler(\n",
    "                sample_weights,\n",
    "                num_samples=n_samples,\n",
    "                replacement=True\n",
    "            )\n",
    "            loaders[split_name] = DataLoader(\n",
    "                ds,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                sampler=sampler,\n",
    "                num_workers=NUM_WORKERS\n",
    "            )\n",
    "        else:\n",
    "            loaders[split_name] = DataLoader(\n",
    "                ds,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=False,\n",
    "                num_workers=NUM_WORKERS\n",
    "            )\n",
    "\n",
    "    train_loader = loaders['train']\n",
    "    valid_loader = loaders['validation']\n",
    "    test_loader  = loaders['test']\n",
    "\n",
    "    # ---------- 2) model / optimiser ----------\n",
    "    print(\"Loading model and optimizer…\")\n",
    "    model = SiameseRuCLIP(\n",
    "        DEVICE, NAME_MODEL_NAME,\n",
    "        DESCRIPTION_MODEL_NAME,\n",
    "        PRELOAD_MODEL_NAME,\n",
    "        DATA_PATH + RESULTS_DIR,\n",
    "        dropout=DROPOUT\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    criterion = ContrastiveLoss(\n",
    "        margin=CONTRASTIVE_MARGIN,\n",
    "        pos_weight=POS_WEIGHT\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    print(\"Done.\")\n",
    "\n",
    "    # ---------- 3) training ----------\n",
    "    with tempfile.TemporaryDirectory() as tmp_ckpt_dir:\n",
    "        (train_losses, val_losses,\n",
    "         best_metric_val, best_weights, thr_history) = train(\n",
    "            model, optimizer, criterion,\n",
    "            EPOCHS, train_loader, valid_loader,\n",
    "            print_epoch=True, device=DEVICE,\n",
    "            models_dir=tmp_ckpt_dir,\n",
    "            metric=BEST_CKPT_METRIC\n",
    "        )\n",
    "\n",
    "    print(f\"→ Best validation {BEST_CKPT_METRIC}: {best_metric_val:.3f}\")\n",
    "\n",
    "    # ---------- 4) loss curves ----------\n",
    "    epochs_ax = list(range(1, len(train_losses) + 1))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(epochs_ax, train_losses, label='Train Loss')\n",
    "    ax.plot(epochs_ax, val_losses,   label='Val   Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Training & Validation Loss by Epoch')\n",
    "    ax.legend()\n",
    "    if MLFLOW_URI:\n",
    "        mlflow.log_figure(fig, 'loss_by_epoch.png')\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # ---------- 5) pick threshold for the *best* model ----------\n",
    "    model.load_state_dict(best_weights)\n",
    "    (_, _, _, _, _, best_thr) = validation(\n",
    "        model, criterion, valid_loader,\n",
    "        epoch='best', device=DEVICE,\n",
    "        split_name='validation',\n",
    "        threshold=None,\n",
    "        metric=BEST_CKPT_METRIC\n",
    "    )\n",
    "    print(f\"Chosen threshold from validation: {best_thr:.3f}\")\n",
    "\n",
    "    # ---------- 6) final TEST ----------\n",
    "    (test_pos_acc, test_neg_acc,\n",
    "     test_acc, test_f1,\n",
    "     test_loss, _) = validation(\n",
    "        model, criterion, test_loader,\n",
    "        epoch='test', device=DEVICE,\n",
    "        split_name='test',\n",
    "        threshold=best_thr,\n",
    "        metric=BEST_CKPT_METRIC\n",
    "    )\n",
    "\n",
    "    # pick out the right test-metric value\n",
    "    test_metric = test_pos_acc if BEST_CKPT_METRIC == 'pos_acc' else test_f1\n",
    "    print(f\"Test {BEST_CKPT_METRIC}: {test_metric:.3f}\")\n",
    "\n",
    "    # ---------- 7) save checkpoint ----------\n",
    "    filename = (\n",
    "        f\"siamese_contrastive_test-{BEST_CKPT_METRIC}={test_metric:.3f}\"\n",
    "        f\"{'_' + MODEL_NAME_POSTFIX if MODEL_NAME_POSTFIX else ''}\"\n",
    "        f\"{'_' + PRELOAD_MODEL_NAME  if PRELOAD_MODEL_NAME else ''}\"\n",
    "        f\"_best-thr={best_thr:.3f}.pt\"\n",
    "    )\n",
    "    final_path = Path(DATA_PATH + RESULTS_DIR) / filename\n",
    "    final_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(best_weights, final_path)\n",
    "    print(f\"Saved best‐{BEST_CKPT_METRIC} checkpoint to {final_path}\")\n",
    "\n",
    "    if MLFLOW_URI:\n",
    "        mlflow.log_metric(\"test_pos_accuracy\", test_pos_acc)\n",
    "        mlflow.log_metric(\"test_neg_accuracy\", test_neg_acc)\n",
    "        mlflow.log_metric(\"test_accuracy\",     test_acc)\n",
    "        mlflow.log_metric(\"test_f1_score\",     test_f1)\n",
    "        mlflow.end_run()\n",
    "\n",
    "_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
