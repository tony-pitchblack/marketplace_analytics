{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcaee945",
   "metadata": {},
   "source": [
    "# Installs & tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d9b411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    import mlflow\n",
    "except ImportError:\n",
    "    !pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c65f9c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    import dotenv\n",
    "except ImportError:\n",
    "    !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40e77b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Log into huggingface via Kaggle Secrets\n",
    "\n",
    "# import os\n",
    "# import huggingface_hub\n",
    "# from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# user_secrets = UserSecretsClient()\n",
    "# HF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "\n",
    "# huggingface_hub.login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0c3f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Log into huggingface via .env\n",
    "\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# import huggingface_hub\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "# huggingface_hub.login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a0467",
   "metadata": {},
   "source": [
    "# Choose notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be91836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "## CHOOSE MODEL PARAMETERS #################################################\n",
    "\n",
    "MODEL_NAME_POSTFIX='splitting-by-query'\n",
    "NAME_MODEL_NAME = 'cointegrated/rubert-tiny' # 'DeepPavlov/distilrubert-tiny-cased-conversational-v1'\n",
    "DESCRIPTION_MODEL_NAME = 'cointegrated/rubert-tiny'\n",
    "\n",
    "DATA_PATH = 'data/'\n",
    "RESULTS_DIR = 'train_results/'\n",
    "\n",
    "# BATCH_SIZE=60 # uses 14.5GiB of 1 GPU\n",
    "# NUM_WORKERS=2 # TODO: use multiple GPU, tune number of workers\n",
    "# NUM_DEBUG_SAMPLES=None\n",
    "# EPOCHS=20\n",
    "\n",
    "BATCH_SIZE=1\n",
    "NUM_WORKERS=0\n",
    "NUM_DEBUG_SAMPLES=2\n",
    "EPOCHS=2\n",
    "\n",
    "PRELOAD_MODEL_NAME = 'cc12m_rubert_tiny_ep_1.pt' # preload ruclip\n",
    "# PRELOAD_MODEL_NAME = None\n",
    "\n",
    "VALIDATION_SPLIT=.05\n",
    "TEST_SPLIT=.1\n",
    "RANDOM_SEED=42\n",
    "LR=9e-5\n",
    "MOMENTUM=0.9\n",
    "WEIGHT_DECAY=1e-2\n",
    "CONTRASTIVE_MARGIN=1.5\n",
    "CONTRASTIVE_THRESHOLD=0.3\n",
    "SHEDULER_PATIENCE=3 # in epochs\n",
    "\n",
    "DEVICE='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3d9e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHOOSE DATA #########################################################\n",
    "\n",
    "# # These table files need 'image_name_first', 'image_name_second' constructed from sku to be usable in current pipeline\n",
    "# TABLE_DATASET_FILE = 'tables_labeled/processed/labeled_1.3k_with-options.csv'\n",
    "# TABLE_DATASET_FILE = 'tables_labeled/processed/labeled_56k_with-options.csv'\n",
    "# IMG_DATASET_NAME = 'images_7k'\n",
    "# STRATIFY_COLS = None\n",
    "\n",
    "# TABLE_DATASET_FILE = 'tables_labeled/processed/labeled_5k_with-options.csv'\n",
    "# IMG_DATASET_NAME = 'images_7k' \n",
    "# STRATIFY_COLS = None\n",
    "\n",
    "# TABLE_DATASET_FILE = 'tables_WB_OZ_100/WB_OZ_100.csv'\n",
    "# TABLE_DATASET_FILE = 'tables_WB_OZ_100/WB_OZ_100_conjugated.csv'\n",
    "# TABLE_DATASET_FILE = 'tables_WB_OZ_100/WB_OZ_100_conjugated_shuffled_seed=42_fraction=1.csv'\n",
    "# TABLE_DATASET_FILE = 'tables_WB_OZ_100/WB_OZ_100_conjugated_shuffled_seed=42_fraction=0.5.csv'\n",
    "# IMG_DATASET_NAME = 'images_WB_OZ_100'\n",
    "# STRATIFY_COLS = None\n",
    "\n",
    "TABLE_DATASET_FILE = 'tables_OZ_geo_5500/processed/regex-pairwise-dataset_num-queries=20_num-pairs=6226_patterns-dict-hash=6dbf9b3ef9568e60cd959f87be7e3b26.csv'\n",
    "IMG_DATASET_NAME = 'images_OZ_geo_5500'\n",
    "STRATIFY_COLS = ['sku_first', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14b5eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOGGING PARAMS ######################################################################\n",
    "\n",
    "# MLFLOW_URI = \"http://176.56.185.96:5000\"\n",
    "# MLFLOW_URI = \"http://localhost:5000\"\n",
    "MLFLOW_URI = None\n",
    "\n",
    "MLFLOW_EXPERIMENT = \"siamese/1fold\"\n",
    "\n",
    "TELEGRAM_TOKEN = None\n",
    "# TELEGRAM_TOKEN = '' # set token to get notifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b40bc83",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00017085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from timm import create_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "# import transformers\n",
    "# from transformers import DistilBertModel, DistilBertConfig, DistilBertTokenizer,\\\n",
    "#         get_linear_schedule_with_warmup\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# import json\n",
    "# from itertools import product\n",
    "\n",
    "# import datasets\n",
    "# from datasets import Dataset, concatenate_datasets\n",
    "# import argparse\n",
    "import requests\n",
    "\n",
    "# from io import BytesIO\n",
    "# from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "# import more_itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import mlflow\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3494173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tg_report(text, token=None) -> None:\n",
    "    method = 'sendMessage'\n",
    "    chat_id = 324956476\n",
    "    _ = requests.post(\n",
    "            url='https://api.telegram.org/bot{0}/{1}'.format(token, method),\n",
    "            data={'chat_id': chat_id, 'text': text} \n",
    "        ).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34706f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuCLIPtiny(nn.Module):\n",
    "    def __init__(self, name_model_name):\n",
    "        super().__init__()\n",
    "        self.visual = create_model('convnext_tiny',\n",
    "                                   pretrained=False, # TODO: берём претрейн\n",
    "                                   num_classes=0,\n",
    "                                   in_chans=3)  # out 768\n",
    "\n",
    "        self.transformer = AutoModel.from_pretrained(name_model_name)\n",
    "        name_model_output_shape = self.transformer.config.hidden_size  # dynamically get hidden size\n",
    "        self.final_ln = torch.nn.Linear(name_model_output_shape, 768)  # now uses the transformer hidden size\n",
    "        self.logit_scale = torch.nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        return self.visual.stem[0].weight.dtype\n",
    "\n",
    "    def encode_image(self, image):\n",
    "        return self.visual(image.type(self.dtype))\n",
    "\n",
    "    def encode_text(self, input_ids, attention_mask):\n",
    "        x = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = x.last_hidden_state[:, 0, :]\n",
    "        x = self.final_ln(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, image, input_ids, attention_mask):\n",
    "        image_features = self.encode_image(image)\n",
    "        text_features = self.encode_text(input_ids, attention_mask)\n",
    "\n",
    "        # normalized features\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # cosine similarity as logits\n",
    "        logit_scale = self.logit_scale.exp()\n",
    "        logits_per_image = logit_scale * image_features @ text_features.t()\n",
    "        logits_per_text = logits_per_image.t()\n",
    "\n",
    "        return logits_per_image, logits_per_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84518fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        _convert_image_to_rgb,\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]), ])\n",
    "\n",
    "def _convert_image_to_rgb(image):\n",
    "    return image.convert(\"RGB\")\n",
    "\n",
    "class Tokenizers:\n",
    "    def __init__(self):\n",
    "        self.name_tokenizer = AutoTokenizer.from_pretrained(NAME_MODEL_NAME)\n",
    "        self.desc_tokenizer = AutoTokenizer.from_pretrained(DESCRIPTION_MODEL_NAME)\n",
    "\n",
    "    def tokenize_name(self, texts, max_len=77):\n",
    "        tokenized = self.name_tokenizer.batch_encode_plus(texts,\n",
    "                                                     truncation=True,\n",
    "                                                     add_special_tokens=True,\n",
    "                                                     max_length=max_len,\n",
    "                                                     padding='max_length',\n",
    "                                                     return_attention_mask=True,\n",
    "                                                     return_tensors='pt')\n",
    "        return torch.stack([tokenized[\"input_ids\"], tokenized[\"attention_mask\"]])\n",
    "    \n",
    "    def tokenize_description(self, texts, max_len=77):\n",
    "        tokenized = self.desc_tokenizer(texts,\n",
    "                                        truncation=True,\n",
    "                                        add_special_tokens=True,\n",
    "                                        max_length=max_len,\n",
    "                                        padding='max_length',\n",
    "                                        return_attention_mask=True,\n",
    "                                        return_tensors='pt')\n",
    "        return torch.stack([tokenized[\"input_ids\"], tokenized[\"attention_mask\"]])\n",
    "\n",
    "class SiameseRuCLIPDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df=None, labels=None, df_path=None, images_dir=DATA_PATH+'images/'):\n",
    "        # loads data either from path using `df_path` or directly from `df` argument\n",
    "        self.df = pd.read_csv(df_path) if df_path is not None else df\n",
    "        self.labels = labels\n",
    "        self.images_dir = images_dir\n",
    "        self.tokenizers = Tokenizers()\n",
    "        self.transform = get_transform()\n",
    "        # \n",
    "        self.max_len = 77\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        name_tokens = self.tokenizers.tokenize_name([str(row.name_first), \n",
    "                                               str(row.name_second)], max_len=self.max_len)\n",
    "        name_first = name_tokens[:, 0, :] # [input_ids, attention_mask]\n",
    "        name_second = name_tokens[:, 1, :]\n",
    "        desc_tokens = self.tokenizers.tokenize_description([str(row.description_first), \n",
    "                                               str(row.description_second)])\n",
    "        desc_first = desc_tokens[:, 0, :] # [input_ids, attention_mask]\n",
    "        desc_second = desc_tokens[:, 1, :]\n",
    "        im_first = cv2.imread(os.path.join(self.images_dir, row.image_name_first))\n",
    "        im_first = cv2.cvtColor(im_first, cv2.COLOR_BGR2RGB)\n",
    "        im_first = Image.fromarray(im_first)\n",
    "        im_first = self.transform(im_first)\n",
    "        im_second = cv2.imread(os.path.join(self.images_dir, row.image_name_second))\n",
    "        im_second = cv2.cvtColor(im_second, cv2.COLOR_BGR2RGB)\n",
    "        im_second = Image.fromarray(im_second)\n",
    "        im_second = self.transform(im_second)\n",
    "        label = self.labels[idx]\n",
    "        return im_first, name_first, desc_first, im_second, name_second, desc_second, label\n",
    "\n",
    "    def __len__(self,):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2d263be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "class SiameseRuCLIP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 device: str,\n",
    "                 name_model_name: str,\n",
    "                 description_model_name: str,\n",
    "                 preload_model_name: str = None,\n",
    "                 models_dir: str = None):\n",
    "        \"\"\"\n",
    "        Initializes the SiameseRuCLIP model.\n",
    "        Required parameters:\n",
    "          - models_dir: directory containing saved checkpoints.\n",
    "          - name_model_name: model name for text (name) branch.\n",
    "          - description_model_name: model name for description branch.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        device = torch.device(device)\n",
    "\n",
    "        # Initialize RuCLIPtiny\n",
    "        self.ruclip = RuCLIPtiny(name_model_name)\n",
    "        if preload_model_name is not None:\n",
    "            std = torch.load(\n",
    "                os.path.join(models_dir, preload_model_name),\n",
    "                weights_only=True,\n",
    "                map_location=device\n",
    "            )\n",
    "            self.ruclip.load_state_dict(std)\n",
    "            self.ruclip.eval()\n",
    "        self.ruclip = self.ruclip.to(device)\n",
    "\n",
    "        # Initialize the description transformer\n",
    "        self.description_transformer = AutoModel.from_pretrained(description_model_name)\n",
    "        self.description_transformer = self.description_transformer.to(device)\n",
    "\n",
    "        # Determine dimensionality\n",
    "        vision_dim = self.ruclip.visual.num_features\n",
    "        name_dim = self.ruclip.final_ln.out_features\n",
    "        desc_dim = self.description_transformer.config.hidden_size\n",
    "        self.hidden_dim = vision_dim + name_dim + desc_dim\n",
    "\n",
    "        # Define MLP head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim // 2, self.hidden_dim // 4),\n",
    "        ).to(device)\n",
    "\n",
    "    def encode_image(self, image):\n",
    "        return self.ruclip.encode_image(image)\n",
    "\n",
    "    def encode_name(self, name):\n",
    "        return self.ruclip.encode_text(name[:, 0, :], name[:, 1, :])\n",
    "\n",
    "    def encode_description(self, desc):\n",
    "        last_hidden_states = self.description_transformer(desc[:, 0, :], desc[:, 1, :]).last_hidden_state\n",
    "        attention_mask = desc[:, 1, :]\n",
    "        return average_pool(last_hidden_states, attention_mask)\n",
    "\n",
    "    def get_final_embedding(self, im, name, desc):\n",
    "        image_emb = self.encode_image(im)\n",
    "        name_emb = self.encode_name(name)\n",
    "        desc_emb = self.encode_description(desc)\n",
    "\n",
    "        # Concatenate the embeddings and forward through the head\n",
    "        combined_emb = torch.cat([image_emb, name_emb, desc_emb], dim=1)\n",
    "        final_embedding = self.head(combined_emb)\n",
    "        return final_embedding\n",
    "\n",
    "    def forward(self, im1, name1, desc1, im2, name2, desc2):\n",
    "        out1 = self.get_final_embedding(im1, name1, desc1)\n",
    "        out2 = self.get_final_embedding(im2, name2, desc2)\n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "987d1ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def __name__(self,):\n",
    "        return 'ContrastiveLoss'\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        pos = (1-label) * torch.pow(euclidean_distance, 2)\n",
    "        neg = label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        loss_contrastive = torch.mean( pos + neg )\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9c6281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pair(output1, output2, target, threshold):\n",
    "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "    # меньше границы, там где будет True — конкуренты\n",
    "    cond = euclidean_distance < threshold\n",
    "    pos_sum = 0\n",
    "    neg_sum = 0\n",
    "    pos_acc = 0\n",
    "    neg_acc = 0\n",
    "\n",
    "    for i in range(len(cond)):\n",
    "        # 1 значит не конкуренты\n",
    "        if target[i]:\n",
    "            neg_sum+=1\n",
    "            # 0 в cond значит дальше друг от друга чем threshold\n",
    "            if not cond[i]:\n",
    "                neg_acc+=1\n",
    "        elif not target[i]:\n",
    "            pos_sum+=1\n",
    "            if cond[i]:\n",
    "                pos_acc+=1\n",
    "\n",
    "    return pos_acc, pos_sum, neg_acc, neg_sum\n",
    "\n",
    "def predict(out1, out2, threshold=CONTRASTIVE_THRESHOLD):\n",
    "    # вернёт 1 если похожи\n",
    "    return F.pairwise_distance(out1, out2) < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6664f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, data_loader, epoch,\n",
    "               device='cpu', split_name='validation',\n",
    "               threshold=CONTRASTIVE_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Runs one epoch of validation (or test), computing:\n",
    "      - avg_loss\n",
    "      - positive/negative accuracies\n",
    "      - avg_acc\n",
    "      - F1\n",
    "    Logs valid_f1_score to MLflow if MLFLOW_URI is set.\n",
    "    Returns: pos_acc, neg_acc, avg_acc, f1, avg_loss\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    pos_acc_sum = neg_acc_sum = 0.0\n",
    "    pos_count = neg_count = 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=f\"{split_name}\"):\n",
    "            im1, name1, desc1, im2, name2, desc2, label = batch\n",
    "            im1, name1, desc1, im2, name2, desc2, label = (\n",
    "                im1.to(device), name1.to(device), desc1.to(device),\n",
    "                im2.to(device), name2.to(device), desc2.to(device),\n",
    "                label.to(device)\n",
    "            )\n",
    "            out1, out2 = model(im1, name1, desc1, im2, name2, desc2)\n",
    "            loss = criterion(out1, out2, label)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # compute pos/neg accuracy\n",
    "            distances = F.pairwise_distance(out1, out2)\n",
    "            preds = (distances < threshold).long()\n",
    "            pos_mask = (label == 0)\n",
    "            neg_mask = (label == 1)\n",
    "            pos_acc_sum += (preds[pos_mask] == 1).sum().item()\n",
    "            neg_acc_sum += (preds[neg_mask] == 0).sum().item()\n",
    "            pos_count   += pos_mask.sum().item()\n",
    "            neg_count   += neg_mask.sum().item()\n",
    "\n",
    "            # for F1\n",
    "            all_preds.extend(preds.cpu().numpy().tolist())\n",
    "            all_labels.extend((label.cpu().numpy() == 0).astype(int).tolist())\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    pos_acc  = pos_acc_sum / pos_count if pos_count else 0.0\n",
    "    neg_acc  = neg_acc_sum / neg_count if neg_count else 0.0\n",
    "    avg_acc  = (pos_acc + neg_acc) / 2.0\n",
    "    f1       = f1_score(all_labels, all_preds, zero_division=0)\n",
    "\n",
    "    report = (f\"[{split_name}] Epoch {epoch} – \"\n",
    "              f\"loss: {avg_loss:.4f}, \"\n",
    "              f\"P Acc: {pos_acc:.3f}, \"\n",
    "              f\"N Acc: {neg_acc:.3f}, \"\n",
    "              f\"Avg Acc: {avg_acc:.3f}, \"\n",
    "              f\"F1: {f1:.3f}\")\n",
    "    print(report)\n",
    "    make_tg_report(report, TELEGRAM_TOKEN)\n",
    "\n",
    "    if MLFLOW_URI:\n",
    "        mlflow.log_metric(\"valid_f1_score\", f1, step=epoch)\n",
    "\n",
    "    return pos_acc, neg_acc, avg_acc, f1, avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e34b5c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot epoch after each train epoch in `train()`\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def plot_epoch(loss_history, filename=\"data/runs_artifacts/epoch_loss.png\") -> None:\n",
    "    Path(filename).parent.mkdir(parents=True, exist_ok=True)\n",
    "    display.clear_output(wait=True)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.title(\"Training loss\")\n",
    "    plt.xlabel(\"Iteration number\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(loss_history, 'b')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)  # Save the plot to a file\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4952b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def train(model, optimizer, criterion,\n",
    "          epochs_num, train_loader, valid_loader=None,\n",
    "          device='cpu', print_epoch=False,\n",
    "          models_dir=None):\n",
    "    \"\"\"\n",
    "    Trains the model for `epochs_num` epochs, saving a checkpoint\n",
    "    each epoch into `models_dir` if given, and selects the best by validation F1.\n",
    "    Returns:\n",
    "      train_losses: list of avg train loss per epoch\n",
    "      val_losses:   list of avg val loss per epoch (only if valid_loader)\n",
    "      best_valid_f1, best_weights\n",
    "    \"\"\"\n",
    "    model.to(device).train()\n",
    "    train_losses, val_losses = [], []\n",
    "    best_valid_f1 = float('-inf')\n",
    "    best_weights = None\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, mode=\"max\",\n",
    "        factor=0.1, patience=SHEDULER_PATIENCE,\n",
    "        threshold=1e-4, threshold_mode='rel',\n",
    "        cooldown=0, min_lr=0, eps=1e-8\n",
    "    )\n",
    "\n",
    "    if models_dir:\n",
    "        Path(models_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for epoch in range(1, epochs_num + 1):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"train {epoch}/{epochs_num}\"):\n",
    "            im1, name1, desc1, im2, name2, desc2, label = [t.to(device) for t in batch]\n",
    "            optimizer.zero_grad()\n",
    "            out1, out2 = model(im1, name1, desc1, im2, name2, desc2)\n",
    "            loss = criterion(out1, out2, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        if print_epoch and valid_loader is not None:\n",
    "            _, _, _, val_f1, avg_val_loss = validation(\n",
    "                model, criterion, valid_loader,\n",
    "                epoch, device, split_name='validation'\n",
    "            )\n",
    "            val_losses.append(avg_val_loss)\n",
    "\n",
    "            scheduler.step(val_f1)\n",
    "\n",
    "            if models_dir:\n",
    "                ckpt_path = Path(models_dir) / f\"checkpoint_epoch_{epoch}.pt\"\n",
    "                torch.save(model.state_dict(), ckpt_path)\n",
    "\n",
    "            if val_f1 > best_valid_f1:\n",
    "                best_valid_f1 = val_f1\n",
    "                best_weights = model.state_dict().copy()\n",
    "\n",
    "    print(f\"Best validation F1: {best_valid_f1:.3f}\")\n",
    "    return train_losses, val_losses, best_valid_f1, best_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481940bc",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e226754b",
   "metadata": {},
   "source": [
    "## Download data from HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b8cde88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf16d5e0aa454765b48999ac982d6c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download models' weights & text/image datasets\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_ID = \"INDEEPA/clip-siamese\"\n",
    "LOCAL_DIR = Path(\"data/train_results\")\n",
    "LOCAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=REPO_ID,\n",
    "    repo_type='dataset',\n",
    "    local_dir='data',\n",
    "    allow_patterns=[\n",
    "        \"train_results/cc12m*.pt\",\n",
    "        TABLE_DATASET_FILE,\n",
    "        f\"{IMG_DATASET_NAME}.zip\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "!unzip -n -q data/{IMG_DATASET_NAME}.zip -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d35d53",
   "metadata": {},
   "source": [
    "## Split data by query sku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "387fca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique query sku: 20\n"
     ]
    }
   ],
   "source": [
    "TABLE_DATASET_PATH = DATA_PATH + TABLE_DATASET_FILE\n",
    "\n",
    "labeled = pd.read_csv(TABLE_DATASET_PATH)\n",
    "print(f\"Unique query sku: {labeled.sku_query.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c414d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/val/test\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "def split_pairwise(\n",
    "    df: pd.DataFrame,\n",
    "    test_size: float = 0.20,\n",
    "    random_state: int | None = None,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Leakage-free DEV / TEST split for a pair-wise SKU dataset.\n",
    "    Input `df` must have columns ['sku_query','sku_candidate','label'].\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    test_rows, dev_rows   = [], []\n",
    "    test_entities: set[str] = set()\n",
    "\n",
    "    # ---- iterate over each original query SKU ------------------------------\n",
    "    for q_sku, grp in df.groupby(\"sku_query\"):\n",
    "        pos_idx = grp.index[grp.label == 1].tolist()\n",
    "        neg_idx = grp.index[grp.label == 0].tolist()\n",
    "\n",
    "        # --- (1) sample TEST rows -------------------------------------------\n",
    "        n_pos = int(np.ceil(test_size * len(pos_idx))) if pos_idx else 0\n",
    "        n_neg = int(np.ceil(test_size * len(neg_idx))) if neg_idx else 0\n",
    "\n",
    "        pos_test = rng.choice(pos_idx, size=n_pos, replace=False) if n_pos else []\n",
    "        neg_test = rng.choice(neg_idx, size=n_neg, replace=False) if n_neg else []\n",
    "\n",
    "        test_rows.extend(pos_test)\n",
    "        test_rows.extend(neg_test)\n",
    "\n",
    "        # register every entity that just entered TEST\n",
    "        test_entities.add(q_sku)\n",
    "        test_entities.update(df.loc[pos_test, \"sku_candidate\"])\n",
    "        test_entities.update(df.loc[neg_test, \"sku_candidate\"])\n",
    "\n",
    "        # --- (2) build DEV from remaining rows ------------------------------\n",
    "        remain_pos = list(set(pos_idx) - set(pos_test))\n",
    "        remain_neg = list(set(neg_idx) - set(neg_test))\n",
    "\n",
    "        if remain_pos:\n",
    "            # choose substitute query (one of the remaining positives)\n",
    "            sub_idx  = int(rng.choice(remain_pos))\n",
    "            sub_sku  = df.loc[sub_idx, \"sku_candidate\"]\n",
    "\n",
    "            for idx in remain_pos:\n",
    "                if idx == sub_idx:            # skip (sub,sub) self-pair\n",
    "                    continue\n",
    "                row = df.loc[idx].copy()\n",
    "                row[\"sku_query\"] = sub_sku\n",
    "                dev_rows.append(row)\n",
    "\n",
    "            for idx in remain_neg:\n",
    "                row = df.loc[idx].copy()\n",
    "                row[\"sku_query\"] = sub_sku\n",
    "                dev_rows.append(row)\n",
    "\n",
    "    # ---- materialise the splits -------------------------------------------\n",
    "    test_df = df.loc[test_rows].reset_index(drop=True)\n",
    "    dev_df  = pd.DataFrame(dev_rows).reset_index(drop=True)\n",
    "\n",
    "    # ---- (3) final purge: remove any row touching a TEST entity ------------\n",
    "    mask = ~(dev_df[\"sku_query\"].isin(test_entities) |\n",
    "             dev_df[\"sku_candidate\"].isin(test_entities))\n",
    "    dev_df = dev_df[mask].reset_index(drop=True)\n",
    "\n",
    "    return dev_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e00ad1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2510, 95), (175, 95), (644, 95))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into train/val/test\n",
    "\n",
    "dev_df,  test_df  = split_pairwise(labeled,  test_size=TEST_SPLIT, random_state=42)\n",
    "train_df, val_df  = split_pairwise(dev_df,   test_size=VALIDATION_SPLIT, random_state=42)\n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efc1fa9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       hard_negative  positive  total\n",
      "split                                \n",
      "train           2156       354   2510\n",
      "val              146        29    175\n",
      "test             551        93    644\n"
     ]
    }
   ],
   "source": [
    "# Print positive/hard_negative pairs count per each split \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# collect your splits in a dict\n",
    "splits = {\n",
    "    'train': train_df,\n",
    "    'val':   val_df,\n",
    "    'test':  test_df,\n",
    "}\n",
    "\n",
    "# build the summary_df records\n",
    "records = []\n",
    "for name, df in splits.items():\n",
    "    vc = df['label'].value_counts()\n",
    "    records.append({\n",
    "        'split':    name,\n",
    "        'hard_negative': vc.get(0, 0),\n",
    "        'positive': vc.get(1, 0),\n",
    "        'total':    len(df),\n",
    "    })\n",
    "\n",
    "# create a DataFrame and set the split name as index\n",
    "summary_df = (\n",
    "    pd.DataFrame(records)\n",
    "      .set_index('split')\n",
    "      .astype(int)\n",
    ")\n",
    "\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bed0574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All sanity checks passed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def sanity_checks(train: pd.DataFrame, val: pd.DataFrame, test: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Verify that:\n",
    "      1) Each query SKU appears in exactly one split\n",
    "      2) No SKU (query or candidate) overlaps across splits\n",
    "      3) No duplicate pairs across splits\n",
    "      4) Each split has at least one positive and one hard_negative\n",
    "    \"\"\"\n",
    "    # 1) Query-level disjointness\n",
    "    q_train = set(train[\"sku_query\"])\n",
    "    q_val   = set(val  [\"sku_query\"])\n",
    "    q_test  = set(test [\"sku_query\"])\n",
    "    assert not (q_train & q_val),   f\"Query SKU overlap train↔val: {q_train & q_val}\"\n",
    "    assert not (q_train & q_test),  f\"Query SKU overlap train↔test: {q_train & q_test}\"\n",
    "    assert not (q_val   & q_test),  f\"Query SKU overlap val↔test:   {q_val   & q_test}\"\n",
    "    \n",
    "    # 2) Global SKU disjointness (query OR candidate)\n",
    "    def all_skus(df):\n",
    "        return set(df[\"sku_query\"]) | set(df[\"sku_candidate\"])\n",
    "    s_train, s_val, s_test = all_skus(train), all_skus(val), all_skus(test)\n",
    "    assert not (s_train & s_val),   f\"SKU overlap train↔val: {s_train & s_val}\"\n",
    "    assert not (s_train & s_test),  f\"SKU overlap train↔test: {s_train & s_test}\"\n",
    "    assert not (s_val   & s_test),  f\"SKU overlap val↔test:   {s_val   & s_test}\"\n",
    "    \n",
    "    # 3) Unique pairs\n",
    "    all_pairs = pd.concat([train, val, test], ignore_index=True)\n",
    "    dupes = all_pairs.duplicated(subset=[\"sku_query\",\"sku_candidate\",\"label\"])\n",
    "    assert not dupes.any(), f\"Found {dupes.sum()} duplicate pairs across splits\"\n",
    "    \n",
    "    # 4) Label coverage in each split\n",
    "    for name, df in [(\"train\", train), (\"val\", val), (\"test\", test)]:\n",
    "        labels = df[\"label\"].unique()\n",
    "        assert set(labels) == {0,1}, f\"{name} split has labels {labels}, expected {{0,1}}\"\n",
    "    \n",
    "    print(\"✅ All sanity checks passed!\")\n",
    "\n",
    "sanity_checks(train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0626ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for later usage\n",
    "\n",
    "folder_name = f'test={TEST_SPLIT}_val={VALIDATION_SPLIT}'\n",
    "dataset_name = Path(TABLE_DATASET_PATH).parts[1]\n",
    "\n",
    "common_file_prefix = (\n",
    "    Path(DATA_PATH) / dataset_name / 'processed' /\n",
    "    'pairwise-splits' / folder_name\n",
    ")\n",
    "common_file_prefix.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_df.to_csv(common_file_prefix / 'train.csv', index=False)\n",
    "val_df.to_csv(common_file_prefix / 'val.csv', index=False)\n",
    "test_df.to_csv(common_file_prefix / 'test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4aa24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_split(df: pd.DataFrame, num_samples: int | None, random_state: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    If num_samples is set, take up to that many random rows;\n",
    "    otherwise just shuffle the entire DataFrame.\n",
    "    Always resets the index.\n",
    "    \"\"\"\n",
    "    if num_samples is not None:\n",
    "        n = min(num_samples, len(df))\n",
    "        out = df.sample(n=n, random_state=random_state)\n",
    "    else:\n",
    "        out = df.sample(frac=1, random_state=random_state)\n",
    "    return out.reset_index(drop=True)\n",
    "\n",
    "# apply to each split\n",
    "train_df = sample_split(train_df, NUM_DEBUG_SAMPLES, RANDOM_SEED)\n",
    "val_df   = sample_split(val_df,   NUM_DEBUG_SAMPLES, RANDOM_SEED)\n",
    "test_df  = sample_split(test_df,  NUM_DEBUG_SAMPLES, RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef17b84c",
   "metadata": {},
   "source": [
    "# Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afb31be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 2/2 [00:00<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch 2 – loss: 2.5965, P Acc: 0.000, N Acc: 0.000, Avg Acc: 0.000, F1: 0.000\n",
      "Test F1-score on best model: 0.000\n",
      "Saved best‐F1 checkpoint to data/data/train_results/siamese_contrastive_test-f1=0.000_splitting-by-query_cc12m_rubert_tiny_ep_1.pt.pt\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def _run():\n",
    "    images_dir = os.path.join(DATA_PATH, IMG_DATASET_NAME)\n",
    "\n",
    "    # 1) Prepare splits and rename columns\n",
    "    splits = {\n",
    "        'train':      train_df,\n",
    "        'validation': val_df,\n",
    "        'test':       test_df,\n",
    "    }\n",
    "    loaders = {}\n",
    "\n",
    "    for split_name, df in splits.items():\n",
    "        # rename for dataset compatibility\n",
    "        df = df.rename(columns={\n",
    "            col: col.replace(\"_query\", \"_first\").replace(\"_candidate\", \"_second\")\n",
    "            for col in df.columns\n",
    "            if \"_query\" in col or \"_candidate\" in col\n",
    "        })\n",
    "\n",
    "        # build dataset + loader\n",
    "        labels = df[\"label\"].values\n",
    "        ds     = SiameseRuCLIPDataset(df.drop(columns=\"label\"), labels, images_dir=images_dir)\n",
    "\n",
    "        shuffle = (split_name == 'train')\n",
    "        loaders[split_name] = DataLoader(\n",
    "            ds,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=NUM_WORKERS\n",
    "        )\n",
    "\n",
    "    train_loader = loaders['train']\n",
    "    valid_loader = loaders['validation']\n",
    "    test_loader  = loaders['test']\n",
    "\n",
    "    print(\"Loading model and optimizer…\")\n",
    "    model     = SiameseRuCLIP(\n",
    "        DEVICE, NAME_MODEL_NAME,\n",
    "        DESCRIPTION_MODEL_NAME,\n",
    "        PRELOAD_MODEL_NAME,\n",
    "        DATA_PATH + RESULTS_DIR,\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    criterion = ContrastiveLoss(margin=CONTRASTIVE_MARGIN).to(DEVICE)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    print(\"Done.\")\n",
    "\n",
    "    # Temporary dir for intermediate checkpoints\n",
    "    with tempfile.TemporaryDirectory() as tmp_ckpt_dir:\n",
    "        train_losses, val_losses, best_f1, best_weights = train(\n",
    "            model, optimizer, criterion,\n",
    "            EPOCHS, train_loader, valid_loader,\n",
    "            print_epoch=True,\n",
    "            device=DEVICE,\n",
    "            models_dir=tmp_ckpt_dir\n",
    "        )\n",
    "    print(f\"→ Best validation F1: {best_f1:.3f}\")\n",
    "\n",
    "    # Plot train vs. val loss by epoch\n",
    "    epochs = list(range(1, len(train_losses) + 1))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(epochs, train_losses, label='Train Loss')\n",
    "    ax.plot(epochs, val_losses,   label='Val   Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Training & Validation Loss by Epoch')\n",
    "    ax.legend()\n",
    "    if MLFLOW_URI:\n",
    "        mlflow.log_figure(fig, 'loss_by_epoch.png')\n",
    "\n",
    "    # TODO: display after each train epoch\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "    # Final test on the best model\n",
    "    model.load_state_dict(best_weights)\n",
    "    model.eval()\n",
    "    test_pos_acc, test_neg_acc, test_acc, test_f1, test_loss = validation(\n",
    "        model, criterion, test_loader,\n",
    "        epoch=EPOCHS, device=DEVICE, split_name='test'\n",
    "    )\n",
    "    print(f\"Test F1-score on best model: {test_f1:.3f}\")\n",
    "\n",
    "    # Save only final model\n",
    "    filename = (\n",
    "        f\"siamese_contrastive_test-f1={test_f1:.3f}\"\n",
    "        f\"{'_' + MODEL_NAME_POSTFIX if MODEL_NAME_POSTFIX else ''}\"\n",
    "        f\"{'_' + PRELOAD_MODEL_NAME if PRELOAD_MODEL_NAME else ''}\"\n",
    "        \".pt\"\n",
    "    )\n",
    "\n",
    "    final_path = (\n",
    "        Path(DATA_PATH) /\n",
    "        Path(DATA_PATH + RESULTS_DIR) /\n",
    "        filename\n",
    "    )\n",
    "\n",
    "    final_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(best_weights, final_path)\n",
    "    print(f\"Saved best‐F1 checkpoint to {final_path}\")\n",
    "\n",
    "    if MLFLOW_URI:\n",
    "        mlflow.log_metric(\"test_pos_accuracy\", test_pos_acc)\n",
    "        mlflow.log_metric(\"test_neg_accuracy\", test_neg_acc)\n",
    "        mlflow.log_metric(\"test_accuracy\", test_acc)\n",
    "        mlflow.log_metric(\"test_f1_score\", test_f1)\n",
    "        mlflow.end_run()\n",
    "\n",
    "_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70470186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
