{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcaee945",
   "metadata": {},
   "source": [
    "# Installs & tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d9b411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    import mlflow\n",
    "except ImportError:\n",
    "    !pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c65f9c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    import dotenv\n",
    "except ImportError:\n",
    "    !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40e77b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Log into huggingface via Kaggle Secrets\n",
    "\n",
    "# import os\n",
    "# import huggingface_hub\n",
    "# from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# user_secrets = UserSecretsClient()\n",
    "# HF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "\n",
    "# huggingface_hub.login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0c3f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Log into huggingface via .env\n",
    "\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# import huggingface_hub\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "# huggingface_hub.login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a0467",
   "metadata": {},
   "source": [
    "# Choose notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be91836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "## CHOOSE MODEL PARAMETERS #################################################\n",
    "\n",
    "DATA_PATH = 'data/'\n",
    "DEVICE='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "NAME_MODEL_NAME = 'cointegrated/rubert-tiny' # 'DeepPavlov/distilrubert-tiny-cased-conversational-v1'\n",
    "DESCRIPTION_MODEL_NAME = 'cointegrated/rubert-tiny'\n",
    "\n",
    "BATCH_SIZE=60 # uses 14.5GiB of 1 GPU\n",
    "NUM_WORKERS=2 # TODO: use multiple GPU, tune number of workers\n",
    "NUM_DEBUG_SAMPLES=None\n",
    "EPOCHS=20\n",
    "\n",
    "# BATCH_SIZE=1\n",
    "# NUM_WORKERS=0\n",
    "# NUM_DEBUG_SAMPLES=2\n",
    "# EPOCHS=2\n",
    "\n",
    "EMB_SIZE=768\n",
    "VALIDATION_SPLIT=.25\n",
    "SHUFFLE_DATASET=True\n",
    "RANDOM_SEED=42\n",
    "LR=9e-5\n",
    "MOMENTUM=0.9\n",
    "WEIGHT_DECAY=1e-2\n",
    "CONTRASTIVE_MARGIN=1.5\n",
    "CONTRASTIVE_THRESHOLD=0.3\n",
    "SHEDULER_PATIENCE=3 # in epochs\n",
    "\n",
    "MODEL_NAME_POSTFIX='splitting-by-query'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3d9e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHOOSE DATA #########################################################\n",
    "\n",
    "# # These table files need 'image_name_first', 'image_name_second' constructed from sku to be usable in current pipeline\n",
    "# TABLE_DATASET_FILE = 'tables_labeled/processed/labeled_1.3k_with-options.csv'\n",
    "# TABLE_DATASET_FILE = 'tables_labeled/processed/labeled_56k_with-options.csv'\n",
    "# IMG_DATASET_NAME = 'images_7k'\n",
    "# STRATIFY_COLS = None\n",
    "\n",
    "# TABLE_DATASET_FILE = 'tables_labeled/processed/labeled_5k_with-options.csv'\n",
    "# IMG_DATASET_NAME = 'images_7k' \n",
    "# STRATIFY_COLS = None\n",
    "\n",
    "# TABLE_DATASET_FILE = 'tables_WB_OZ_100/WB_OZ_100.csv'\n",
    "# TABLE_DATASET_FILE = 'tables_WB_OZ_100/WB_OZ_100_conjugated.csv'\n",
    "# TABLE_DATASET_FILE = 'tables_WB_OZ_100/WB_OZ_100_conjugated_shuffled_seed=42_fraction=1.csv'\n",
    "# TABLE_DATASET_FILE = 'tables_WB_OZ_100/WB_OZ_100_conjugated_shuffled_seed=42_fraction=0.5.csv'\n",
    "# IMG_DATASET_NAME = 'images_WB_OZ_100'\n",
    "# STRATIFY_COLS = None\n",
    "\n",
    "TABLE_DATASET_FILE = 'tables_OZ_geo_5500/processed/regex-pairwise-dataset_num-queries=20_num-pairs=6226_patterns-dict-hash=6dbf9b3ef9568e60cd959f87be7e3b26.csv'\n",
    "IMG_DATASET_NAME = 'images_OZ_geo_5500'\n",
    "STRATIFY_COLS = ['sku_first', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14b5eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOGGING PARAMS ######################################################################\n",
    "\n",
    "# MLFLOW_URI = \"http://176.56.185.96:5000\"\n",
    "# MLFLOW_URI = \"http://localhost:5000\"\n",
    "MLFLOW_URI = None\n",
    "\n",
    "MLFLOW_EXPERIMENT = \"siamese/1fold\"\n",
    "\n",
    "TELEGRAM_TOKEN = None\n",
    "# TELEGRAM_TOKEN = '' # set token to get notifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b40bc83",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00017085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from timm import create_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "# import transformers\n",
    "# from transformers import DistilBertModel, DistilBertConfig, DistilBertTokenizer,\\\n",
    "#         get_linear_schedule_with_warmup\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# import json\n",
    "# from itertools import product\n",
    "\n",
    "# import datasets\n",
    "# from datasets import Dataset, concatenate_datasets\n",
    "# import argparse\n",
    "import requests\n",
    "\n",
    "# from io import BytesIO\n",
    "# from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "# import more_itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import mlflow\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3494173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tg_report(text, token=None) -> None:\n",
    "    method = 'sendMessage'\n",
    "    chat_id = 324956476\n",
    "    _ = requests.post(\n",
    "            url='https://api.telegram.org/bot{0}/{1}'.format(token, method),\n",
    "            data={'chat_id': chat_id, 'text': text} \n",
    "        ).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34706f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuCLIPtiny(nn.Module):\n",
    "    def __init__(self, name_model_name):\n",
    "        super().__init__()\n",
    "        self.visual = create_model('convnext_tiny',\n",
    "                                   pretrained=False, # TODO: берём претрейн\n",
    "                                   num_classes=0,\n",
    "                                   in_chans=3)  # out 768\n",
    "\n",
    "        self.transformer = AutoModel.from_pretrained(name_model_name)\n",
    "        name_model_output_shape = self.transformer.config.hidden_size  # dynamically get hidden size\n",
    "        self.final_ln = torch.nn.Linear(name_model_output_shape, 768)  # now uses the transformer hidden size\n",
    "        self.logit_scale = torch.nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        return self.visual.stem[0].weight.dtype\n",
    "\n",
    "    def encode_image(self, image):\n",
    "        return self.visual(image.type(self.dtype))\n",
    "\n",
    "    def encode_text(self, input_ids, attention_mask):\n",
    "        x = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = x.last_hidden_state[:, 0, :]\n",
    "        x = self.final_ln(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, image, input_ids, attention_mask):\n",
    "        image_features = self.encode_image(image)\n",
    "        text_features = self.encode_text(input_ids, attention_mask)\n",
    "\n",
    "        # normalized features\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # cosine similarity as logits\n",
    "        logit_scale = self.logit_scale.exp()\n",
    "        logits_per_image = logit_scale * image_features @ text_features.t()\n",
    "        logits_per_text = logits_per_image.t()\n",
    "\n",
    "        return logits_per_image, logits_per_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84518fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        _convert_image_to_rgb,\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]), ])\n",
    "\n",
    "def _convert_image_to_rgb(image):\n",
    "    return image.convert(\"RGB\")\n",
    "\n",
    "class Tokenizers:\n",
    "    def __init__(self):\n",
    "        self.name_tokenizer = AutoTokenizer.from_pretrained(NAME_MODEL_NAME)\n",
    "        self.desc_tokenizer = AutoTokenizer.from_pretrained(DESCRIPTION_MODEL_NAME)\n",
    "\n",
    "    def tokenize_name(self, texts, max_len=77):\n",
    "        tokenized = self.name_tokenizer.batch_encode_plus(texts,\n",
    "                                                     truncation=True,\n",
    "                                                     add_special_tokens=True,\n",
    "                                                     max_length=max_len,\n",
    "                                                     padding='max_length',\n",
    "                                                     return_attention_mask=True,\n",
    "                                                     return_tensors='pt')\n",
    "        return torch.stack([tokenized[\"input_ids\"], tokenized[\"attention_mask\"]])\n",
    "    \n",
    "    def tokenize_description(self, texts, max_len=77):\n",
    "        tokenized = self.desc_tokenizer(texts,\n",
    "                                        truncation=True,\n",
    "                                        add_special_tokens=True,\n",
    "                                        max_length=max_len,\n",
    "                                        padding='max_length',\n",
    "                                        return_attention_mask=True,\n",
    "                                        return_tensors='pt')\n",
    "        return torch.stack([tokenized[\"input_ids\"], tokenized[\"attention_mask\"]])\n",
    "\n",
    "class SiameseRuCLIPDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df=None, labels=None, df_path=None, images_dir=DATA_PATH+'images/'):\n",
    "        # loads data either from path using `df_path` or directly from `df` argument\n",
    "        self.df = pd.read_csv(df_path) if df_path is not None else df\n",
    "        self.labels = labels\n",
    "        self.images_dir = images_dir\n",
    "        self.tokenizers = Tokenizers()\n",
    "        self.transform = get_transform()\n",
    "        # \n",
    "        self.max_len = 77\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        name_tokens = self.tokenizers.tokenize_name([str(row.name_first), \n",
    "                                               str(row.name_second)], max_len=self.max_len)\n",
    "        name_first = name_tokens[:, 0, :] # [input_ids, attention_mask]\n",
    "        name_second = name_tokens[:, 1, :]\n",
    "        desc_tokens = self.tokenizers.tokenize_description([str(row.description_first), \n",
    "                                               str(row.description_second)])\n",
    "        desc_first = desc_tokens[:, 0, :] # [input_ids, attention_mask]\n",
    "        desc_second = desc_tokens[:, 1, :]\n",
    "        im_first = cv2.imread(os.path.join(self.images_dir, row.image_name_first))\n",
    "        im_first = cv2.cvtColor(im_first, cv2.COLOR_BGR2RGB)\n",
    "        im_first = Image.fromarray(im_first)\n",
    "        im_first = self.transform(im_first)\n",
    "        im_second = cv2.imread(os.path.join(self.images_dir, row.image_name_second))\n",
    "        im_second = cv2.cvtColor(im_second, cv2.COLOR_BGR2RGB)\n",
    "        im_second = Image.fromarray(im_second)\n",
    "        im_second = self.transform(im_second)\n",
    "        label = self.labels[idx]\n",
    "        return im_first, name_first, desc_first, im_second, name_second, desc_second, label\n",
    "\n",
    "    def __len__(self,):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2d263be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "class SiameseRuCLIP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 device: str,\n",
    "                 name_model_name: str,\n",
    "                 description_model_name: str,\n",
    "                 models_dir: str = None,\n",
    "                 preload_ruclip: bool = False,\n",
    "                 preload_model_name: str = None):\n",
    "        \"\"\"\n",
    "        Initializes the SiameseRuCLIP model.\n",
    "        Required parameters:\n",
    "          - models_dir: directory containing saved checkpoints.\n",
    "          - name_model_name: model name for text (name) branch.\n",
    "          - description_model_name: model name for description branch.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        device = torch.device(device)\n",
    "\n",
    "        # Initialize RuCLIPtiny\n",
    "        self.ruclip = RuCLIPtiny(name_model_name)\n",
    "        if preload_ruclip:\n",
    "            std = torch.load(\n",
    "                os.path.join(models_dir, preload_model_name),\n",
    "                weights_only=True,\n",
    "                map_location=device\n",
    "            )\n",
    "            self.ruclip.load_state_dict(std)\n",
    "            self.ruclip.eval()\n",
    "        self.ruclip = self.ruclip.to(device)\n",
    "\n",
    "        # Initialize the description transformer\n",
    "        self.description_transformer = AutoModel.from_pretrained(description_model_name)\n",
    "        self.description_transformer = self.description_transformer.to(device)\n",
    "\n",
    "        # Determine dimensionality\n",
    "        vision_dim = self.ruclip.visual.num_features\n",
    "        name_dim = self.ruclip.final_ln.out_features\n",
    "        desc_dim = self.description_transformer.config.hidden_size\n",
    "        self.hidden_dim = vision_dim + name_dim + desc_dim\n",
    "\n",
    "        # Define MLP head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim // 2, self.hidden_dim // 4),\n",
    "        ).to(device)\n",
    "\n",
    "    def encode_image(self, image):\n",
    "        return self.ruclip.encode_image(image)\n",
    "\n",
    "    def encode_name(self, name):\n",
    "        return self.ruclip.encode_text(name[:, 0, :], name[:, 1, :])\n",
    "\n",
    "    def encode_description(self, desc):\n",
    "        last_hidden_states = self.description_transformer(desc[:, 0, :], desc[:, 1, :]).last_hidden_state\n",
    "        attention_mask = desc[:, 1, :]\n",
    "        return average_pool(last_hidden_states, attention_mask)\n",
    "\n",
    "    def get_final_embedding(self, im, name, desc):\n",
    "        image_emb = self.encode_image(im)\n",
    "        name_emb = self.encode_name(name)\n",
    "        desc_emb = self.encode_description(desc)\n",
    "\n",
    "        # Concatenate the embeddings and forward through the head\n",
    "        combined_emb = torch.cat([image_emb, name_emb, desc_emb], dim=1)\n",
    "        final_embedding = self.head(combined_emb)\n",
    "        return final_embedding\n",
    "\n",
    "    def forward(self, im1, name1, desc1, im2, name2, desc2):\n",
    "        out1 = self.get_final_embedding(im1, name1, desc1)\n",
    "        out2 = self.get_final_embedding(im2, name2, desc2)\n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "987d1ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def __name__(self,):\n",
    "        return 'ContrastiveLoss'\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        pos = (1-label) * torch.pow(euclidean_distance, 2)\n",
    "        neg = label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        loss_contrastive = torch.mean( pos + neg )\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9c6281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pair(output1, output2, target, threshold):\n",
    "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "    # меньше границы, там где будет True — конкуренты\n",
    "    cond = euclidean_distance < threshold\n",
    "    pos_sum = 0\n",
    "    neg_sum = 0\n",
    "    pos_acc = 0\n",
    "    neg_acc = 0\n",
    "\n",
    "    for i in range(len(cond)):\n",
    "        # 1 значит не конкуренты\n",
    "        if target[i]:\n",
    "            neg_sum+=1\n",
    "            # 0 в cond значит дальше друг от друга чем threshold\n",
    "            if not cond[i]:\n",
    "                neg_acc+=1\n",
    "        elif not target[i]:\n",
    "            pos_sum+=1\n",
    "            if cond[i]:\n",
    "                pos_acc+=1\n",
    "\n",
    "    return pos_acc, pos_sum, neg_acc, neg_sum\n",
    "\n",
    "def predict(out1, out2, threshold=CONTRASTIVE_THRESHOLD):\n",
    "    # вернёт 1 если похожи\n",
    "    return F.pairwise_distance(out1, out2) < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6664f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, data_loader, epoch,\n",
    "               device='cpu', split_name='validation',\n",
    "               threshold=CONTRASTIVE_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Runs one epoch of validation (or test), computing:\n",
    "      - avg_loss\n",
    "      - positive/negative accuracies\n",
    "      - avg_acc\n",
    "      - F1\n",
    "    Logs valid_f1_score to MLflow if MLFLOW_URI is set.\n",
    "    Returns: pos_acc, neg_acc, avg_acc, f1, avg_loss\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    pos_acc_sum = neg_acc_sum = 0.0\n",
    "    pos_count = neg_count = 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=f\"{split_name}\"):\n",
    "            im1, name1, desc1, im2, name2, desc2, label = batch\n",
    "            im1, name1, desc1, im2, name2, desc2, label = (\n",
    "                im1.to(device), name1.to(device), desc1.to(device),\n",
    "                im2.to(device), name2.to(device), desc2.to(device),\n",
    "                label.to(device)\n",
    "            )\n",
    "            out1, out2 = model(im1, name1, desc1, im2, name2, desc2)\n",
    "            loss = criterion(out1, out2, label)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # compute pos/neg accuracy\n",
    "            distances = F.pairwise_distance(out1, out2)\n",
    "            preds = (distances < threshold).long()\n",
    "            pos_mask = (label == 0)\n",
    "            neg_mask = (label == 1)\n",
    "            pos_acc_sum += (preds[pos_mask] == 1).sum().item()\n",
    "            neg_acc_sum += (preds[neg_mask] == 0).sum().item()\n",
    "            pos_count   += pos_mask.sum().item()\n",
    "            neg_count   += neg_mask.sum().item()\n",
    "\n",
    "            # for F1\n",
    "            all_preds.extend(preds.cpu().numpy().tolist())\n",
    "            all_labels.extend((label.cpu().numpy() == 0).astype(int).tolist())\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    pos_acc  = pos_acc_sum / pos_count if pos_count else 0.0\n",
    "    neg_acc  = neg_acc_sum / neg_count if neg_count else 0.0\n",
    "    avg_acc  = (pos_acc + neg_acc) / 2.0\n",
    "    f1       = f1_score(all_labels, all_preds, zero_division=0)\n",
    "\n",
    "    report = (f\"[{split_name}] Epoch {epoch} – \"\n",
    "              f\"loss: {avg_loss:.4f}, \"\n",
    "              f\"P Acc: {pos_acc:.3f}, \"\n",
    "              f\"N Acc: {neg_acc:.3f}, \"\n",
    "              f\"Avg Acc: {avg_acc:.3f}, \"\n",
    "              f\"F1: {f1:.3f}\")\n",
    "    print(report)\n",
    "    make_tg_report(report, TELEGRAM_TOKEN)\n",
    "\n",
    "    if MLFLOW_URI:\n",
    "        mlflow.log_metric(\"valid_f1_score\", f1, step=epoch)\n",
    "\n",
    "    return pos_acc, neg_acc, avg_acc, f1, avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34b5c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot epoch after each train epoch in `train()`\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def plot_epoch(loss_history, filename=\"data/runs_artifacts/epoch_loss.png\") -> None:\n",
    "    Path(filename).parent.mkdir(parents=True, exist_ok=True)\n",
    "    display.clear_output(wait=True)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.title(\"Training loss\")\n",
    "    plt.xlabel(\"Iteration number\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(loss_history, 'b')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)  # Save the plot to a file\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4952b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def train(model, optimizer, criterion,\n",
    "          epochs_num, train_loader, valid_loader=None,\n",
    "          device='cpu', print_epoch=False,\n",
    "          models_dir=None):\n",
    "    \"\"\"\n",
    "    Trains the model for `epochs_num` epochs, saving a checkpoint\n",
    "    each epoch into `models_dir` if given, and selects the best by validation F1.\n",
    "    Returns:\n",
    "      train_losses: list of avg train loss per epoch\n",
    "      val_losses:   list of avg val loss per epoch (only if valid_loader)\n",
    "      best_valid_f1, best_weights\n",
    "    \"\"\"\n",
    "    model.to(device).train()\n",
    "    train_losses, val_losses = [], []\n",
    "    best_valid_f1 = float('-inf')\n",
    "    best_weights = None\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, mode=\"max\",\n",
    "        factor=0.1, patience=SHEDULER_PATIENCE,\n",
    "        threshold=1e-4, threshold_mode='rel',\n",
    "        cooldown=0, min_lr=0, eps=1e-8\n",
    "    )\n",
    "\n",
    "    if models_dir:\n",
    "        Path(models_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for epoch in range(1, epochs_num + 1):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"train {epoch}/{epochs_num}\"):\n",
    "            im1, name1, desc1, im2, name2, desc2, label = [t.to(device) for t in batch]\n",
    "            optimizer.zero_grad()\n",
    "            out1, out2 = model(im1, name1, desc1, im2, name2, desc2)\n",
    "            loss = criterion(out1, out2, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        if print_epoch and valid_loader is not None:\n",
    "            _, _, _, val_f1, avg_val_loss = validation(\n",
    "                model, criterion, valid_loader,\n",
    "                epoch, device, split_name='validation'\n",
    "            )\n",
    "            val_losses.append(avg_val_loss)\n",
    "\n",
    "            scheduler.step(val_f1)\n",
    "\n",
    "            if models_dir:\n",
    "                ckpt_path = Path(models_dir) / f\"checkpoint_epoch_{epoch}.pt\"\n",
    "                torch.save(model.state_dict(), ckpt_path)\n",
    "\n",
    "            if val_f1 > best_valid_f1:\n",
    "                best_valid_f1 = val_f1\n",
    "                best_weights = model.state_dict().copy()\n",
    "\n",
    "    print(f\"Best validation F1: {best_valid_f1:.3f}\")\n",
    "    return train_losses, val_losses, best_valid_f1, best_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481940bc",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e226754b",
   "metadata": {},
   "source": [
    "## Download data from HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b8cde88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79d919262df4e6eb2c2927e80504b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download models' weights & text/image datasets\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_ID = \"INDEEPA/clip-siamese\"\n",
    "LOCAL_DIR = Path(\"data/train_results\")\n",
    "LOCAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=REPO_ID,\n",
    "    repo_type='dataset',\n",
    "    local_dir='data',\n",
    "    allow_patterns=[\n",
    "        \"train_results/cc12m*.pt\",\n",
    "        TABLE_DATASET_FILE,\n",
    "        f\"{IMG_DATASET_NAME}.zip\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "!unzip -n -q data/{IMG_DATASET_NAME}.zip -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d35d53",
   "metadata": {},
   "source": [
    "## Split data by query sku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "387fca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique query sku: 20\n"
     ]
    }
   ],
   "source": [
    "TABLE_DATASET_PATH = DATA_PATH + TABLE_DATASET_FILE\n",
    "\n",
    "labeled = pd.read_csv(TABLE_DATASET_PATH)\n",
    "print(f\"Unique query sku: {labeled.sku_query.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c414d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/val/test\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "def split_pairwise(\n",
    "    df: pd.DataFrame,\n",
    "    test_size: float = 0.20,\n",
    "    random_state: int | None = None,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Leakage-free DEV / TEST split for a pair-wise SKU dataset.\n",
    "    Input `df` must have columns ['sku_query','sku_candidate','label'].\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    test_rows, dev_rows   = [], []\n",
    "    test_entities: set[str] = set()\n",
    "\n",
    "    # ---- iterate over each original query SKU ------------------------------\n",
    "    for q_sku, grp in df.groupby(\"sku_query\"):\n",
    "        pos_idx = grp.index[grp.label == 1].tolist()\n",
    "        neg_idx = grp.index[grp.label == 0].tolist()\n",
    "\n",
    "        # --- (1) sample TEST rows -------------------------------------------\n",
    "        n_pos = int(np.ceil(test_size * len(pos_idx))) if pos_idx else 0\n",
    "        n_neg = int(np.ceil(test_size * len(neg_idx))) if neg_idx else 0\n",
    "\n",
    "        pos_test = rng.choice(pos_idx, size=n_pos, replace=False) if n_pos else []\n",
    "        neg_test = rng.choice(neg_idx, size=n_neg, replace=False) if n_neg else []\n",
    "\n",
    "        test_rows.extend(pos_test)\n",
    "        test_rows.extend(neg_test)\n",
    "\n",
    "        # register every entity that just entered TEST\n",
    "        test_entities.add(q_sku)\n",
    "        test_entities.update(df.loc[pos_test, \"sku_candidate\"])\n",
    "        test_entities.update(df.loc[neg_test, \"sku_candidate\"])\n",
    "\n",
    "        # --- (2) build DEV from remaining rows ------------------------------\n",
    "        remain_pos = list(set(pos_idx) - set(pos_test))\n",
    "        remain_neg = list(set(neg_idx) - set(neg_test))\n",
    "\n",
    "        if remain_pos:\n",
    "            # choose substitute query (one of the remaining positives)\n",
    "            sub_idx  = int(rng.choice(remain_pos))\n",
    "            sub_sku  = df.loc[sub_idx, \"sku_candidate\"]\n",
    "\n",
    "            for idx in remain_pos:\n",
    "                if idx == sub_idx:            # skip (sub,sub) self-pair\n",
    "                    continue\n",
    "                row = df.loc[idx].copy()\n",
    "                row[\"sku_query\"] = sub_sku\n",
    "                dev_rows.append(row)\n",
    "\n",
    "            for idx in remain_neg:\n",
    "                row = df.loc[idx].copy()\n",
    "                row[\"sku_query\"] = sub_sku\n",
    "                dev_rows.append(row)\n",
    "\n",
    "    # ---- materialise the splits -------------------------------------------\n",
    "    test_df = df.loc[test_rows].reset_index(drop=True)\n",
    "    dev_df  = pd.DataFrame(dev_rows).reset_index(drop=True)\n",
    "\n",
    "    # ---- (3) final purge: remove any row touching a TEST entity ------------\n",
    "    mask = ~(dev_df[\"sku_query\"].isin(test_entities) |\n",
    "             dev_df[\"sku_candidate\"].isin(test_entities))\n",
    "    dev_df = dev_df[mask].reset_index(drop=True)\n",
    "\n",
    "    return dev_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e00ad1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2548, 95), (409, 95), (332, 95))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into train/val/test\n",
    "\n",
    "dev_df,  test_df  = split_pairwise(labeled,  test_size=0.05, random_state=42)\n",
    "train_df, val_df  = split_pairwise(dev_df,   test_size=0.1, random_state=42)\n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efc1fa9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       hard_negative  positive  total\n",
      "split                                \n",
      "train           2210       338   2548\n",
      "val              348        61    409\n",
      "test             280        52    332\n"
     ]
    }
   ],
   "source": [
    "# Print positive/hard_negative pairs count per each split \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# collect your splits in a dict\n",
    "splits = {\n",
    "    'train': train_df,\n",
    "    'val':   val_df,\n",
    "    'test':  test_df,\n",
    "}\n",
    "\n",
    "# build the summary_df records\n",
    "records = []\n",
    "for name, df in splits.items():\n",
    "    vc = df['label'].value_counts()\n",
    "    records.append({\n",
    "        'split':    name,\n",
    "        'hard_negative': vc.get(0, 0),\n",
    "        'positive': vc.get(1, 0),\n",
    "        'total':    len(df),\n",
    "    })\n",
    "\n",
    "# create a DataFrame and set the split name as index\n",
    "summary_df = (\n",
    "    pd.DataFrame(records)\n",
    "      .set_index('split')\n",
    "      .astype(int)\n",
    ")\n",
    "\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bed0574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All sanity checks passed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def sanity_checks(train: pd.DataFrame, val: pd.DataFrame, test: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Verify that:\n",
    "      1) Each query SKU appears in exactly one split\n",
    "      2) No SKU (query or candidate) overlaps across splits\n",
    "      3) No duplicate pairs across splits\n",
    "      4) Each split has at least one positive and one hard_negative\n",
    "    \"\"\"\n",
    "    # 1) Query-level disjointness\n",
    "    q_train = set(train[\"sku_query\"])\n",
    "    q_val   = set(val  [\"sku_query\"])\n",
    "    q_test  = set(test [\"sku_query\"])\n",
    "    assert not (q_train & q_val),   f\"Query SKU overlap train↔val: {q_train & q_val}\"\n",
    "    assert not (q_train & q_test),  f\"Query SKU overlap train↔test: {q_train & q_test}\"\n",
    "    assert not (q_val   & q_test),  f\"Query SKU overlap val↔test:   {q_val   & q_test}\"\n",
    "    \n",
    "    # 2) Global SKU disjointness (query OR candidate)\n",
    "    def all_skus(df):\n",
    "        return set(df[\"sku_query\"]) | set(df[\"sku_candidate\"])\n",
    "    s_train, s_val, s_test = all_skus(train), all_skus(val), all_skus(test)\n",
    "    assert not (s_train & s_val),   f\"SKU overlap train↔val: {s_train & s_val}\"\n",
    "    assert not (s_train & s_test),  f\"SKU overlap train↔test: {s_train & s_test}\"\n",
    "    assert not (s_val   & s_test),  f\"SKU overlap val↔test:   {s_val   & s_test}\"\n",
    "    \n",
    "    # 3) Unique pairs\n",
    "    all_pairs = pd.concat([train, val, test], ignore_index=True)\n",
    "    dupes = all_pairs.duplicated(subset=[\"sku_query\",\"sku_candidate\",\"label\"])\n",
    "    assert not dupes.any(), f\"Found {dupes.sum()} duplicate pairs across splits\"\n",
    "    \n",
    "    # 4) Label coverage in each split\n",
    "    for name, df in [(\"train\", train), (\"val\", val), (\"test\", test)]:\n",
    "        labels = df[\"label\"].unique()\n",
    "        assert set(labels) == {0,1}, f\"{name} split has labels {labels}, expected {{0,1}}\"\n",
    "    \n",
    "    print(\"✅ All sanity checks passed!\")\n",
    "\n",
    "sanity_checks(train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4aa24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_split(df: pd.DataFrame, num_samples: int | None, random_state: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    If num_samples is set, take up to that many random rows;\n",
    "    otherwise just shuffle the entire DataFrame.\n",
    "    Always resets the index.\n",
    "    \"\"\"\n",
    "    if num_samples is not None:\n",
    "        n = min(num_samples, len(df))\n",
    "        out = df.sample(n=n, random_state=random_state)\n",
    "    else:\n",
    "        out = df.sample(frac=1, random_state=random_state)\n",
    "    return out.reset_index(drop=True)\n",
    "\n",
    "# apply to each split\n",
    "train_df = sample_split(train_df, NUM_DEBUG_SAMPLES, RANDOM_SEED)\n",
    "val_df   = sample_split(val_df,   NUM_DEBUG_SAMPLES, RANDOM_SEED)\n",
    "test_df  = sample_split(test_df,  NUM_DEBUG_SAMPLES, RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef17b84c",
   "metadata": {},
   "source": [
    "# Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb31be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def _run():\n",
    "    images_dir = os.path.join(DATA_PATH, IMG_DATASET_NAME)\n",
    "\n",
    "    # 1) Prepare splits and rename columns\n",
    "    splits = {\n",
    "        'train':      train_df,\n",
    "        'validation': val_df,\n",
    "        'test':       test_df,\n",
    "    }\n",
    "    loaders = {}\n",
    "\n",
    "    for split_name, df in splits.items():\n",
    "        # rename for dataset compatibility\n",
    "        df = df.rename(columns={\n",
    "            col: col.replace(\"_query\", \"_first\").replace(\"_candidate\", \"_second\")\n",
    "            for col in df.columns\n",
    "            if \"_query\" in col or \"_candidate\" in col\n",
    "        })\n",
    "\n",
    "        # build dataset + loader\n",
    "        labels = df[\"label\"].values\n",
    "        ds     = SiameseRuCLIPDataset(df.drop(columns=\"label\"), labels, images_dir=images_dir)\n",
    "\n",
    "        shuffle = (split_name == 'train')\n",
    "        loaders[split_name] = DataLoader(\n",
    "            ds,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=NUM_WORKERS\n",
    "        )\n",
    "\n",
    "    train_loader = loaders['train']\n",
    "    valid_loader = loaders['validation']\n",
    "    test_loader  = loaders['test']\n",
    "\n",
    "    print(\"Loading model and optimizer…\")\n",
    "    model     = SiameseRuCLIP(DEVICE, NAME_MODEL_NAME, DESCRIPTION_MODEL_NAME).to(DEVICE)\n",
    "    criterion = ContrastiveLoss(margin=CONTRASTIVE_MARGIN).to(DEVICE)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    print(\"Done.\")\n",
    "\n",
    "    # Temporary dir for intermediate checkpoints\n",
    "    with tempfile.TemporaryDirectory() as tmp_ckpt_dir:\n",
    "        train_losses, val_losses, best_f1, best_weights = train(\n",
    "            model, optimizer, criterion,\n",
    "            EPOCHS, train_loader, valid_loader,\n",
    "            print_epoch=True,\n",
    "            device=DEVICE,\n",
    "            models_dir=tmp_ckpt_dir\n",
    "        )\n",
    "    print(f\"→ Best validation F1: {best_f1:.3f}\")\n",
    "\n",
    "    # Plot train vs. val loss by epoch\n",
    "    epochs = list(range(1, len(train_losses) + 1))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(epochs, train_losses, label='Train Loss')\n",
    "    ax.plot(epochs, val_losses,   label='Val   Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Training & Validation Loss by Epoch')\n",
    "    ax.legend()\n",
    "    if MLFLOW_URI:\n",
    "        mlflow.log_figure(fig, 'loss_by_epoch.png')\n",
    "\n",
    "    # TODO: display after each train epoch\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "    # Final test on the best model\n",
    "    model.load_state_dict(best_weights)\n",
    "    model.eval()\n",
    "    test_pos_acc, test_neg_acc, test_acc, test_f1, test_loss = validation(\n",
    "        model, criterion, test_loader,\n",
    "        epoch=EPOCHS, device=DEVICE, split_name='test'\n",
    "    )\n",
    "    print(f\"Test F1-score on best model: {test_f1:.3f}\")\n",
    "\n",
    "    # Save only final model\n",
    "    filename = (\n",
    "        f\"siamese_contrastive_test-f1={test_f1:.3f}\"\n",
    "        f\"{'_' + MODEL_NAME_POSTFIX if MODEL_NAME_POSTFIX else ''}.pt\"\n",
    "    )\n",
    "\n",
    "    final_path = (\n",
    "        Path(DATA_PATH) /\n",
    "        \"train_results\" /\n",
    "        filename\n",
    "    )\n",
    "\n",
    "    final_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(best_weights, final_path)\n",
    "    print(f\"Saved best‐F1 checkpoint to {final_path}\")\n",
    "\n",
    "    if MLFLOW_URI:\n",
    "        mlflow.log_metric(\"test_pos_accuracy\", test_pos_acc)\n",
    "        mlflow.log_metric(\"test_neg_accuracy\", test_neg_acc)\n",
    "        mlflow.log_metric(\"test_accuracy\", test_acc)\n",
    "        mlflow.log_metric(\"test_f1_score\", test_f1)\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6511a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 2/2 [00:00<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch 2 – loss: 1.4657, P Acc: 0.000, N Acc: 0.000, Avg Acc: 0.000, F1: 0.000\n",
      "Test F1-score on best model: 0.000\n",
      "Saved best‐F1 checkpoint to data/train_results/siamese_contrastive_test-f1=0.000_splitting-by-query.pt\n"
     ]
    }
   ],
   "source": [
    "_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
