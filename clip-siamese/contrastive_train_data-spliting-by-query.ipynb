{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcaee945",
   "metadata": {},
   "source": [
    "# Installs & tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9d9b411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    import mlflow\n",
    "except ImportError:\n",
    "    !pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c65f9c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    import dotenv\n",
    "except ImportError:\n",
    "    !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "40e77b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Log into huggingface via Kaggle Secrets\n",
    "\n",
    "# import os\n",
    "# import huggingface_hub\n",
    "# from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# user_secrets = UserSecretsClient()\n",
    "# HF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "\n",
    "# huggingface_hub.login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b0c3f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Log into huggingface via .env\n",
    "\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# import huggingface_hub\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "# huggingface_hub.login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a0467",
   "metadata": {},
   "source": [
    "# Choose notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "be91836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "## CHOOSE MODEL PARAMETERS #################################################\n",
    "\n",
    "MODEL_NAME_POSTFIX='splitting-by-query'\n",
    "NAME_MODEL_NAME = 'cointegrated/rubert-tiny' # 'DeepPavlov/distilrubert-tiny-cased-conversational-v1'\n",
    "DESCRIPTION_MODEL_NAME = 'cointegrated/rubert-tiny'\n",
    "\n",
    "DATA_PATH = 'data/'\n",
    "RESULTS_DIR = 'train_results/'\n",
    "\n",
    "# BATCH_SIZE=60 # uses 14.5GiB of 1 GPU\n",
    "# NUM_WORKERS=2 # TODO: use multiple GPU, tune number of workers\n",
    "# NUM_DEBUG_SAMPLES=None\n",
    "# EPOCHS=20\n",
    "\n",
    "BATCH_SIZE=1\n",
    "NUM_WORKERS=0\n",
    "NUM_DEBUG_SAMPLES=2\n",
    "EPOCHS=2\n",
    "\n",
    "PRELOAD_MODEL_NAME = 'cc12m_rubert_tiny_ep_1.pt' # preload ruclip\n",
    "# PRELOAD_MODEL_NAME = None\n",
    "\n",
    "VALIDATION_SPLIT=.05\n",
    "TEST_SPLIT=.1\n",
    "RANDOM_SEED=42\n",
    "LR=9e-5\n",
    "MOMENTUM=0.9\n",
    "WEIGHT_DECAY=1e-2\n",
    "CONTRASTIVE_MARGIN=1.5\n",
    "CONTRASTIVE_THRESHOLD=0.3\n",
    "SHEDULER_PATIENCE=3 # in epochs\n",
    "\n",
    "DEVICE='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f3d9e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHOOSE DATA #########################################################\n",
    "\n",
    "# # These table files need 'image_name_first', 'image_name_second' constructed from sku to be usable in current pipeline\n",
    "# TABLE_DATASET_FILE = 'tables_labeled/processed/labeled_1.3k_with-options.csv'\n",
    "# TABLE_DATASET_FILE = 'tables_labeled/processed/labeled_56k_with-options.csv'\n",
    "# IMG_DATASET_NAME = 'images_7k'\n",
    "# STRATIFY_COLS = None\n",
    "\n",
    "# TABLE_DATASET_FILE = 'tables_labeled/processed/labeled_5k_with-options.csv'\n",
    "# IMG_DATASET_NAME = 'images_7k' \n",
    "# STRATIFY_COLS = None\n",
    "\n",
    "# TABLE_DATASET_FILE = 'tables_WB_OZ_100/WB_OZ_100.csv'\n",
    "# TABLE_DATASET_FILE = 'tables_WB_OZ_100/WB_OZ_100_conjugated.csv'\n",
    "# TABLE_DATASET_FILE = 'tables_WB_OZ_100/WB_OZ_100_conjugated_shuffled_seed=42_fraction=1.csv'\n",
    "# TABLE_DATASET_FILE = 'tables_WB_OZ_100/WB_OZ_100_conjugated_shuffled_seed=42_fraction=0.5.csv'\n",
    "# IMG_DATASET_NAME = 'images_WB_OZ_100'\n",
    "# STRATIFY_COLS = None\n",
    "\n",
    "TABLE_DATASET_FILE = 'tables_OZ_geo_5500/processed/regex-pairwise-dataset_num-queries=20_num-pairs=6226_patterns-dict-hash=6dbf9b3ef9568e60cd959f87be7e3b26.csv'\n",
    "IMG_DATASET_NAME = 'images_OZ_geo_5500'\n",
    "STRATIFY_COLS = ['sku_first', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "14b5eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOGGING PARAMS ######################################################################\n",
    "\n",
    "# MLFLOW_URI = \"http://176.56.185.96:5000\"\n",
    "# MLFLOW_URI = \"http://localhost:5000\"\n",
    "MLFLOW_URI = None\n",
    "\n",
    "MLFLOW_EXPERIMENT = \"siamese/1fold\"\n",
    "\n",
    "TELEGRAM_TOKEN = None\n",
    "# TELEGRAM_TOKEN = '' # set token to get notifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b40bc83",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "00017085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from timm import create_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "# import transformers\n",
    "# from transformers import DistilBertModel, DistilBertConfig, DistilBertTokenizer,\\\n",
    "#         get_linear_schedule_with_warmup\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# import json\n",
    "# from itertools import product\n",
    "\n",
    "# import datasets\n",
    "# from datasets import Dataset, concatenate_datasets\n",
    "# import argparse\n",
    "import requests\n",
    "\n",
    "# from io import BytesIO\n",
    "# from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "# import more_itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import mlflow\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3494173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tg_report(text, token=None) -> None:\n",
    "    method = 'sendMessage'\n",
    "    chat_id = 324956476\n",
    "    _ = requests.post(\n",
    "            url='https://api.telegram.org/bot{0}/{1}'.format(token, method),\n",
    "            data={'chat_id': chat_id, 'text': text} \n",
    "        ).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "34706f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuCLIPtiny(nn.Module):\n",
    "    def __init__(self, name_model_name):\n",
    "        super().__init__()\n",
    "        self.visual = create_model('convnext_tiny',\n",
    "                                   pretrained=False, # TODO: берём претрейн\n",
    "                                   num_classes=0,\n",
    "                                   in_chans=3)  # out 768\n",
    "\n",
    "        self.transformer = AutoModel.from_pretrained(name_model_name)\n",
    "        name_model_output_shape = self.transformer.config.hidden_size  # dynamically get hidden size\n",
    "        self.final_ln = torch.nn.Linear(name_model_output_shape, 768)  # now uses the transformer hidden size\n",
    "        self.logit_scale = torch.nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        return self.visual.stem[0].weight.dtype\n",
    "\n",
    "    def encode_image(self, image):\n",
    "        return self.visual(image.type(self.dtype))\n",
    "\n",
    "    def encode_text(self, input_ids, attention_mask):\n",
    "        x = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = x.last_hidden_state[:, 0, :]\n",
    "        x = self.final_ln(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, image, input_ids, attention_mask):\n",
    "        image_features = self.encode_image(image)\n",
    "        text_features = self.encode_text(input_ids, attention_mask)\n",
    "\n",
    "        # normalized features\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # cosine similarity as logits\n",
    "        logit_scale = self.logit_scale.exp()\n",
    "        logits_per_image = logit_scale * image_features @ text_features.t()\n",
    "        logits_per_text = logits_per_image.t()\n",
    "\n",
    "        return logits_per_image, logits_per_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "84518fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        _convert_image_to_rgb,\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]), ])\n",
    "\n",
    "def _convert_image_to_rgb(image):\n",
    "    return image.convert(\"RGB\")\n",
    "\n",
    "class Tokenizers:\n",
    "    def __init__(self):\n",
    "        self.name_tokenizer = AutoTokenizer.from_pretrained(NAME_MODEL_NAME)\n",
    "        self.desc_tokenizer = AutoTokenizer.from_pretrained(DESCRIPTION_MODEL_NAME)\n",
    "\n",
    "    def tokenize_name(self, texts, max_len=77):\n",
    "        tokenized = self.name_tokenizer.batch_encode_plus(texts,\n",
    "                                                     truncation=True,\n",
    "                                                     add_special_tokens=True,\n",
    "                                                     max_length=max_len,\n",
    "                                                     padding='max_length',\n",
    "                                                     return_attention_mask=True,\n",
    "                                                     return_tensors='pt')\n",
    "        return torch.stack([tokenized[\"input_ids\"], tokenized[\"attention_mask\"]])\n",
    "    \n",
    "    def tokenize_description(self, texts, max_len=77):\n",
    "        tokenized = self.desc_tokenizer(texts,\n",
    "                                        truncation=True,\n",
    "                                        add_special_tokens=True,\n",
    "                                        max_length=max_len,\n",
    "                                        padding='max_length',\n",
    "                                        return_attention_mask=True,\n",
    "                                        return_tensors='pt')\n",
    "        return torch.stack([tokenized[\"input_ids\"], tokenized[\"attention_mask\"]])\n",
    "\n",
    "class SiameseRuCLIPDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df=None, labels=None, df_path=None, images_dir=DATA_PATH+'images/'):\n",
    "        # loads data either from path using `df_path` or directly from `df` argument\n",
    "        self.df = pd.read_csv(df_path) if df_path is not None else df\n",
    "        self.labels = labels\n",
    "        self.images_dir = images_dir\n",
    "        self.tokenizers = Tokenizers()\n",
    "        self.transform = get_transform()\n",
    "        # \n",
    "        self.max_len = 77\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        name_tokens = self.tokenizers.tokenize_name([str(row.name_first), \n",
    "                                               str(row.name_second)], max_len=self.max_len)\n",
    "        name_first = name_tokens[:, 0, :] # [input_ids, attention_mask]\n",
    "        name_second = name_tokens[:, 1, :]\n",
    "        desc_tokens = self.tokenizers.tokenize_description([str(row.description_first), \n",
    "                                               str(row.description_second)])\n",
    "        desc_first = desc_tokens[:, 0, :] # [input_ids, attention_mask]\n",
    "        desc_second = desc_tokens[:, 1, :]\n",
    "        im_first = cv2.imread(os.path.join(self.images_dir, row.image_name_first))\n",
    "        im_first = cv2.cvtColor(im_first, cv2.COLOR_BGR2RGB)\n",
    "        im_first = Image.fromarray(im_first)\n",
    "        im_first = self.transform(im_first)\n",
    "        im_second = cv2.imread(os.path.join(self.images_dir, row.image_name_second))\n",
    "        im_second = cv2.cvtColor(im_second, cv2.COLOR_BGR2RGB)\n",
    "        im_second = Image.fromarray(im_second)\n",
    "        im_second = self.transform(im_second)\n",
    "        label = self.labels[idx]\n",
    "        return im_first, name_first, desc_first, im_second, name_second, desc_second, label\n",
    "\n",
    "    def __len__(self,):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e2d263be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "class SiameseRuCLIP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 device: str,\n",
    "                 name_model_name: str,\n",
    "                 description_model_name: str,\n",
    "                 preload_model_name: str = None,\n",
    "                 models_dir: str = None):\n",
    "        \"\"\"\n",
    "        Initializes the SiameseRuCLIP model.\n",
    "        Required parameters:\n",
    "          - models_dir: directory containing saved checkpoints.\n",
    "          - name_model_name: model name for text (name) branch.\n",
    "          - description_model_name: model name for description branch.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        device = torch.device(device)\n",
    "\n",
    "        # Initialize RuCLIPtiny\n",
    "        self.ruclip = RuCLIPtiny(name_model_name)\n",
    "        if preload_model_name is not None:\n",
    "            std = torch.load(\n",
    "                os.path.join(models_dir, preload_model_name),\n",
    "                weights_only=True,\n",
    "                map_location=device\n",
    "            )\n",
    "            self.ruclip.load_state_dict(std)\n",
    "            self.ruclip.eval()\n",
    "        self.ruclip = self.ruclip.to(device)\n",
    "\n",
    "        # Initialize the description transformer\n",
    "        self.description_transformer = AutoModel.from_pretrained(description_model_name)\n",
    "        self.description_transformer = self.description_transformer.to(device)\n",
    "\n",
    "        # Determine dimensionality\n",
    "        vision_dim = self.ruclip.visual.num_features\n",
    "        name_dim = self.ruclip.final_ln.out_features\n",
    "        desc_dim = self.description_transformer.config.hidden_size\n",
    "        self.hidden_dim = vision_dim + name_dim + desc_dim\n",
    "\n",
    "        # Define MLP head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim // 2, self.hidden_dim // 4),\n",
    "        ).to(device)\n",
    "\n",
    "    def encode_image(self, image):\n",
    "        return self.ruclip.encode_image(image)\n",
    "\n",
    "    def encode_name(self, name):\n",
    "        return self.ruclip.encode_text(name[:, 0, :], name[:, 1, :])\n",
    "\n",
    "    def encode_description(self, desc):\n",
    "        last_hidden_states = self.description_transformer(desc[:, 0, :], desc[:, 1, :]).last_hidden_state\n",
    "        attention_mask = desc[:, 1, :]\n",
    "        return average_pool(last_hidden_states, attention_mask)\n",
    "\n",
    "    def get_final_embedding(self, im, name, desc):\n",
    "        image_emb = self.encode_image(im)\n",
    "        name_emb = self.encode_name(name)\n",
    "        desc_emb = self.encode_description(desc)\n",
    "\n",
    "        # Concatenate the embeddings and forward through the head\n",
    "        combined_emb = torch.cat([image_emb, name_emb, desc_emb], dim=1)\n",
    "        final_embedding = self.head(combined_emb)\n",
    "        return final_embedding\n",
    "\n",
    "    def forward(self, im1, name1, desc1, im2, name2, desc2):\n",
    "        out1 = self.get_final_embedding(im1, name1, desc1)\n",
    "        out2 = self.get_final_embedding(im2, name2, desc2)\n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "987d1ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def __name__(self,):\n",
    "        return 'ContrastiveLoss'\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        pos = (1-label) * torch.pow(euclidean_distance, 2)\n",
    "        neg = label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        loss_contrastive = torch.mean( pos + neg )\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a9c6281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pair(output1, output2, target, threshold):\n",
    "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "    # меньше границы, там где будет True — конкуренты\n",
    "    cond = euclidean_distance < threshold\n",
    "    pos_sum = 0\n",
    "    neg_sum = 0\n",
    "    pos_acc = 0\n",
    "    neg_acc = 0\n",
    "\n",
    "    for i in range(len(cond)):\n",
    "        # 1 значит не конкуренты\n",
    "        if target[i]:\n",
    "            neg_sum+=1\n",
    "            # 0 в cond значит дальше друг от друга чем threshold\n",
    "            if not cond[i]:\n",
    "                neg_acc+=1\n",
    "        elif not target[i]:\n",
    "            pos_sum+=1\n",
    "            if cond[i]:\n",
    "                pos_acc+=1\n",
    "\n",
    "    return pos_acc, pos_sum, neg_acc, neg_sum\n",
    "\n",
    "def predict(out1, out2, threshold=CONTRASTIVE_THRESHOLD):\n",
    "    # вернёт 1 если похожи\n",
    "    return F.pairwise_distance(out1, out2) < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6664f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, data_loader, epoch,\n",
    "               device='cpu', split_name='validation',\n",
    "               threshold=CONTRASTIVE_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Runs one epoch of validation (or test), computing:\n",
    "      - avg_loss\n",
    "      - positive/negative accuracies\n",
    "      - avg_acc\n",
    "      - F1\n",
    "    Logs valid_f1_score to MLflow if MLFLOW_URI is set.\n",
    "    Returns: pos_acc, neg_acc, avg_acc, f1, avg_loss\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    pos_acc_sum = neg_acc_sum = 0.0\n",
    "    pos_count = neg_count = 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=f\"{split_name}\"):\n",
    "            im1, name1, desc1, im2, name2, desc2, label = batch\n",
    "            im1, name1, desc1, im2, name2, desc2, label = (\n",
    "                im1.to(device), name1.to(device), desc1.to(device),\n",
    "                im2.to(device), name2.to(device), desc2.to(device),\n",
    "                label.to(device)\n",
    "            )\n",
    "            out1, out2 = model(im1, name1, desc1, im2, name2, desc2)\n",
    "            loss = criterion(out1, out2, label)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # compute pos/neg accuracy\n",
    "            distances = F.pairwise_distance(out1, out2)\n",
    "            preds = (distances < threshold).long()\n",
    "            pos_mask = (label == 0)\n",
    "            neg_mask = (label == 1)\n",
    "            pos_acc_sum += (preds[pos_mask] == 1).sum().item()\n",
    "            neg_acc_sum += (preds[neg_mask] == 0).sum().item()\n",
    "            pos_count   += pos_mask.sum().item()\n",
    "            neg_count   += neg_mask.sum().item()\n",
    "\n",
    "            # for F1\n",
    "            all_preds.extend(preds.cpu().numpy().tolist())\n",
    "            all_labels.extend((label.cpu().numpy() == 0).astype(int).tolist())\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    pos_acc  = pos_acc_sum / pos_count if pos_count else 0.0\n",
    "    neg_acc  = neg_acc_sum / neg_count if neg_count else 0.0\n",
    "    avg_acc  = (pos_acc + neg_acc) / 2.0\n",
    "    f1       = f1_score(all_labels, all_preds, zero_division=0)\n",
    "\n",
    "    report = (f\"[{split_name}] Epoch {epoch} – \"\n",
    "              f\"loss: {avg_loss:.4f}, \"\n",
    "              f\"P Acc: {pos_acc:.3f}, \"\n",
    "              f\"N Acc: {neg_acc:.3f}, \"\n",
    "              f\"Avg Acc: {avg_acc:.3f}, \"\n",
    "              f\"F1: {f1:.3f}\")\n",
    "    print(report)\n",
    "    make_tg_report(report, TELEGRAM_TOKEN)\n",
    "\n",
    "    if MLFLOW_URI:\n",
    "        mlflow.log_metric(\"valid_f1_score\", f1, step=epoch)\n",
    "\n",
    "    return pos_acc, neg_acc, avg_acc, f1, avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e34b5c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot epoch after each train epoch in `train()`\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def plot_epoch(loss_history, filename=\"data/runs_artifacts/epoch_loss.png\") -> None:\n",
    "    Path(filename).parent.mkdir(parents=True, exist_ok=True)\n",
    "    display.clear_output(wait=True)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.title(\"Training loss\")\n",
    "    plt.xlabel(\"Iteration number\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(loss_history, 'b')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)  # Save the plot to a file\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4952b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def train(model, optimizer, criterion,\n",
    "          epochs_num, train_loader, valid_loader=None,\n",
    "          device='cpu', print_epoch=False,\n",
    "          models_dir=None):\n",
    "    \"\"\"\n",
    "    Trains the model for `epochs_num` epochs, saving a checkpoint\n",
    "    each epoch into `models_dir` if given, and selects the best by validation F1.\n",
    "    Returns:\n",
    "      train_losses: list of avg train loss per epoch\n",
    "      val_losses:   list of avg val loss per epoch (only if valid_loader)\n",
    "      best_valid_f1, best_weights\n",
    "    \"\"\"\n",
    "    model.to(device).train()\n",
    "    train_losses, val_losses = [], []\n",
    "    best_valid_f1 = float('-inf')\n",
    "    best_weights = None\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, mode=\"max\",\n",
    "        factor=0.1, patience=SHEDULER_PATIENCE,\n",
    "        threshold=1e-4, threshold_mode='rel',\n",
    "        cooldown=0, min_lr=0, eps=1e-8\n",
    "    )\n",
    "\n",
    "    if models_dir:\n",
    "        Path(models_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for epoch in range(1, epochs_num + 1):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"train {epoch}/{epochs_num}\"):\n",
    "            im1, name1, desc1, im2, name2, desc2, label = [t.to(device) for t in batch]\n",
    "            optimizer.zero_grad()\n",
    "            out1, out2 = model(im1, name1, desc1, im2, name2, desc2)\n",
    "            loss = criterion(out1, out2, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        if print_epoch and valid_loader is not None:\n",
    "            _, _, _, val_f1, avg_val_loss = validation(\n",
    "                model, criterion, valid_loader,\n",
    "                epoch, device, split_name='validation'\n",
    "            )\n",
    "            val_losses.append(avg_val_loss)\n",
    "\n",
    "            scheduler.step(val_f1)\n",
    "\n",
    "            if models_dir:\n",
    "                ckpt_path = Path(models_dir) / f\"checkpoint_epoch_{epoch}.pt\"\n",
    "                torch.save(model.state_dict(), ckpt_path)\n",
    "\n",
    "            if val_f1 > best_valid_f1:\n",
    "                best_valid_f1 = val_f1\n",
    "                best_weights = model.state_dict().copy()\n",
    "\n",
    "    print(f\"Best validation F1: {best_valid_f1:.3f}\")\n",
    "    return train_losses, val_losses, best_valid_f1, best_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481940bc",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e226754b",
   "metadata": {},
   "source": [
    "## Download data from HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6b8cde88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ae0ff5c9c54ec79f7f8b39631c8653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download models' weights & text/image datasets\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_ID = \"INDEEPA/clip-siamese\"\n",
    "LOCAL_DIR = Path(\"data/train_results\")\n",
    "LOCAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=REPO_ID,\n",
    "    repo_type='dataset',\n",
    "    local_dir='data',\n",
    "    allow_patterns=[\n",
    "        \"train_results/cc12m*.pt\",\n",
    "        TABLE_DATASET_FILE,\n",
    "        f\"{IMG_DATASET_NAME}.zip\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "!unzip -n -q data/{IMG_DATASET_NAME}.zip -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d35d53",
   "metadata": {},
   "source": [
    "## Split data by query sku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "387fca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique query sku: 20\n"
     ]
    }
   ],
   "source": [
    "TABLE_DATASET_PATH = DATA_PATH + TABLE_DATASET_FILE\n",
    "\n",
    "labeled = pd.read_csv(TABLE_DATASET_PATH)\n",
    "print(f\"Unique query sku: {labeled.sku_query.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c414d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/val/test\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "def split_pairwise(\n",
    "    df: pd.DataFrame,\n",
    "    test_size: float = 0.20,\n",
    "    random_state: int | None = None,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Leakage-free DEV / TEST split for a pair-wise SKU dataset.\n",
    "    Input `df` must have columns ['sku_query','sku_candidate','label'].\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    test_rows, dev_rows   = [], []\n",
    "    test_entities: set[str] = set()\n",
    "\n",
    "    # ---- iterate over each original query SKU ------------------------------\n",
    "    for q_sku, grp in df.groupby(\"sku_query\"):\n",
    "        pos_idx = grp.index[grp.label == 1].tolist()\n",
    "        neg_idx = grp.index[grp.label == 0].tolist()\n",
    "\n",
    "        # --- (1) sample TEST rows -------------------------------------------\n",
    "        n_pos = int(np.ceil(test_size * len(pos_idx))) if pos_idx else 0\n",
    "        n_neg = int(np.ceil(test_size * len(neg_idx))) if neg_idx else 0\n",
    "\n",
    "        pos_test = rng.choice(pos_idx, size=n_pos, replace=False) if n_pos else []\n",
    "        neg_test = rng.choice(neg_idx, size=n_neg, replace=False) if n_neg else []\n",
    "\n",
    "        test_rows.extend(pos_test)\n",
    "        test_rows.extend(neg_test)\n",
    "\n",
    "        # register every entity that just entered TEST\n",
    "        test_entities.add(q_sku)\n",
    "        test_entities.update(df.loc[pos_test, \"sku_candidate\"])\n",
    "        test_entities.update(df.loc[neg_test, \"sku_candidate\"])\n",
    "\n",
    "        # --- (2) build DEV from remaining rows ------------------------------\n",
    "        remain_pos = list(set(pos_idx) - set(pos_test))\n",
    "        remain_neg = list(set(neg_idx) - set(neg_test))\n",
    "\n",
    "        if remain_pos:\n",
    "            # choose substitute query (one of the remaining positives)\n",
    "            sub_idx  = int(rng.choice(remain_pos))\n",
    "            sub_sku  = df.loc[sub_idx, \"sku_candidate\"]\n",
    "\n",
    "            for idx in remain_pos:\n",
    "                if idx == sub_idx:            # skip (sub,sub) self-pair\n",
    "                    continue\n",
    "                row = df.loc[idx].copy()\n",
    "                row[\"sku_query\"] = sub_sku\n",
    "                dev_rows.append(row)\n",
    "\n",
    "            for idx in remain_neg:\n",
    "                row = df.loc[idx].copy()\n",
    "                row[\"sku_query\"] = sub_sku\n",
    "                dev_rows.append(row)\n",
    "\n",
    "    # ---- materialise the splits -------------------------------------------\n",
    "    test_df = df.loc[test_rows].reset_index(drop=True)\n",
    "    dev_df  = pd.DataFrame(dev_rows).reset_index(drop=True)\n",
    "\n",
    "    # ---- (3) final purge: remove any row touching a TEST entity ------------\n",
    "    mask = ~(dev_df[\"sku_query\"].isin(test_entities) |\n",
    "             dev_df[\"sku_candidate\"].isin(test_entities))\n",
    "    dev_df = dev_df[mask].reset_index(drop=True)\n",
    "\n",
    "    return dev_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e00ad1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2510, 95), (175, 95), (644, 95))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into train/val/test\n",
    "\n",
    "dev_df,  test_df  = split_pairwise(labeled,  test_size=TEST_SPLIT, random_state=42)\n",
    "train_df, val_df  = split_pairwise(dev_df,   test_size=VALIDATION_SPLIT, random_state=42)\n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "efc1fa9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       hard_negative  positive  total\n",
      "split                                \n",
      "train           2156       354   2510\n",
      "val              146        29    175\n",
      "test             551        93    644\n"
     ]
    }
   ],
   "source": [
    "# Print positive/hard_negative pairs count per each split \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# collect your splits in a dict\n",
    "splits = {\n",
    "    'train': train_df,\n",
    "    'val':   val_df,\n",
    "    'test':  test_df,\n",
    "}\n",
    "\n",
    "# build the summary_df records\n",
    "records = []\n",
    "for name, df in splits.items():\n",
    "    vc = df['label'].value_counts()\n",
    "    records.append({\n",
    "        'split':    name,\n",
    "        'hard_negative': vc.get(0, 0),\n",
    "        'positive': vc.get(1, 0),\n",
    "        'total':    len(df),\n",
    "    })\n",
    "\n",
    "# create a DataFrame and set the split name as index\n",
    "summary_df = (\n",
    "    pd.DataFrame(records)\n",
    "      .set_index('split')\n",
    "      .astype(int)\n",
    ")\n",
    "\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1bed0574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All sanity checks passed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def sanity_checks(train: pd.DataFrame, val: pd.DataFrame, test: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Verify that:\n",
    "      1) Each query SKU appears in exactly one split\n",
    "      2) No SKU (query or candidate) overlaps across splits\n",
    "      3) No duplicate pairs across splits\n",
    "      4) Each split has at least one positive and one hard_negative\n",
    "    \"\"\"\n",
    "    # 1) Query-level disjointness\n",
    "    q_train = set(train[\"sku_query\"])\n",
    "    q_val   = set(val  [\"sku_query\"])\n",
    "    q_test  = set(test [\"sku_query\"])\n",
    "    assert not (q_train & q_val),   f\"Query SKU overlap train↔val: {q_train & q_val}\"\n",
    "    assert not (q_train & q_test),  f\"Query SKU overlap train↔test: {q_train & q_test}\"\n",
    "    assert not (q_val   & q_test),  f\"Query SKU overlap val↔test:   {q_val   & q_test}\"\n",
    "    \n",
    "    # 2) Global SKU disjointness (query OR candidate)\n",
    "    def all_skus(df):\n",
    "        return set(df[\"sku_query\"]) | set(df[\"sku_candidate\"])\n",
    "    s_train, s_val, s_test = all_skus(train), all_skus(val), all_skus(test)\n",
    "    assert not (s_train & s_val),   f\"SKU overlap train↔val: {s_train & s_val}\"\n",
    "    assert not (s_train & s_test),  f\"SKU overlap train↔test: {s_train & s_test}\"\n",
    "    assert not (s_val   & s_test),  f\"SKU overlap val↔test:   {s_val   & s_test}\"\n",
    "    \n",
    "    # 3) Unique pairs\n",
    "    all_pairs = pd.concat([train, val, test], ignore_index=True)\n",
    "    dupes = all_pairs.duplicated(subset=[\"sku_query\",\"sku_candidate\",\"label\"])\n",
    "    assert not dupes.any(), f\"Found {dupes.sum()} duplicate pairs across splits\"\n",
    "    \n",
    "    # 4) Label coverage in each split\n",
    "    for name, df in [(\"train\", train), (\"val\", val), (\"test\", test)]:\n",
    "        labels = df[\"label\"].unique()\n",
    "        assert set(labels) == {0,1}, f\"{name} split has labels {labels}, expected {{0,1}}\"\n",
    "    \n",
    "    print(\"✅ All sanity checks passed!\")\n",
    "\n",
    "sanity_checks(train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b096d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename for compatibility with torch.Dataset\n",
    "\n",
    "def rename_cols(df):\n",
    "    df = df.rename(columns={\n",
    "        col: col.replace(\"_query\", \"_first\").replace(\"_candidate\", \"_second\")\n",
    "        for col in df.columns\n",
    "        if \"_query\" in col or \"_candidate\" in col\n",
    "    })\n",
    "    return df\n",
    "\n",
    "train_df = rename_cols(train_df)\n",
    "val_df = rename_cols(val_df)\n",
    "test_df = rename_cols(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0626ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for later usage\n",
    "\n",
    "folder_name = f'test={TEST_SPLIT}_val={VALIDATION_SPLIT}'\n",
    "dataset_name = Path(TABLE_DATASET_PATH).parts[1]\n",
    "\n",
    "common_file_prefix = (\n",
    "    Path(DATA_PATH) / dataset_name / 'processed' /\n",
    "    'pairwise-splits' / folder_name\n",
    ")\n",
    "common_file_prefix.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_df.to_csv(common_file_prefix / 'train.csv', index=False)\n",
    "val_df.to_csv(common_file_prefix / 'val.csv', index=False)\n",
    "test_df.to_csv(common_file_prefix / 'test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b4aa24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_split(df: pd.DataFrame, num_samples: int | None, random_state: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    If num_samples is set, take up to that many random rows;\n",
    "    otherwise just shuffle the entire DataFrame.\n",
    "    Always resets the index.\n",
    "    \"\"\"\n",
    "    if num_samples is not None:\n",
    "        n = min(num_samples, len(df))\n",
    "        out = df.sample(n=n, random_state=random_state)\n",
    "    else:\n",
    "        out = df.sample(frac=1, random_state=random_state)\n",
    "    return out.reset_index(drop=True)\n",
    "\n",
    "# apply to each split\n",
    "train_df = sample_split(train_df, NUM_DEBUG_SAMPLES, RANDOM_SEED)\n",
    "val_df   = sample_split(val_df,   NUM_DEBUG_SAMPLES, RANDOM_SEED)\n",
    "test_df  = sample_split(test_df,  NUM_DEBUG_SAMPLES, RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef17b84c",
   "metadata": {},
   "source": [
    "# Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "afb31be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 2/2 [00:00<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch 2 – loss: 2.2997, P Acc: 0.000, N Acc: 0.000, Avg Acc: 0.000, F1: 0.000\n",
      "Test F1-score on best model: 0.000\n",
      "Saved best‐F1 checkpoint to data/data/train_results/siamese_contrastive_test-f1=0.000_splitting-by-query_cc12m_rubert_tiny_ep_1.pt.pt\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def _run():\n",
    "    images_dir = os.path.join(DATA_PATH, IMG_DATASET_NAME)\n",
    "\n",
    "    # 1) Prepare splits and rename columns\n",
    "    splits = {\n",
    "        'train':      train_df,\n",
    "        'validation': val_df,\n",
    "        'test':       test_df,\n",
    "    }\n",
    "    loaders = {}\n",
    "\n",
    "    for split_name, df in splits.items():\n",
    "        # build dataset + loader\n",
    "        labels = df[\"label\"].values\n",
    "        ds     = SiameseRuCLIPDataset(df.drop(columns=\"label\"), labels, images_dir=images_dir)\n",
    "\n",
    "        shuffle = (split_name == 'train')\n",
    "        loaders[split_name] = DataLoader(\n",
    "            ds,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=NUM_WORKERS\n",
    "        )\n",
    "\n",
    "    train_loader = loaders['train']\n",
    "    valid_loader = loaders['validation']\n",
    "    test_loader  = loaders['test']\n",
    "\n",
    "    print(\"Loading model and optimizer…\")\n",
    "    model     = SiameseRuCLIP(\n",
    "        DEVICE, NAME_MODEL_NAME,\n",
    "        DESCRIPTION_MODEL_NAME,\n",
    "        PRELOAD_MODEL_NAME,\n",
    "        DATA_PATH + RESULTS_DIR,\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    criterion = ContrastiveLoss(margin=CONTRASTIVE_MARGIN).to(DEVICE)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    print(\"Done.\")\n",
    "\n",
    "    # Temporary dir for intermediate checkpoints\n",
    "    with tempfile.TemporaryDirectory() as tmp_ckpt_dir:\n",
    "        train_losses, val_losses, best_f1, best_weights = train(\n",
    "            model, optimizer, criterion,\n",
    "            EPOCHS, train_loader, valid_loader,\n",
    "            print_epoch=True,\n",
    "            device=DEVICE,\n",
    "            models_dir=tmp_ckpt_dir\n",
    "        )\n",
    "    print(f\"→ Best validation F1: {best_f1:.3f}\")\n",
    "\n",
    "    # Plot train vs. val loss by epoch\n",
    "    epochs = list(range(1, len(train_losses) + 1))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(epochs, train_losses, label='Train Loss')\n",
    "    ax.plot(epochs, val_losses,   label='Val   Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Training & Validation Loss by Epoch')\n",
    "    ax.legend()\n",
    "    if MLFLOW_URI:\n",
    "        mlflow.log_figure(fig, 'loss_by_epoch.png')\n",
    "\n",
    "    # TODO: display after each train epoch\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "    # Final test on the best model\n",
    "    model.load_state_dict(best_weights)\n",
    "    model.eval()\n",
    "    test_pos_acc, test_neg_acc, test_acc, test_f1, test_loss = validation(\n",
    "        model, criterion, test_loader,\n",
    "        epoch=EPOCHS, device=DEVICE, split_name='test'\n",
    "    )\n",
    "    print(f\"Test F1-score on best model: {test_f1:.3f}\")\n",
    "\n",
    "    # Save only final model\n",
    "    filename = (\n",
    "        f\"siamese_contrastive_test-f1={test_f1:.3f}\"\n",
    "        f\"{'_' + MODEL_NAME_POSTFIX if MODEL_NAME_POSTFIX else ''}\"\n",
    "        f\"{'_' + PRELOAD_MODEL_NAME if PRELOAD_MODEL_NAME else ''}\"\n",
    "        \".pt\"\n",
    "    )\n",
    "\n",
    "    final_path = (\n",
    "        Path(DATA_PATH) /\n",
    "        Path(DATA_PATH + RESULTS_DIR) /\n",
    "        filename\n",
    "    )\n",
    "\n",
    "    final_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(best_weights, final_path)\n",
    "    print(f\"Saved best‐F1 checkpoint to {final_path}\")\n",
    "\n",
    "    if MLFLOW_URI:\n",
    "        mlflow.log_metric(\"test_pos_accuracy\", test_pos_acc)\n",
    "        mlflow.log_metric(\"test_neg_accuracy\", test_neg_acc)\n",
    "        mlflow.log_metric(\"test_accuracy\", test_acc)\n",
    "        mlflow.log_metric(\"test_f1_score\", test_f1)\n",
    "        mlflow.end_run()\n",
    "\n",
    "_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70470186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
