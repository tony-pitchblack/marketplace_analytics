{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installs & tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    import dotenv\n",
    "except ImportError:\n",
    "    !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Kaggle environment. Skipping Kaggle secrets.\n",
      "Trying to load HF_TOKEN from .env.\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Log into huggingface via Kaggle Secrets or .env\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import huggingface_hub\n",
    "\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "    user_secrets = UserSecretsClient()\n",
    "    HF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Not Kaggle environment. Skipping Kaggle secrets.\")\n",
    "    print(\"Trying to load HF_TOKEN from .env.\")\n",
    "    load_dotenv()\n",
    "    HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "    print(\"Success!\")\n",
    "\n",
    "huggingface_hub.login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/'\n",
    "SOURCE_TABLE_NAME = 'tables_OZ_geo_5500/processed/OZ_geo_5500.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "EMBEDDING_MODEL_NAME = 'sergeyzh/LaBSE-ru-turbo'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    EMB_BATCH_SIZE = 512\n",
    "    NUM_EMBS = None\n",
    "    DEVICE = 'cuda'\n",
    "else:\n",
    "    EMB_BATCH_SIZE = 1\n",
    "    NUM_EMBS = 2\n",
    "    DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f4d0069b5c48c087014e5835284c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download models' weights & text/image datasets\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_ID = \"INDEEPA/clip-siamese\"\n",
    "\n",
    "_ = snapshot_download(\n",
    "    repo_id=REPO_ID,\n",
    "    repo_type='dataset',\n",
    "    local_dir='data',\n",
    "    allow_patterns=[\n",
    "        SOURCE_TABLE_NAME,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5562, 46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1871769771</td>\n",
       "      <td>Карты МИРА и РОССИИ настенные политические,160...</td>\n",
       "      <td>Представляем вашему вниманию уникальный набор ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sku                                               name  \\\n",
       "0  1871769771  Карты МИРА и РОССИИ настенные политические,160...   \n",
       "\n",
       "                                         description  \n",
       "0  Представляем вашему вниманию уникальный набор ...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "source_df = pd.read_csv(DATA_PATH + SOURCE_TABLE_NAME)\n",
    "print(source_df.shape)\n",
    "source_df[['sku', 'name', 'description']].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>name_and_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1871769771</td>\n",
       "      <td>Карты МИРА и РОССИИ настенные политические,160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1679550303</td>\n",
       "      <td>Схема линий скоростного транспорта Москвы (Мет...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1200553001</td>\n",
       "      <td>Политическая карта МИРА 160х109 см, Карта мира...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>922231521</td>\n",
       "      <td>Политическая карта МИРА настенная, 100х70см, ш...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>922230517</td>\n",
       "      <td>Политическая карта МИРА настенная, 160х102см, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sku                               name_and_description\n",
       "0  1871769771  Карты МИРА и РОССИИ настенные политические,160...\n",
       "1  1679550303  Схема линий скоростного транспорта Москвы (Мет...\n",
       "2  1200553001  Политическая карта МИРА 160х109 см, Карта мира...\n",
       "3   922231521  Политическая карта МИРА настенная, 100х70см, ш...\n",
       "4   922230517  Политическая карта МИРА настенная, 160х102см, ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# concatenate name & description\n",
    "\n",
    "source_df['name_and_description'] = source_df['name'].fillna('') + '.\\n' + source_df['description'].fillna('')\n",
    "display(source_df[['sku', 'name_and_description']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1da5cf05bf946499d24b4ebef0d4db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>name_desc_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1871769771</td>\n",
       "      <td>[-0.020089328289031982, -0.05487040802836418, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1679550303</td>\n",
       "      <td>[-0.004182410426437855, -0.040884267538785934,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sku                                      name_desc_emb\n",
       "0  1871769771  [-0.020089328289031982, -0.05487040802836418, ...\n",
       "1  1679550303  [-0.004182410426437855, -0.040884267538785934,..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to:\n",
      "embeddings/OZ_geo_5500/OZ_geo_5500_name-and-description_embeddings_num-rows=2.parquet\n"
     ]
    }
   ],
   "source": [
    "# --- Compute and save embeddings for all SKUs in source_df ---\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "all_skus_df = source_df.copy()\n",
    "if NUM_EMBS is not None:\n",
    "    all_skus_df = all_skus_df.head(NUM_EMBS)\n",
    "\n",
    "model = SentenceTransformer(EMBEDDING_MODEL_NAME, device=DEVICE)\n",
    "\n",
    "emb_table = all_skus_df[['sku', 'name_and_description']].copy().reset_index(drop=True)\n",
    "candidate_texts = emb_table['name_and_description'].astype(str).tolist()\n",
    "\n",
    "embeddings = model.encode(\n",
    "    candidate_texts,\n",
    "    batch_size=EMB_BATCH_SIZE,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "emb_table['name_desc_emb'] = [emb.tolist() if hasattr(emb, 'tolist') else emb for emb in embeddings]\n",
    "emb_table = emb_table[['sku', 'name_desc_emb']]\n",
    "display(emb_table.head())\n",
    "\n",
    "# Save to parquet\n",
    "file_dir = Path('embeddings/OZ_geo_5500')\n",
    "file_name = f\"{Path(SOURCE_TABLE_NAME).stem}_name-and-description_embeddings_num-rows={len(emb_table)}.parquet\"\n",
    "full_file_path = Path(DATA_PATH) / file_dir / file_name\n",
    "full_file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "emb_table.to_parquet(full_file_path, index=False)\n",
    "print(f\"Saved embeddings to:\\n{file_dir / file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/INDEEPA/clip-siamese/commit/29c32eb5082a972001f154f7a356221ded363ce6', commit_message='Upload folder using huggingface_hub', commit_description='', oid='29c32eb5082a972001f154f7a356221ded363ce6', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/INDEEPA/clip-siamese', endpoint='https://huggingface.co', repo_type='dataset', repo_id='INDEEPA/clip-siamese'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload embeddings to HF\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import HfApi, login\n",
    "\n",
    "# Load HF_TOKEN from .env\n",
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "if not hf_token:\n",
    "    raise ValueError(\"HF_TOKEN not found in .env file\")\n",
    "\n",
    "# Log into HuggingFace\n",
    "login(token=hf_token)\n",
    "\n",
    "# Upload the folder\n",
    "api = HfApi()\n",
    "api.upload_folder(\n",
    "    folder_path=DATA_PATH / file_dir,  # Path to the local directory\n",
    "    path_in_repo=str(file_dir),\n",
    "    repo_id=\"INDEEPA/clip-siamese\",\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
